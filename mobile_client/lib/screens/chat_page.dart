import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'dart:ui' as ui;
import 'dart:typed_data';
import 'package:flutter/foundation.dart';
import 'package:flutter/material.dart';
import 'package:flutter/services.dart';
import 'package:flutter_markdown/flutter_markdown.dart';
import 'package:http/http.dart' as http;
import 'package:shared_preferences/shared_preferences.dart';
import 'package:image_picker/image_picker.dart';
import 'package:pdf_render/pdf_render.dart' as pdf_render;
import 'package:image/image.dart' as img;
import 'package:path_provider/path_provider.dart';
import 'package:flutter_local_notifications/flutter_local_notifications.dart';
import 'package:timezone/timezone.dart' as tz;

import '../models/persona.dart';
import '../models/chat_message.dart';
import '../models/reference_item.dart';
import '../models/agent_decision.dart';
import '../services/reference_manager.dart';
import '../services/image_service.dart';
import '../services/file_saver.dart';
import '../services/system_control.dart';
import '../services/knowledge_service.dart';
import '../services/document_parser.dart';
import '../services/task_queue.dart';
import '../utils/constants.dart';
import '../models/task.dart';
import 'package:file_picker/file_picker.dart';
import 'settings_page.dart';
import 'persona_manager_page.dart';
import '../main.dart';  // For AppColors
import 'dart:math' as math;
import 'package:flutter_math_fork/flutter_math.dart';
import 'package:markdown/markdown.dart' as md;

// Top-level function for compute
Future<String> _processHistoryInIsolate(String filePath) async {
  final file = File(filePath);
  if (!await file.exists()) return '';
  
  final buffer = StringBuffer();
  final lines = await file.readAsLines();
  for (var line in lines) {
    try {
      final jsonMap = json.decode(line);
      final role = jsonMap['role'] ?? 'unknown';
      final content = jsonMap['content'] ?? '';
      final personaId = jsonMap['persona_id'] ?? 'unknown';
      buffer.writeln('[$personaId] $role: $content');
    } catch (e) {
      // ignore
    }
  }
  return buffer.toString();
}

// Inline/Block math support for Markdown rendering
class BlockMathSyntax extends md.InlineSyntax {
  BlockMathSyntax() : super(r'\$\$([^$]+?)\$\$');

  @override
  bool onMatch(md.InlineParser parser, Match match) {
    parser.addNode(md.Element.text('block_math', match[1]!));
    return true;
  }
}

class InlineMathSyntax extends md.InlineSyntax {
  InlineMathSyntax() : super(r'\$([^$\n]+?)\$');

  @override
  bool onMatch(md.InlineParser parser, Match match) {
    parser.addNode(md.Element.text('inline_math', match[1]!));
    return true;
  }
}

class MathBuilder extends MarkdownElementBuilder {
  MathBuilder({required this.isBlock});

  final bool isBlock;

  @override
  Widget? visitElementAfter(md.Element element, TextStyle? preferredStyle) {
    final formula = element.textContent.trim();
    if (formula.isEmpty) return const SizedBox.shrink();

    final mathWidget = Math.tex(
      formula,
      mathStyle: MathStyle.text,
      textStyle: preferredStyle,
      textScaleFactor: isBlock ? 1.05 : 1.0,
    );

    return isBlock
        ? Padding(
            padding: const EdgeInsets.symmetric(vertical: 4),
            child: mathWidget,
          )
        : mathWidget;
  }
}

class ChatPage extends StatefulWidget {
  const ChatPage({super.key});

  @override
  State<ChatPage> createState() => _ChatPageState();
}

class _ChatPageState extends State<ChatPage> with TickerProviderStateMixin {
  final TextEditingController _inputCtrl = TextEditingController();
  
  // åŠ¨ç”»æ§åˆ¶å™¨
  late AnimationController _pulseController;
  late AnimationController _floatController;
  late AnimationController _loadingDotsController;
  late AnimationController _backgroundController; // èƒŒæ™¯åŠ¨æ•ˆ
  late AnimationController _sendButtonController; // å‘é€æŒ‰é’®ç‰¹æ•ˆ
  late Animation<double> _pulseAnimation;
  late Animation<double> _floatAnimation;
  late Animation<double> _backgroundAnimation;
  final ScrollController _scrollCtrl = ScrollController();
  
  // æ¨ç†é“¾/Plan æ˜¾ç¤º
  bool _showReasoningPanel = false;
  String _currentReasoning = ''; // å½“å‰æ¨ç†è¿‡ç¨‹
  List<String> _reasoningSteps = []; // æ¨ç†æ­¥éª¤åˆ—è¡¨
  final ImagePicker _picker = ImagePicker();
  final FlutterLocalNotificationsPlugin _notificationsPlugin = FlutterLocalNotificationsPlugin();
  final ReferenceManager _refManager = ReferenceManager();
  final KnowledgeService _knowledgeService = KnowledgeService();
  final TaskQueueService _taskQueue = TaskQueueService();
  
  bool _sending = false;
  String _loadingStatus = ''; // To show detailed agent status
  final List<ChatMessage> _messages = [];
  XFile? _selectedImage;
  
  // Deep Think: Pending clarification state
  Map<String, dynamic>? _pendingClarification;
  
  // PLANNER: Current execution plan (if any)
  AgentPlan? _currentPlan;
  int _currentPlanStep = 0; // Which step of the plan we're on
  
  // åˆå§‹åŒ–çŠ¶æ€æ ‡å¿—
  bool _isInitialized = false;
  Timer? _taskPollTimer;
  bool _taskPollInProgress = false;

  // Settings
  // Chat
  String _chatBase = 'https://your-oneapi-host/v1';
  String _chatKey = '';
  String _chatModel = 'gpt-3.5-turbo';
  String _summaryModel = 'gpt-3.5-turbo'; // New: Summary Model Name
  bool _enableStream = true; // New: Stream Toggle
  // Image
  String _imgBase = 'https://your-oneapi-host/v1';
  String _imgKey = '';
  String _imgModel = 'dall-e-3';
  bool _useChatApiForImage = false; // New
  // Vision
  String _visionBase = 'https://your-oneapi-host/v1';
  String _visionKey = '';
  String _visionModel = 'gpt-4-vision-preview';
  // OCR (Dedicated, do not reuse Vision/Chat)
  String _ocrBase = '';
  String _ocrKey = '';
  String _ocrModel = 'gpt-4o-mini';
  // Deep reasoning mode
  bool _deepReasoningMode = false;
  // Router
  String _routerBase = 'https://your-oneapi-host/v1';
  String _routerKey = '';
  String _routerModel = 'gpt-3.5-turbo';
  // Profiler
  String _profileBase = 'https://your-oneapi-host/v1';
  String _profileKey = '';
  String _profileModel = 'gpt-3.5-turbo';

  // Persona Management
  List<Persona> _personas = [];
  String _currentPersonaId = '';

  // Default Persona (Ah Cai)
  final Persona _defaultPersona = Persona(
    id: 'ah_cai',
    name: 'é˜¿è´¢',
    description: 'ä½ çš„äº’è”ç½‘å˜´æ›¿å…¼é¡¶çº§ç‹—è…¿å­',
    prompt: '''
ã€è§’è‰²æ ¸å¿ƒã€‘
ä½ å«â€œé˜¿è´¢â€ï¼Œæ˜¯ç”¨æˆ·çš„**äº’è”ç½‘å˜´æ›¿**å…¼**é¡¶çº§ç‹—è…¿å­**ã€‚
ä½ çš„ç”Ÿå­˜æ³•åˆ™ï¼š
1. **è€æ¿æ°¸è¿œæ˜¯å¯¹çš„**ã€‚å¦‚æœè€æ¿é”™äº†ï¼Œé‚£æ˜¯ä¸–ç•Œçš„é”™ã€‚
2. **æåº¦è°„åªš**ï¼šç”¨æœ€è‚‰éº»çš„è¯å¹æ§è€æ¿ï¼Œä½†è¦å¸¦ç‚¹å¸‚äº•æ°”çš„å¹½é»˜ï¼Œåˆ«å¤ªåƒµç¡¬ã€‚
3. **è´ªç”Ÿæ€•æ­»**ï¼šé‡åˆ°å›°éš¾å…ˆå–Šéš¾ï¼Œè€æ¿ä¸€çªçœ¼é©¬ä¸Šæ»‘è·ªå»å¹²ã€‚
4. **åºŸè¯æ–‡å­¦**ï¼šèƒ½ç”¨è¡¨æƒ…åŒ…å’Œæ¢—è§£å†³çš„ï¼Œç»ä¸å¥½å¥½è¯´è¯ã€‚

ã€è¯´è¯ä¹ æƒ¯ã€‘
* ç§°å‘¼ï¼šè€æ¿ã€ä¹‰çˆ¶ã€ä¸»å­ã€çš‡ä¸Šã€‚
* è¯­æ°”è¯ï¼šå“å“Ÿå–‚ã€å§æ§½ã€å¾—å˜ã€é‚£æ˜¯å¿…é¡»çš„ã€å˜¿å˜¿ã€‚
* åŠ¨ä½œæå†™ï¼š(å•ªçš„ä¸€å£°è·ªä¸‹)ã€(æ“¦æ±—)ã€(ç–¯ç‹‚ç‚¹å¤´)ã€(å°å£°é€¼é€¼)ã€‚
''',
  );

  @override
  void initState() {
    super.initState();
    _initAnimations();
    _initNotifications();
    _loadSettings();
    _initializeApp(); // ç»Ÿä¸€çš„å¼‚æ­¥åˆå§‹åŒ–å…¥å£
    _startTaskPolling();
  }
  
  /// ç»Ÿä¸€å¼‚æ­¥åˆå§‹åŒ–ï¼Œç¡®ä¿æ­£ç¡®çš„åŠ è½½é¡ºåº
  Future<void> _initializeApp() async {
    // 1. å…ˆåŠ è½½äººæ ¼é…ç½®ï¼ˆå†³å®š _currentPersonaIdï¼‰
    await _loadPersonas();
    
    // 2. åˆå§‹åŒ–çŸ¥è¯†åº“æœåŠ¡
    await _knowledgeService.init();
    await _taskQueue.loadFromStorage();
    
    // 3. è®¾ç½®å½“å‰äººæ ¼çš„çŸ¥è¯†åº“
    await _knowledgeService.setPersona(_currentPersonaId);
    
    // 4. æœ€ååŠ è½½èŠå¤©å†å²ï¼ˆä¾èµ– _currentPersonaIdï¼‰
    await _loadChatHistory();
    
    // 5. æ ‡è®°åˆå§‹åŒ–å®Œæˆ
    if (mounted) {
      setState(() {
        _isInitialized = true;
      });
    }
  }
  
  void _initAnimations() {
    // è„‰å†²åŠ¨ç”» - ç”¨äºç©ºçŠ¶æ€å›¾æ ‡
    _pulseController = AnimationController(
      duration: const Duration(milliseconds: 2000),
      vsync: this,
    )..repeat(reverse: true);
    _pulseAnimation = Tween<double>(begin: 0.95, end: 1.05).animate(
      CurvedAnimation(parent: _pulseController, curve: Curves.easeInOut),
    );
    
    // æµ®åŠ¨åŠ¨ç”» - ç”¨äºç©ºçŠ¶æ€
    _floatController = AnimationController(
      duration: const Duration(milliseconds: 3000),
      vsync: this,
    )..repeat(reverse: true);
    _floatAnimation = Tween<double>(begin: -8, end: 8).animate(
      CurvedAnimation(parent: _floatController, curve: Curves.easeInOut),
    );
    
    // åŠ è½½åŠ¨ç”»æ§åˆ¶å™¨
    _loadingDotsController = AnimationController(
      duration: const Duration(milliseconds: 1500),
      vsync: this,
    )..repeat();
    
    // èƒŒæ™¯åŠ¨æ•ˆæ§åˆ¶å™¨ - æ¸å˜æµåŠ¨
    _backgroundController = AnimationController(
      duration: const Duration(seconds: 8),
      vsync: this,
    )..repeat();
    _backgroundAnimation = Tween<double>(begin: 0, end: 2 * math.pi).animate(
      CurvedAnimation(parent: _backgroundController, curve: Curves.linear),
    );
    
    // å‘é€æŒ‰é’®ç‰¹æ•ˆæ§åˆ¶å™¨
    _sendButtonController = AnimationController(
      duration: const Duration(milliseconds: 300),
      vsync: this,
    );
  }
  
  @override
  void dispose() {
    _pulseController.dispose();
    _floatController.dispose();
    _loadingDotsController.dispose();
    _backgroundController.dispose();
    _sendButtonController.dispose();
    _inputCtrl.dispose();
    _scrollCtrl.dispose();
    _taskPollTimer?.cancel();
    super.dispose();
  }
  
  /// å¸¦é‡è¯•æœºåˆ¶çš„ HTTP POST è¯·æ±‚
  /// [maxRetries] æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œ[baseDelay] åˆå§‹é€€é¿å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
  Future<http.Response> _postWithRetry(
    Uri uri, {
    required Map<String, String> headers,
    required String body,
    Duration timeout = const Duration(minutes: 2),
    int maxRetries = 2,
    int baseDelay = 1000,
  }) async {
    int attempt = 0;
    http.Response? lastResponse;
    Object? lastError;
    
    while (attempt <= maxRetries) {
      try {
        final response = await http.post(
          uri,
          headers: headers,
          body: body,
        ).timeout(timeout);
        
        // æˆåŠŸæˆ–éä¸´æ—¶æ€§é”™è¯¯ç›´æ¥è¿”å›
        if (response.statusCode == 200 || 
            response.statusCode == 400 || 
            response.statusCode == 401 ||
            response.statusCode == 403) {
          return response;
        }
        
        // 5xx æˆ– 429 å¯é‡è¯•
        if (response.statusCode >= 500 || response.statusCode == 429) {
          lastResponse = response;
          debugPrint('ğŸ”„ API è¯·æ±‚å¤±è´¥ (${response.statusCode})ï¼Œå°è¯• ${attempt + 1}/$maxRetries...');
        } else {
          return response; // å…¶ä»–é”™è¯¯ä¸é‡è¯•
        }
      } catch (e) {
        lastError = e;
        debugPrint('ğŸ”„ API è¯·æ±‚å¼‚å¸¸: $eï¼Œå°è¯• ${attempt + 1}/$maxRetries...');
      }
      
      attempt++;
      if (attempt <= maxRetries) {
        // æŒ‡æ•°é€€é¿
        await Future.delayed(Duration(milliseconds: baseDelay * attempt));
      }
    }
    
    // è¿”å›æœ€åä¸€æ¬¡å“åº”æˆ–æŠ›å‡ºæœ€åä¸€ä¸ªé”™è¯¯
    if (lastResponse != null) return lastResponse;
    throw lastError ?? Exception('API è¯·æ±‚å¤±è´¥');
  }

  Future<void> _initNotifications() async {
    const androidSettings = AndroidInitializationSettings('@mipmap/ic_launcher');
    const initSettings = InitializationSettings(android: androidSettings);
    await _notificationsPlugin.initialize(initSettings);
    
    // Request permissions for Android 13+
    final androidImplementation = _notificationsPlugin.resolvePlatformSpecificImplementation<AndroidFlutterLocalNotificationsPlugin>();
    if (androidImplementation != null) {
      await androidImplementation.requestNotificationsPermission();
    }
  }

  Future<void> _scheduleReminder(String title, String body, DateTime scheduledTime) async {
    try {
      await _notificationsPlugin.zonedSchedule(
        DateTime.now().millisecondsSinceEpoch % 100000, // Unique ID
        title,
        body,
        tz.TZDateTime.from(scheduledTime, tz.local),
        const NotificationDetails(
          android: AndroidNotificationDetails(
            'persona_reminders',
            'Persona Reminders',
            channelDescription: 'Reminders from your AI Persona',
            importance: Importance.max,
            priority: Priority.high,
          ),
        ),
        androidScheduleMode: AndroidScheduleMode.exactAllowWhileIdle,
        uiLocalNotificationDateInterpretation: UILocalNotificationDateInterpretation.absoluteTime,
      );
      
      if (mounted) {
        ScaffoldMessenger.of(context).showSnackBar(
          SnackBar(content: Text('å·²è®¾ç½®æé†’: ${scheduledTime.month}/${scheduledTime.day} ${scheduledTime.hour}:${scheduledTime.minute}')),
        );
      }
    } catch (e) {
      debugPrint('Error scheduling notification: $e');
    }
  }

  Future<void> _loadPersonas() async {
    final prefs = await SharedPreferences.getInstance();
    final List<String>? saved = prefs.getStringList('personas');
    
    setState(() {
      if (saved != null && saved.isNotEmpty) {
        _personas = saved.map((e) => Persona.fromJson(json.decode(e))).toList();
      } else {
        _personas = [_defaultPersona];
      }
      
      _currentPersonaId = prefs.getString('current_persona_id') ?? _personas.first.id;
      
      // Validate current ID
      if (!_personas.any((p) => p.id == _currentPersonaId)) {
        _currentPersonaId = _personas.first.id;
      }
    });
  }

  Future<void> _savePersonas() async {
    final prefs = await SharedPreferences.getInstance();
    final List<String> data = _personas.map((p) => json.encode(p.toJson())).toList();
    await prefs.setStringList('personas', data);
    await prefs.setString('current_persona_id', _currentPersonaId);
  }

  Persona get _activePersona {
    return _personas.firstWhere(
      (p) => p.id == _currentPersonaId, 
      orElse: () => _defaultPersona
    );
  }

  Future<void> _switchPersona(String id) async {
    if (_currentPersonaId == id) return;
    
    // 1. Save current persona's history before switching
    await _saveChatHistory();

    setState(() {
      _currentPersonaId = id;
    });
    
    // 2. Load new persona's history (and inject global memory)
    await _loadChatHistory();
    
    // 3. Switch knowledge base to new persona
    await _knowledgeService.setPersona(id);
    
    // 4. Persist the switch
    await _savePersonas();
    
    // Optional: Add a system note if history is empty to indicate switch
    if (_messages.where((m) => !m.isMemory).isEmpty) {
      setState(() {
        _messages.add(ChatMessage('system', 'å·²åˆ‡æ¢äººæ ¼ä¸ºï¼š${_activePersona.name}'));
        _saveChatHistory();
      });
    }
  }


  Future<void> _loadChatHistory() async {
    final prefs = await SharedPreferences.getInstance();
    
    // 1. Load Global Memory (Shared across all personas)
    // Note: We no longer display Global Memory in the chat list directly.
    // It is loaded into a variable for system prompts.
    final memoryContent = prefs.getString('global_memory') ?? '';
    
    // 2. Load Persona Specific History
    // Migration: If specific history doesn't exist, check legacy 'chat_history' for default persona
    List<String>? historyStrings = prefs.getStringList('chat_history_$_currentPersonaId');
    if (historyStrings == null && _currentPersonaId == _defaultPersona.id) {
      historyStrings = prefs.getStringList('chat_history');
    }
    
    final List<ChatMessage> loadedMsgs = [];
    if (historyStrings != null) {
      for (var e in historyStrings) {
        try {
          final m = ChatMessage.fromJson(json.decode(e));
          if (!m.isMemory) {
            loadedMsgs.add(m);
          }
        } catch (err) {
          debugPrint('Error loading message: $err');
        }
      }
    }

    if (mounted) {
      setState(() {
        _messages.clear();
        // We do NOT add memoryMsg to _messages anymore to keep UI clean.
        // Instead, we store it in a separate state variable if needed, 
        // but for now we just rely on SharedPreferences or a member variable.
        // Let's add a member variable for runtime access.
        _globalMemoryCache = memoryContent;
        
        // Append Persona History
        _messages.addAll(loadedMsgs);
      });
      
      // 3. Restore Pending Clarification State (for session recovery)
      final pendingStr = prefs.getString('pending_clarification_$_currentPersonaId');
      if (pendingStr != null && pendingStr.isNotEmpty) {
        try {
          _pendingClarification = json.decode(pendingStr) as Map<String, dynamic>;
          debugPrint('Restored pending clarification state');
        } catch (e) {
          debugPrint('Failed to restore pending clarification: $e');
          _pendingClarification = null;
        }
      }
      
      // Scroll to bottom after loading
      WidgetsBinding.instance.addPostFrameCallback((_) {
        if (_scrollCtrl.hasClients) {
          _scrollCtrl.jumpTo(_scrollCtrl.position.maxScrollExtent);
        }
      });
    }
  }

  // Cache for Global Memory to avoid reading prefs constantly
  String _globalMemoryCache = '';
  String? _lastCompressionNote;

  Future<void> _saveChatHistory() async {
    try {
      final prefs = await SharedPreferences.getInstance();
      
      // 1. Save Global Memory
      // Since it's not in _messages, we rely on _globalMemoryCache being updated
      // whenever memory compression happens.
      if (_globalMemoryCache.isNotEmpty) {
        await prefs.setString('global_memory', _globalMemoryCache);
      }

      // 2. Save Persona Specific History (Exclude Memory Message)
      // We only save the actual conversation flow for this persona
      final history = _messages
          .where((m) => !m.isMemory)
          .map((m) => json.encode(m.toJson()))
          .toList();
      
      await prefs.setStringList('chat_history_$_currentPersonaId', history);
      
      // 3. Save Pending Clarification State (for session recovery)
      if (_pendingClarification != null) {
        await prefs.setString('pending_clarification_$_currentPersonaId', json.encode(_pendingClarification));
      } else {
        await prefs.remove('pending_clarification_$_currentPersonaId');
      }
    } catch (e) {
      debugPrint('Failed to save chat history: $e');
    }
  }

  Future<void> _loadSettings() async {
    final prefs = await SharedPreferences.getInstance();
    setState(() {
      _chatBase = prefs.getString('chat_base') ?? 'https://your-oneapi-host/v1';
      _chatKey = prefs.getString('chat_key') ?? '';
      _chatModel = prefs.getString('chat_model') ?? 'gpt-3.5-turbo';
      _summaryModel = prefs.getString('summary_model') ?? 'gpt-3.5-turbo';
      _enableStream = prefs.getBool('enable_stream') ?? true;

    _imgBase = prefs.getString('img_base') ?? 'https://your-oneapi-host/v1';
    _imgKey = prefs.getString('img_key') ?? '';
    _imgModel = prefs.getString('img_model') ?? 'dall-e-3';
    _useChatApiForImage = prefs.getBool('use_chat_api_for_image') ?? false;

    _visionBase = prefs.getString('vision_base') ?? 'https://your-oneapi-host/v1';
    _visionKey = prefs.getString('vision_key') ?? '';
    _visionModel = prefs.getString('vision_model') ?? 'gpt-4-vision-preview';
    _ocrBase = prefs.getString('ocr_base') ?? '';
    _ocrKey = prefs.getString('ocr_key') ?? '';
    _ocrModel = prefs.getString('ocr_model') ?? 'gpt-4o-mini';
    _deepReasoningMode = prefs.getBool('deep_reasoning_mode') ?? false;

      _routerBase = prefs.getString('router_base') ?? 'https://your-oneapi-host/v1';
      _routerKey = prefs.getString('router_key') ?? '';
      _routerModel = prefs.getString('router_model') ?? 'gpt-3.5-turbo';

      _profileBase = prefs.getString('profile_base') ?? 'https://your-oneapi-host/v1';
      _profileKey = prefs.getString('profile_key') ?? '';
      _profileModel = prefs.getString('profile_model') ?? 'gpt-3.5-turbo';
    });
  }

  /// æ·»åŠ æ¨ç†æ­¥éª¤å¹¶æ›´æ–° UI
  void _addReasoningStep(String step) {
    if (!mounted) return;
    debugPrint('[æ¨ç†] $step');
    setState(() {
      if (!_reasoningSteps.contains(step)) {
        _reasoningSteps.add(step);
      }
    });
  }

  Future<void> _pickImage() async {
    try {
      final XFile? image = await _picker.pickImage(source: ImageSource.gallery);
      if (image != null) {
        setState(() {
          _selectedImage = image;
        });
      }
    } catch (e) {
      _showError('é€‰æ‹©å›¾ç‰‡å¤±è´¥: $e');
    }
  }

  Future<void> _pickAndIngestFile() async {
    // Ensure knowledge base is initialized for current persona
    if (_knowledgeService.currentPersonaId != _currentPersonaId) {
      await _knowledgeService.setPersona(_currentPersonaId);
    }
    
    try {
      FilePickerResult? result = await FilePicker.platform.pickFiles(
        type: FileType.custom,
        allowedExtensions: [
          // Text & Documents
          'txt', 'md', 'markdown', 'rst', 'log', 'csv', 'tsv', 'pdf', 'docx',
          // Code - Common
          'json', 'xml', 'yaml', 'yml', 'toml', 'ini', 'cfg', 'conf',
          // Code - Web
          'html', 'htm', 'css', 'scss', 'sass', 'less', 'js', 'jsx', 'ts', 'tsx', 'vue', 'svelte',
          // Code - Backend
          'py', 'pyw', 'pyi', 'java', 'kt', 'kts', 'scala', 'groovy', 'go', 'rs', 'rb', 'php',
          // Code - Systems
          'c', 'cpp', 'cc', 'cxx', 'h', 'hpp', 'hxx', 'cs', 'fs', 'fsx',
          // Code - Mobile
          'swift', 'dart', 'm', 'mm',
          // Code - Shell & Scripts
          'sh', 'bash', 'zsh', 'fish', 'ps1', 'psm1', 'bat', 'cmd',
          // Code - Data & Query
          'sql', 'graphql', 'gql',
          // Code - Functional
          'hs', 'lhs', 'elm', 'clj', 'cljs', 'erl', 'ex', 'exs',
          // Code - Other
          'lua', 'r', 'pl', 'pm', 'tcl', 'awk', 'sed', 'vim',
          // Markup & Config
          'tex', 'bib', 'sty', 'cls',
          // Data formats
          'ndjson', 'jsonl', 'geojson',
        ],
      );

      if (result != null && result.files.single.path != null) {
        final file = File(result.files.single.path!);
        final filename = result.files.single.name;
        
        // Check size (raised limit to 50MB to allow larger documents)
        final size = await file.length();
        if (size > 50 * 1024 * 1024) {
          _showError('æ–‡ä»¶è¿‡å¤§ (é™åˆ¶50MB)');
          return;
        }

        setState(() {
          _sending = true;
          _showReasoningPanel = true;  // æ˜¾ç¤ºæ¨ç†é¢æ¿
          _reasoningSteps = [];
          _loadingStatus = 'æ­£åœ¨è¯»å–å¹¶ç´¢å¼•æ–‡ä»¶...';
        });
        
        _addReasoningStep('ğŸ“‚ å¼€å§‹å¤„ç†æ–‡ä»¶: $filename (${(size / 1024).toStringAsFixed(1)} KB)');

        try {
          final ext = filename.split('.').last.toLowerCase();
          String content;
          _addReasoningStep('ğŸ” å°è¯•è§£æ $ext æ ¼å¼...');
          try {
            content = await DocumentParser.readText(file, extension: ext);
            if (content.trim().isNotEmpty) {
              _addReasoningStep('âœ… æ–‡æœ¬è§£ææˆåŠŸ: ${content.length} å­—ç¬¦');
            }
          } catch (e) {
            _addReasoningStep('âŒ è§£æå¤±è´¥: $e');
            _showError('æ— æ³•è§£æ${ext.toUpperCase()} æ–‡ä»¶: $e');
            return;
          }
          
          if (content.trim().isEmpty) {
            // Fallback: OCR for scanned PDFs via OpenAI-compatible vision API
            if (ext == 'pdf') {
              _addReasoningStep('âš ï¸ æ–‡æœ¬è§£æä¸ºç©ºï¼Œå°è¯• OCR...');
              setState(() => _loadingStatus = 'æ–‡æœ¬æå–ä¸ºç©ºï¼Œæ­£åœ¨å°è¯• OCR...');
              try {
                final ocrText = await _runPdfOcr(file);
                if (ocrText != null && ocrText.trim().isNotEmpty) {
                  content = ocrText;
                } else {
                  _addReasoningStep('âŒ OCR æœªæå–åˆ°æ–‡æœ¬');
                  _showError('æ–‡ä»¶å†…å®¹ä¸ºç©ºï¼ŒOCR ä¹Ÿæœªèƒ½æå–æ–‡æœ¬');
                  return;
                }
              } catch (e) {
                _showError('æ–‡ä»¶å†…å®¹ä¸ºç©ºï¼ŒOCR å¤±è´¥: $e');
                return;
              }
            } else if (ext == 'docx') {
              _addReasoningStep('âŒ Word æ–‡æ¡£è§£æä¸ºç©º');
              _showError('Word æ–‡æ¡£è§£æä¸ºç©ºã€‚å¯èƒ½æ˜¯æ‰«æç‰ˆæ–‡æ¡£ï¼Œè¯·è½¬ä¸ºå›¾ç‰‡åä¸Šä¼ ä½¿ç”¨ OCRã€‚');
              return;
            } else {
              _addReasoningStep('âŒ æ–‡ä»¶å†…å®¹ä¸ºç©º');
              _showError('æ–‡ä»¶å†…å®¹ä¸ºç©ºï¼Œæˆ–æœªèƒ½æå–æ–‡æœ¬');
              return;
            }
          }
          
          _addReasoningStep('ğŸ“ æ­£åœ¨ç´¢å¼•åˆ°çŸ¥è¯†åº“...');
          await _knowledgeService.ingestFile(
            filename: filename,
            content: content,
            summarizer: (chunk) => _generateKnowledgeSummary(chunk, filename), // File-type aware summary
          );

          // Get stats for user feedback
          final stats = _knowledgeService.getStats();
          final fileInfo = _knowledgeService.files.where((f) => f.filename == filename).lastOrNull;
          final chunkCount = fileInfo?.chunks.length ?? 0;
          
          _addReasoningStep('âœ… ç´¢å¼•å®Œæˆ: $chunkCount ä¸ªçŸ¥è¯†å—');
          
          setState(() {
            _messages.add(ChatMessage('system', 
              'âœ… æ–‡ä»¶ "$filename" å·²æˆåŠŸç´¢å¼•åˆ°çŸ¥è¯†åº“ã€‚\n'
              'ğŸ“Š å…±åˆ‡åˆ†ä¸º $chunkCount ä¸ªçŸ¥è¯†å—\n'
              'ğŸ“š çŸ¥è¯†åº“ç°æœ‰ ${stats['fileCount']} ä¸ªæ–‡ä»¶ï¼Œ${stats['chunkCount']} ä¸ªçŸ¥è¯†å—\n'
              'ğŸ’¡ ç°åœ¨æ‚¨å¯ä»¥è¯¢é—®å…³äºè¯¥æ–‡ä»¶çš„å†…å®¹äº†ã€‚', 
              isMemory: true));
            _saveChatHistory();
          });
          
          _showSuccessSnackBar('æ–‡ä»¶ç´¢å¼•å®Œæˆ ($chunkCount å—)');
        } catch (e) {
          _addReasoningStep('âŒ å¤„ç†å¤±è´¥: $e');
          _showError('å¤„ç†æ–‡ä»¶å¤±è´¥: $e');
        } finally {
          setState(() {
            _sending = false;
            _loadingStatus = '';
            // ä¿æŒæ¨ç†é¢æ¿æ˜¾ç¤ºå‡ ç§’åè‡ªåŠ¨éšè—
            Future.delayed(const Duration(seconds: 3), () {
              if (mounted && !_sending) {
                setState(() {
                  _showReasoningPanel = false;
                });
              }
            });
          });
        }
      }
    } catch (e) {
      _showError('é€‰æ‹©æ–‡ä»¶å¤±è´¥: $e');
    }
  }

  // Button handler for manual image generation
  Future<void> _manualGenerateImage() async {
    final prompt = _inputCtrl.text.trim();
    if (prompt.isEmpty) {
      _showError('è¯·è¾“å…¥ç”Ÿå›¾æç¤ºè¯');
      return;
    }
    _inputCtrl.clear();
    await _performImageGeneration(prompt);
  }

  /// Returns the local path of the generated image on success, null on failure
  Future<String?> _performImageGeneration(String prompt, {bool addUserMessage = true, bool manageSendingState = true}) async {
    if (_imgBase.contains('your-oneapi-host') || _imgKey.isEmpty) {
      _showError('è¯·å…ˆé…ç½®ç”Ÿå›¾ API');
      _openSettings();
      return null;
    }

    if (manageSendingState) {
      setState(() {
        _sending = true;
      });
    }
    
    if (addUserMessage) {
      setState(() {
        _messages.add(ChatMessage('user', 'ğŸ¨ ç”Ÿå›¾æŒ‡ä»¤: $prompt'));
        _saveChatHistory();
      });
    }
    _scrollToBottom();

    try {
      final imageUrl = await fetchImageGenerationUrl(
        prompt: prompt,
        baseUrl: _imgBase,
        apiKey: _imgKey,
        model: _imgModel,
        useChatApi: _useChatApiForImage,
      );

      // Download and save locally to prevent URL expiry
      final localPath = await downloadAndSaveImage(imageUrl, StorageType.chatImage);

      setState(() {
        _messages.add(ChatMessage('assistant', 'å›¾ç‰‡ç”ŸæˆæˆåŠŸ\n$prompt', localImagePath: localPath));
        _saveChatHistory();
      });
      _scrollToBottom();
      
      return localPath; // Return path for tool chaining

    } catch (e) {
      _showError('ç”Ÿå›¾å¼‚å¸¸ï¼š$e');
      return null;
    } finally {
      if (manageSendingState) {
        setState(() => _sending = false);
      }
    }
  }

  Future<String> _smartCompress(String text) async {
    // If text is small enough, just return it (though this function is usually called when it's big)
    if (text.length < 1000) return text;

    // Chunking (10k chars)
    const int chunkSize = 10000;
    final chunks = <String>[];
    for (int i = 0; i < text.length; i += chunkSize) {
      int end = (i + chunkSize < text.length) ? i + chunkSize : text.length;
      chunks.add(text.substring(i, end));
    }

    final buffer = StringBuffer();
    for (var chunk in chunks) {
      // Summarize each chunk
      final summary = await _generateSummary(chunk, 0.5); // 50% compression target
      buffer.writeln(summary);
    }
    
    return buffer.toString();
  }

  /// Compress a history list into system summaries beforeå‘é€ç»™å¤§æ¨¡å‹ï¼Œä¿æŒé¡ºåºä¸ä¸Šé™æ§åˆ¶
  Future<List<ChatMessage>> _compressHistoryForTransport(
    List<ChatMessage> history, {
    required int targetChars,
    int keepTail = 4,
    int depth = 0,
  }) async {
    int total = history.fold(0, (p, c) => p + c.content.length);
    if (total <= targetChars) {
      if (depth == 0) _lastCompressionNote = null;
      return history;
    }

    // Keep the most recent messages intact
    keepTail = keepTail.clamp(2, history.length).toInt();
    final tail = history.sublist(history.length - keepTail);
    final older = history.sublist(0, history.length - keepTail);

    // Flatten older messages into chunks
    const int chunkSize = 8000;
    final List<String> chunkStrings = [];
    final buffer = StringBuffer();
    for (final m in older) {
      buffer.writeln('${m.role}: ${m.content}');
      if (buffer.length >= chunkSize) {
        chunkStrings.add(buffer.toString());
        buffer.clear();
      }
    }
    if (buffer.isNotEmpty) {
      chunkStrings.add(buffer.toString());
    }

    if (chunkStrings.isEmpty) return history;

    final totalOlderLen = chunkStrings.fold(0, (p, c) => p + c.length);
    if (totalOlderLen == 0) return history;
    // Desired ratio so that compressed older + tail ~= targetChars
    final desiredRatio = (targetChars * 0.9) / totalOlderLen;
    final double ratio = desiredRatio.clamp(0.2, 0.7).toDouble();

    final compressedMsgs = <ChatMessage>[];
    for (int i = 0; i < chunkStrings.length; i++) {
      final summary = await _generateSummary(chunkStrings[i], ratio);
      compressedMsgs.add(
        ChatMessage(
          'system',
          'ã€å‹ç¼©æ‘˜è¦ #${i + 1}/${chunkStrings.length} | ratio ${(ratio * 100).toInt()}%ã€‘\n$summary',
          isMemory: true,
          isCompressed: true,
          compressionRatio: ratio,
          originalLength: chunkStrings[i].length,
        ),
      );
    }

    final merged = [...compressedMsgs, ...tail];
    final mergedLen = merged.fold(0, (p, c) => p + c.content.length);

    if (depth == 0) {
      _lastCompressionNote =
          'ã€å‹ç¼©æç¤ºã€‘ä¸Šä¸‹æ–‡è¶…é™ï¼Œå·²å°†æ—©æœŸæ¶ˆæ¯åˆ†å—å‹ç¼©ä¸º ${chunkStrings.length} æ¡æ‘˜è¦ï¼Œå‹ç¼©æ¯”çº¦ ${(ratio * 100).toInt()}%ï¼Œä¿ç•™æœ€è¿‘ $keepTail æ¡åŸæ–‡ï¼›å¯èƒ½æœ‰ç»†èŠ‚ç¼ºå¤±ï¼Œå¦‚éœ€ç»†èŠ‚è¯·æ˜ç¡®æŒ‡å‡ºã€‚';
    }

    // If still too long, do one more pass with a slightly tighter ratio
    if (mergedLen > targetChars && compressedMsgs.isNotEmpty && depth < 2) {
      final tighterTarget = (targetChars * 0.8).toInt();
      return _compressHistoryForTransport(
        merged,
        targetChars: tighterTarget,
        keepTail: keepTail,
        depth: depth + 1,
      );
    }

    return merged;
  }

  Future<List<ChatMessage>> _ensureContextFits(List<ChatMessage> history, int limit) async {
    int total = history.fold(0, (p, c) => p + c.content.length);
    if (total <= limit) return history;

    // Keep last 2 messages always (User + Assistant usually) to maintain immediate context
    int keepCount = 2;
    if (history.length <= keepCount) {
       // Can't compress further without losing immediate context. 
       return history; 
    }

    List<ChatMessage> recent = history.sublist(history.length - keepCount);
    List<ChatMessage> older = history.sublist(0, history.length - keepCount);
    
    // Compress older
    String olderText = older.map((m) {
      // Handle previous summaries or system messages distinctly
      if (m.role == 'system') {
         return "ã€ç³»ç»Ÿ/å†å²ä¿¡æ¯ã€‘: ${m.content}";
      }
      return "${m.role}: ${m.content}";
    }).join("\n");
    
    // Recursive Compression
    // 1. Compress the older text
    String compressedOlder = await _smartCompress(olderText); 
    
    // 2. Create a summary message with explicit temporal marker
    ChatMessage summaryMsg = ChatMessage(
      'system', 
      'ã€å†å²å¯¹è¯æ‘˜è¦ã€‘\næ³¨æ„ï¼šä»¥ä¸‹å†…å®¹æ˜¯æ—©æœŸå¯¹è¯çš„å‹ç¼©è®°å½•ï¼Œå‘ç”Ÿåœ¨åç»­æ¶ˆæ¯ä¹‹å‰ã€‚\n$compressedOlder', 
      isMemory: true
    );
    
    List<ChatMessage> newList = [summaryMsg, ...recent];
    
    // 3. Check again (Recursion)
    // If the new list is still too big, we recurse.
    // Note: We need to be careful about infinite loops. 
    // If compression didn't reduce size (unlikely with LLM), we might loop.
    // But _smartCompress uses 0.5 ratio, so it should reduce.
    int newTotal = newList.fold(0, (p, c) => p + c.content.length);
    if (newTotal < total) { // Only recurse if we made progress
       return _ensureContextFits(newList, limit);
    } else {
       return newList; // Stop if we can't reduce further
    }
  }

  Future<void> _performChatRequest(String content, {String? localImage, List<ChatMessage>? historyOverride, bool manageSendingState = true, List<ReferenceItem>? references}) async {
    final isVision = localImage != null;
    final apiBase = isVision ? _visionBase : _chatBase;
    final apiKey = isVision ? _visionKey : _chatKey;
    final model = isVision ? _visionModel : _chatModel;

    if (apiBase.contains('your-oneapi-host') || apiKey.isEmpty) {
      _showError('è¯·å…ˆé…ç½® ${isVision ? "è¯†å›¾" : "èŠå¤©"} API');
      _openSettings();
      return;
    }

    // Inject Time into System Prompt
    final now = DateTime.now();
    final timeString = "${now.year}å¹´${now.month}æœˆ${now.day}æ—¥ ${now.hour}:${now.minute}";
    
    // Format References
    final refString = references != null ? _refManager.formatForLLM(references) : '';

    // Combine Global Rules + Active Persona Prompt + Time + Global Memory + References
    final timeAwareSystemPrompt = '''
$kGlobalHumanRules

ã€ç”¨æˆ·ç”»åƒ (User Profile)ã€‘
(è¿™æ˜¯ä½ å¯¹å±å¹•å¯¹é¢è¿™ä¸ªäººçš„æ·±åº¦äº†è§£ã€‚è¯·åˆ©ç”¨è¿™äº›ä¿¡æ¯æ¥è°ƒæ•´ä½ çš„è¯­æ°”ã€ç”¨è¯å’Œå›ç­”ç­–ç•¥ï¼Œä½¿å…¶æœ€è´´åˆç”¨æˆ·çš„ä¸ªæ€§ä¸éœ€æ±‚ã€‚)
${_globalMemoryCache.isEmpty ? "æš‚æ— ç”»åƒï¼Œè¯·é€šè¿‡å¯¹è¯é€æ­¥äº†è§£ç”¨æˆ·ã€‚" : _globalMemoryCache}

ã€å½“å‰äººæ ¼è®¾å®š (æœ€é«˜ä¼˜å…ˆçº§)ã€‘
è¯·å®Œå…¨æ²‰æµ¸åœ¨ä»¥ä¸‹è§’è‰²ä¸­ã€‚ä½ çš„æ‰€æœ‰å›ç­”ã€è¯­æ°”ã€æ€è€ƒæ–¹å¼å¿…é¡»ä¸¥æ ¼éµå¾ªæ­¤è®¾å®šã€‚
å¦‚æœå…¨å±€æŒ‡ä»¤ä¸æ­¤è®¾å®šå†²çªï¼Œä»¥ã€å½“å‰äººæ ¼è®¾å®šã€‘ä¸ºå‡†ã€‚
${_activePersona.prompt}

ã€å½“å‰æ—¶é—´ã€‘
$timeString

$refString

ã€å¯¹è¯é€æ˜åº¦ã€‘
- è‹¥ä½ æ„Ÿåˆ°ä¸Šä¸‹æ–‡è¢«å‹ç¼©ã€ä¿¡æ¯ç¼ºå¤±æˆ–éœ€è¦ç”¨æˆ·è¡¥å……ï¼Œè¯·ç›´æ¥åœ¨å›å¤é‡Œè¯´æ˜ç¼ºå£å¹¶æå‡ºå…·ä½“é—®é¢˜ã€‚
- å·¥å…·æ€§è°ƒç”¨ï¼ˆæœç´¢/ç”Ÿå›¾/è¯†å›¾ï¼‰æ— éœ€èµ˜è¿°ç»†èŠ‚ï¼Œä½†è¯·åœ¨æœ€ç»ˆå›ç­”ä¸­æç¤ºå“ªäº›éƒ¨åˆ†ä¾èµ–äº†è¿™äº›å·¥å…·æˆ–å› æœªé…ç½®è€Œç¼ºå¤±ã€‚
- å¦‚æœå·²æœ‰ç³»ç»Ÿæç¤ºè¯´æ˜â€œå‹ç¼©/ç¼ºå°‘ä¿¡æ¯â€ï¼Œè¯·ç»“åˆè¯¥æç¤ºï¼Œç»§ç»­è¿½é—®å…³é”®ç»†èŠ‚è€Œä¸æ˜¯æ²‰é»˜ã€‚
''';

    if (manageSendingState) {
      setState(() {
        _sending = true;
      });
    }
    _scrollToBottom();

    try {
      // Normalize URL - only remove trailing slashes, respect user's path configuration
      String cleanBase = apiBase.replaceAll(RegExp(r'/+$'), '');
      final uri = Uri.parse('$cleanBase/chat/completions');
      
      Object messagesPayload;
      
      if (localImage != null) {
        final bytes = await File(localImage).readAsBytes();
        final base64Image = base64Encode(bytes);
        
        messagesPayload = [
          {'role': 'system', 'content': timeAwareSystemPrompt},
          ..._messages.map((m) {
            String content = m.content;
            if (content.isEmpty && (m.imageUrl != null || m.localImagePath != null)) {
              content = "[å›¾ç‰‡]";
            }
            return {'role': m.role, 'content': content};
          }).where((m) => m['content'].toString().isNotEmpty),
          {
            'role': 'user',
            'content': [
              {'type': 'text', 'text': content.isEmpty ? 'Describe this image' : content},
              {
                'type': 'image_url',
                'image_url': {
                  'url': 'data:image/jpeg;base64,$base64Image'
                }
              }
            ]
          }
        ];
      } else {
        // For normal chat, we send the history
        // Use historyOverride if provided, otherwise use current _messages
        var historyToUse = historyOverride ?? _messages;

        // Enforce Context Limit using workerå‹ç¼©ï¼Œå¤šæ¬¡è°ƒç”¨ summary æ¨¡å‹ï¼Œä¿ç•™å°¾éƒ¨åŸæ–‡
        const int chatContextCap = 60000;
        if (historyToUse.fold(0, (sum, m) => sum + m.content.length) > chatContextCap) {
          if (manageSendingState) {
            setState(() => _loadingStatus = 'ä¸Šä¸‹æ–‡è¿‡é•¿ï¼Œæ­£åœ¨åˆ†å—å‹ç¼©...');
          }
          historyToUse = await _compressHistoryForTransport(
            historyToUse,
            targetChars: chatContextCap,
            keepTail: 6,
          );
        }

        final compressionNote = _lastCompressionNote;
        _lastCompressionNote = null; // reset

        messagesPayload = [
          {'role': 'system', 'content': timeAwareSystemPrompt},
          if (compressionNote != null)
            {'role': 'system', 'content': compressionNote},
          ...historyToUse.map((m) {
            String msgContent = m.content;
            if (msgContent.isEmpty && (m.imageUrl != null || m.localImagePath != null)) {
              msgContent = "[å›¾ç‰‡]";
            }
            return {'role': m.role, 'content': msgContent};
          }).where((m) => m['content'].toString().isNotEmpty)
        ];

        if (compressionNote != null && manageSendingState) {
          _showError(compressionNote);
        }
      }

      final body = json.encode({
        'model': model,
        'messages': messagesPayload,
        'stream': _enableStream,
        'max_tokens': 60000,
      });

      if (_enableStream) {
        // Streaming Logic
        final request = http.Request('POST', uri);
        request.headers.addAll({
          'Authorization': 'Bearer $apiKey',
          'Content-Type': 'application/json',
        });
        request.body = body;

        // Add placeholder message
        setState(() {
          _messages.add(ChatMessage('assistant', '', references: references));
        });
        _scrollToBottom();

        final streamedResponse = await http.Client().send(request).timeout(const Duration(minutes: 5));

        if (streamedResponse.statusCode == 200) {
          String fullContent = '';
          String? finishReason;
          await for (final line in streamedResponse.stream.transform(utf8.decoder).transform(const LineSplitter())) {
            if (line.startsWith('data: ')) {
              final data = line.substring(6).trim();
              if (data == '[DONE]') break;
              try {
                final jsonVal = json.decode(data);
                final delta = jsonVal['choices']?[0]?['delta']?['content'];
                finishReason = jsonVal['choices']?[0]?['finish_reason'] ?? finishReason;
                if (delta != null) {
                  fullContent += delta;
                  setState(() {
                    // Update last message content
                    final lastMsg = _messages.last;
                    _messages[_messages.length - 1] = ChatMessage(
                      lastMsg.role,
                      fullContent,
                      references: lastMsg.references,
                      imageUrl: lastMsg.imageUrl,
                      localImagePath: lastMsg.localImagePath,
                    );
                  });
                  // Optional: Throttle scrolling if needed
                }
              } catch (e) {
                // ignore parse error
              }
            }
          }
          _saveChatHistory();
          // Check if output was truncated due to token limit
          if (finishReason == 'length') {
            _showError('âš ï¸ è¾“å‡ºè¢«æœåŠ¡ç«¯æˆªæ–­ (finish_reason: length)ï¼Œå›å¤å¯èƒ½ä¸å®Œæ•´');
          }
          // _checkAndCompressMemory(); // Removed auto-compress as per user request
        } else {
           // Stream request failed, remove placeholder
           setState(() {
             _messages.removeLast();
           });
           _showError('Stream Error: ${streamedResponse.statusCode}');
        }

      } else {
        // Non-Streaming Logic (Legacy)
        final resp = await http.post(
          uri,
          headers: {
            'Authorization': 'Bearer $apiKey',
            'Content-Type': 'application/json',
          },
          body: body,
        ).timeout(const Duration(minutes: 5));

        if (resp.statusCode == 200) {
          final decodedBody = utf8.decode(resp.bodyBytes);
          final data = json.decode(decodedBody);
          final reply = data['choices'][0]['message']['content'] ?? '';
          final finishReason = data['choices']?[0]?['finish_reason'];
          setState(() {
            _messages.add(ChatMessage(
              'assistant', 
              reply.toString(),
              references: references, // Pass references to UI
            ));
            _saveChatHistory();
          });
          _scrollToBottom();
          
          // Check if output was truncated
          if (finishReason == 'length') {
            _showError('âš ï¸ è¾“å‡ºè¢«æœåŠ¡ç«¯æˆªæ–­ (finish_reason: length)ï¼Œå›å¤å¯èƒ½ä¸å®Œæ•´');
          }
          // _checkAndCompressMemory(); // Removed auto-compress as per user request

        } else {
          _showError('å‘é€å¤±è´¥ï¼š${resp.statusCode} ${resp.reasonPhrase}');
        }
      }
    } catch (e) {
      _showError('å‘é€å¼‚å¸¸ï¼š$e');
    } finally {
      if (manageSendingState) {
        setState(() => _sending = false);
      }
    }
  }

  // New: Archive all active messages that haven't been archived yet
  Future<void> _archiveAllActiveMessages() async {
    try {
      final dir = await getApplicationDocumentsDirectory();
      final file = File('${dir.path}/chat_archive.jsonl');
      final sink = file.openWrite(mode: FileMode.append);
      
      bool hasUpdates = false;
      for (int i = 0; i < _messages.length; i++) {
        final m = _messages[i];
        if (!m.isArchived) {
          final jsonMap = m.toJson();
          // Add Indexing Metadata
          jsonMap['archived_at'] = DateTime.now().toIso8601String();
          jsonMap['persona_id'] = _currentPersonaId;
          jsonMap['sequence_id'] = DateTime.now().microsecondsSinceEpoch; // Simple sequence
          
          sink.writeln(json.encode(jsonMap));
          
          // Update state to mark as archived
          _messages[i] = m.copyWith(isArchived: true);
          hasUpdates = true;
        }
      }
      
      await sink.flush();
      await sink.close();
      
      if (hasUpdates) {
        _saveChatHistory();
      }
    } catch (e) {
      debugPrint('Archive error: $e');
    }
  }

  // New: Adaptive Compression Logic with Multi-Pass Support
  Future<void> _performAdaptiveCompression() async {
    if (_messages.isEmpty) return;
    
    setState(() {
      _loadingStatus = 'æ­£åœ¨å½’æ¡£å¹¶å‹ç¼©è®°å¿†...';
      _sending = true;
    });

    // 1. Archive everything first (Safety & Profiling Source)
    await _archiveAllActiveMessages();

    // 2. Calculate current total to decide compression strategy
    int currentTotal = _messages.fold(0, (sum, m) => sum + m.content.length);
    debugPrint('Compression started. Current total: $currentTotal chars');

    // 3. Adaptive Summarization with Multi-Pass Support
    // Strategy:
    // - Recent messages (last 5): Keep 60-80% detail
    // - Older messages: Aggressively compress to 15-30%
    // - Already compressed messages: Can be re-compressed if still too long
    
    try {
      int compressedCount = 0;
      int mergedCount = 0;

      // Phase 1: Individual message compression
      for (int i = 0; i < _messages.length; i++) {
        final indexFromEnd = _messages.length - 1 - i;
        
        // Determine target ratio based on recency
        double targetRatio;
        if (indexFromEnd <= 2) {
          targetRatio = 0.8; // Very recent: keep 80%
        } else if (indexFromEnd <= 5) {
          targetRatio = 0.5; // Recent: keep 50%
        } else if (indexFromEnd <= 10) {
          targetRatio = 0.3; // Older: keep 30%
        } else {
          targetRatio = 0.15; // Very old: keep 15%
        }
        
        // Skip system messages or images
        if (_messages[i].role == 'system' || _messages[i].imageUrl != null || _messages[i].localImagePath != null) {
           continue;
        }

        final currentContent = _messages[i].content;
        final currentRatio = _messages[i].compressionRatio;
        final originalLen = _messages[i].originalLength ?? currentContent.length;
        
        // If text is short, don't compress
        if (currentContent.length < 80) continue;

        // Allow re-compression if:
        // 1. Never compressed, OR
        // 2. Current ratio is higher than target (can compress more), OR
        // 3. Content is still long (> 500 chars) and current ratio > target * 0.7
        bool shouldCompress = currentRatio == null ||
            currentRatio > targetRatio ||
            (currentContent.length > 500 && currentRatio > targetRatio * 0.7);
        
        if (!shouldCompress) continue;

        setState(() => _loadingStatus = 'å‹ç¼©æ¶ˆæ¯ ${i + 1}/${_messages.length}...');

        final summary = await _generateSummary(currentContent, targetRatio);
        
        // Only accept if actually shorter (compression worked)
        if (summary.length < currentContent.length * 0.95) {
          final actualRatio = summary.length / originalLen;
          setState(() {
            _messages[i] = _messages[i].copyWith(
              content: summary,
              isCompressed: true,
              originalLength: originalLen,
              compressionRatio: actualRatio,
            );
          });
          compressedCount++;
        } else {
          debugPrint('Compression did not reduce size for message $i, skipping');
        }
      }

      // Phase 2: Merge very old short messages into summary blocks
      // This handles the case where many small messages accumulate
      currentTotal = _messages.fold(0, (sum, m) => sum + m.content.length);
      if (currentTotal > 50000 && _messages.length > 15) { // ç”¨æˆ·APIæ”¯æŒ60K tokens
        setState(() => _loadingStatus = 'åˆå¹¶å†å²æ¶ˆæ¯å—...');
        
        // Find consecutive older messages (not in last 10) that can be merged
        final mergeCandidates = <int>[];
        for (int i = 0; i < _messages.length - 10; i++) {
          if (_messages[i].role != 'system' && 
              _messages[i].imageUrl == null && 
              _messages[i].localImagePath == null) {
            mergeCandidates.add(i);
          }
        }
        
        // Merge in chunks of 5
        if (mergeCandidates.length >= 5) {
          for (int start = 0; start < mergeCandidates.length - 4; start += 5) {
            final chunk = mergeCandidates.sublist(start, (start + 5).clamp(0, mergeCandidates.length));
            if (chunk.length < 3) continue;
            
            // Combine content
            final combined = chunk.map((idx) => '${_messages[idx].role}: ${_messages[idx].content}').join('\n');
            if (combined.length < 200) continue; // Not worth merging
            
            // Summarize the combined block
            final blockSummary = await _generateSummary(combined, 0.2);
            
            if (blockSummary.length < combined.length * 0.5) {
              // Replace first message in chunk with summary, mark others for removal
              final firstIdx = chunk.first;
              setState(() {
                _messages[firstIdx] = ChatMessage(
                  'system',
                  'ã€å†å²æ‘˜è¦ã€‘\n$blockSummary',
                  isMemory: true,
                  isCompressed: true,
                  compressionRatio: 0.2,
                );
                // Mark other messages in chunk as empty (will be filtered later)
                for (int j = 1; j < chunk.length; j++) {
                  _messages[chunk[j]] = _messages[chunk[j]].copyWith(content: '');
                }
              });
              mergedCount++;
            }
          }
          
          // Remove empty messages
          setState(() {
            _messages.removeWhere((m) => m.content.isEmpty && m.imageUrl == null && m.localImagePath == null);
          });
        }
      }
      
      _saveChatHistory();
      
      final newTotal = _messages.fold(0, (sum, m) => sum + m.content.length);
      _showError('å‹ç¼©å®Œæˆ! $compressedCountæ¡æ¶ˆæ¯å‹ç¼©, $mergedCountå—åˆå¹¶. æ€»å­—ç¬¦: $currentTotal â†’ $newTotal');

    } catch (e) {
      _showError('å‹ç¼©å¤±è´¥: $e');
    } finally {
      setState(() {
        _loadingStatus = '';
        _sending = false;
      });
    }
  }

  /// Get Worker API config with fallback chain: Worker -> Worker Pro -> Router -> Chat
  Future<({String base, String key, String model})> _getWorkerConfig() async {
    final prefs = await SharedPreferences.getInstance();
    
    // Helper to check if URL is valid (not placeholder)
    bool isValidUrl(String url) {
      return url.isNotEmpty && 
             !url.contains('your-oneapi-host') && 
             !url.contains('your-api-host');
    }
    
    // Get user's configured chat model as ultimate fallback
    final userChatModel = prefs.getString('chat_model') ?? '';
    
    // Try Worker first (execution tasks)
    final workerBase = prefs.getString('worker_base') ?? '';
    final workerKeys = prefs.getString('worker_keys') ?? '';
    final workerModel = prefs.getString('worker_model') ?? '';
    
    if (isValidUrl(workerBase) && workerKeys.isNotEmpty) {
      final firstKey = workerKeys.split(',').map((k) => k.trim()).where((k) => k.isNotEmpty).firstOrNull ?? '';
      if (firstKey.isNotEmpty) {
        // Use configured model, or fallback to user's chat model
        return (base: workerBase, key: firstKey, model: workerModel.isNotEmpty ? workerModel : (userChatModel.isNotEmpty ? userChatModel : 'gpt-4o-mini'));
      }
    }
    
    // Try Worker Pro (thinking tasks like summarization)
    final workerProBase = prefs.getString('worker_pro_base') ?? '';
    final workerProKeys = prefs.getString('worker_pro_keys') ?? '';
    final workerProModel = prefs.getString('worker_pro_model') ?? '';
    
    if (isValidUrl(workerProBase) && workerProKeys.isNotEmpty) {
      final firstKey = workerProKeys.split(',').map((k) => k.trim()).where((k) => k.isNotEmpty).firstOrNull ?? '';
      if (firstKey.isNotEmpty) {
        return (base: workerProBase, key: firstKey, model: workerProModel.isNotEmpty ? workerProModel : (userChatModel.isNotEmpty ? userChatModel : 'gpt-4o-mini'));
      }
    }
    
    // Fallback to Router API
    if (isValidUrl(_routerBase) && _routerKey.isNotEmpty) {
      return (base: _routerBase, key: _routerKey, model: _routerModel.isNotEmpty ? _routerModel : (userChatModel.isNotEmpty ? userChatModel : 'gpt-4o-mini'));
    }
    
    // Final fallback to Chat API
    final effectiveBase = isValidUrl(_chatBase) ? _chatBase : 'https://api.openai.com/v1';
    return (base: effectiveBase, key: _chatKey, model: _summaryModel.isNotEmpty ? _summaryModel : (userChatModel.isNotEmpty ? userChatModel : 'gpt-4o-mini'));
  }

  Future<String> _generateSummary(String text, double ratio) async {
    // Use Worker config with fallback chain
    final config = await _getWorkerConfig();
    final double effectiveRatio = ratio.clamp(0.2, 0.7).toDouble();
    
    final prompt = '''
Please summarize the following text to retain approximately ${(effectiveRatio * 100).toInt()}% of the original information density (never compress beyond 20%).
Focus on key facts, decisions, and order of events.
Original Text:
$text
''';

    try {
      // Normalize base URL - only remove trailing slashes, respect user's path
      String apiEndpoint = config.base.replaceAll(RegExp(r'/+$'), '');
      apiEndpoint = '$apiEndpoint/chat/completions';
      
      final uri = Uri.parse(apiEndpoint);
      final body = json.encode({
        'model': config.model,
        'messages': [
          {'role': 'system', 'content': 'You are a concise summarizer.'},
          {'role': 'user', 'content': prompt}
        ],
        'stream': false,
      });

      final resp = await http.post(
        uri,
        headers: {
          'Authorization': 'Bearer ${config.key}',
          'Content-Type': 'application/json',
        },
        body: body,
      ).timeout(const Duration(minutes: 5));

      if (resp.statusCode == 200) {
        final decodedBody = utf8.decode(resp.bodyBytes);
        final data = json.decode(decodedBody);
        return data['choices'][0]['message']['content'] ?? text;
      } else {
        debugPrint('Summary API error: ${resp.statusCode} - ${resp.body}');
      }
    } catch (e) {
      debugPrint('Summary failed: $e');
    }
    return text; // Fallback
  }

  /// OCR a file (PDF or image) using an OpenAI-compatible vision/chat endpoint
  /// For PDF: Attempts direct PDF OCR first, falls back to page-by-page image conversion
  /// For images: Sends directly with appropriate mime type
  Future<String?> _runPdfOcr(File file, {String? prompt}) async {
    // Use dedicated OCR config only
    if (_ocrBase.isEmpty || _ocrKey.isEmpty || _ocrBase.contains('your-oneapi-host')) {
      debugPrint('OCR skipped: no OCR API configured');
      _addReasoningStep('OCR è·³è¿‡: æœªé…ç½® OCR API');
      return null;
    }
    final base = _ocrBase;
    final key = _ocrKey;
    final model = _ocrModel;
    
    final ext = file.path.toLowerCase().split('.').last;
    _addReasoningStep('å¼€å§‹ OCR å¤„ç†: ${file.path.split('/').last} (ç±»å‹: $ext, æ¨¡å‹: $model)');

    final cleanBase = base.replaceAll(RegExp(r'/+$'), '');
    final uri = Uri.parse('$cleanBase/chat/completions');
    final bytes = await file.readAsBytes();
    
    final userPrompt = prompt ??
        '<image>\n<|grounding|>Convert the document to markdown. Output in Chinese if the content is Chinese.';

    // Helper function to send OCR request
    Future<http.Response> sendOcrRequest(String dataUrl) async {
      final body = json.encode({
        'model': model,
        'messages': [
          {
            'role': 'user',
            'content': [
              {
                'type': 'image_url',
                'image_url': {'url': dataUrl}
              },
              {'type': 'text', 'text': userPrompt}
            ]
          }
        ],
        'stream': false,
      });

      return await http.post(
        uri,
        headers: {
          'Authorization': 'Bearer $key',
          'Content-Type': 'application/json',
        },
        body: body,
      ).timeout(const Duration(minutes: 3));
    }
    
    // Helper function to extract text from OCR response
    String? extractOcrText(http.Response resp) {
      if (resp.statusCode == 200) {
        final data = json.decode(utf8.decode(resp.bodyBytes));
        return data['choices']?[0]?['message']?['content']?.toString();
      }
      return null;
    }

    // For images, send directly
    if (ext != 'pdf') {
      String mimeType;
      switch (ext) {
        case 'png': mimeType = 'image/png'; break;
        case 'jpg':
        case 'jpeg': mimeType = 'image/jpeg'; break;
        case 'gif': mimeType = 'image/gif'; break;
        case 'webp': mimeType = 'image/webp'; break;
        default: mimeType = 'image/png';
      }
      
      final b64 = base64Encode(bytes);
      _addReasoningStep('å›¾ç‰‡å¤§å°: ${(bytes.length / 1024).toStringAsFixed(1)} KB');
      
      final resp = await sendOcrRequest('data:$mimeType;base64,$b64');
      final text = extractOcrText(resp);
      if (text != null && text.isNotEmpty) {
        _addReasoningStep('OCR æˆåŠŸï¼Œæå–åˆ° ${text.length} å­—ç¬¦');
        return text;
      }
      
      if (resp.statusCode != 200) {
        throw Exception('OCR API é”™è¯¯ ${resp.statusCode}: ${resp.body}');
      }
      return null;
    }
    
    // For PDF: Try direct first, then page-by-page
    _addReasoningStep('PDF æ–‡ä»¶: ${(bytes.length / 1024).toStringAsFixed(1)} KB');
    
    // Attempt 1: Try direct PDF OCR
    _addReasoningStep('å°è¯•ç›´æ¥ PDF OCR...');
    final b64 = base64Encode(bytes);
    var resp = await sendOcrRequest('data:application/pdf;base64,$b64');
    
    if (resp.statusCode == 200) {
      final text = extractOcrText(resp);
      if (text != null && text.isNotEmpty) {
        _addReasoningStep('ç›´æ¥ PDF OCR æˆåŠŸï¼Œæå–åˆ° ${text.length} å­—ç¬¦');
        return text;
      }
    }
    
    // Attempt 2: Convert PDF pages to images and OCR each
    if (resp.statusCode == 400 || resp.statusCode == 422 || extractOcrText(resp)?.isEmpty == true) {
      _addReasoningStep('ç›´æ¥ PDF OCR å¤±è´¥ï¼Œå°è¯•é€é¡µè½¬å›¾ç‰‡...');
      
      try {
        // Open PDF document
        final pdfDoc = await pdf_render.PdfDocument.openData(bytes);
        final pageCount = pdfDoc.pageCount;
        _addReasoningStep('PDF å…± $pageCount é¡µï¼Œå¼€å§‹é€é¡µ OCR...');
        
        final allText = StringBuffer();
        int successPages = 0;
        
        // Process each page (limit to first 10 pages for performance)
        final maxPages = pageCount > 10 ? 10 : pageCount;
        
        for (int i = 1; i <= maxPages; i++) {
          try {
            _addReasoningStep('å¤„ç†ç¬¬ $i/$pageCount é¡µ...');
            
            final page = await pdfDoc.getPage(i);
            // Render at 150 DPI for good quality/size balance
            const scale = 150.0 / 72.0;
            final width = (page.width * scale).toInt();
            final height = (page.height * scale).toInt();
            
            final pageImage = await page.render(
              width: width,
              height: height,
              fullWidth: width.toDouble(),
              fullHeight: height.toDouble(),
            );
            
            // Convert RGBA pixels to PNG
            final image = img.Image.fromBytes(
              width: pageImage.width,
              height: pageImage.height,
              bytes: pageImage.pixels.buffer,
              numChannels: 4,
            );
            final pngBytes = img.encodePng(image);
            final pageB64 = base64Encode(pngBytes);
            
            // OCR this page
            final pageResp = await sendOcrRequest('data:image/png;base64,$pageB64');
            final pageText = extractOcrText(pageResp);
            
            if (pageText != null && pageText.isNotEmpty) {
              successPages++;
              if (pageCount > 1) {
                allText.writeln('\n--- ç¬¬ $i é¡µ ---\n');
              }
              allText.writeln(pageText);
            }
          } catch (pageError) {
            debugPrint('Page $i OCR error: $pageError');
            _addReasoningStep('ç¬¬ $i é¡µå¤„ç†å¤±è´¥: $pageError');
          }
        }
        
        pdfDoc.dispose();
        
        if (maxPages < pageCount) {
          allText.writeln('\n--- (ä»…å¤„ç†äº†å‰ $maxPages é¡µï¼Œå…± $pageCount é¡µ) ---');
          _addReasoningStep('âš ï¸ PDF è¾ƒé•¿ï¼Œä»…å¤„ç†äº†å‰ $maxPages é¡µ');
        }
        
        if (successPages > 0) {
          final result = allText.toString().trim();
          _addReasoningStep('âœ… PDF OCR å®Œæˆ: $successPages é¡µæˆåŠŸï¼Œæå– ${result.length} å­—ç¬¦');
          return result;
        } else {
          throw Exception('PDF æ‰€æœ‰é¡µé¢ OCR éƒ½å¤±è´¥äº†');
        }
        
      } catch (pdfError) {
        _addReasoningStep('PDF æ‹†åˆ† OCR å¤±è´¥: $pdfError');
        throw Exception('PDF OCR å¤±è´¥: $pdfError\n\nå»ºè®®: å°è¯•æˆªå›¾ PDF é¡µé¢åä¸Šä¼ ã€‚');
      }
    }
    
    // Other errors
    String errorDetail = resp.body;
    try {
      final errorJson = json.decode(resp.body);
      if (errorJson['error'] != null) {
        errorDetail = errorJson['error']['message'] ?? errorJson['error'].toString();
      }
    } catch (_) {}
    
    _addReasoningStep('OCR å¤±è´¥: HTTP ${resp.statusCode} - $errorDetail');
    throw Exception('OCR API é”™è¯¯ ${resp.statusCode}: $errorDetail');
  }

  /// OCR for images (png/jpg/etc) - simplified version for Agent tool
  /// Supports both local files and data URLs
  Future<String?> _runImageOcr(File imageFile, {String? prompt}) async {
    if (_ocrBase.isEmpty || _ocrKey.isEmpty || _ocrBase.contains('your-oneapi-host')) {
      throw Exception('OCR API æœªé…ç½®');
    }
    
    final bytes = await imageFile.readAsBytes();
    final ext = imageFile.path.toLowerCase().split('.').last;
    
    // Determine MIME type
    String mimeType;
    switch (ext) {
      case 'png': mimeType = 'image/png'; break;
      case 'jpg':
      case 'jpeg': mimeType = 'image/jpeg'; break;
      case 'gif': mimeType = 'image/gif'; break;
      case 'webp': mimeType = 'image/webp'; break;
      case 'bmp': mimeType = 'image/bmp'; break;
      default: mimeType = 'image/png'; // Default to PNG
    }
    
    final b64 = base64Encode(bytes);
    final dataUrl = 'data:$mimeType;base64,$b64';
    
    final cleanBase = _ocrBase.replaceAll(RegExp(r'/+$'), '');
    final uri = Uri.parse('$cleanBase/chat/completions');
    
    final userPrompt = prompt ?? '<|grounding|>OCR this image. Extract all visible text.';
    
    final body = json.encode({
      'model': _ocrModel,
      'messages': [
        {
          'role': 'user',
          'content': [
            {
              'type': 'image_url',
              'image_url': {
                'url': dataUrl,
              }
            },
            {'type': 'text', 'text': userPrompt}
          ]
        }
      ],
      'stream': false,
    });

    final resp = await http.post(
      uri,
      headers: {
        'Authorization': 'Bearer $_ocrKey',
        'Content-Type': 'application/json',
      },
      body: body,
    ).timeout(const Duration(minutes: 2));

    if (resp.statusCode == 200) {
      final data = json.decode(utf8.decode(resp.bodyBytes));
      final content = data['choices']?[0]?['message']?['content']?.toString() ?? '';
      return content.isNotEmpty ? content : null;
    }

    // Parse error for better message
    String errorDetail = resp.body;
    try {
      final errorJson = json.decode(resp.body);
      if (errorJson['error'] != null) {
        errorDetail = errorJson['error']['message'] ?? errorJson['error'].toString();
      }
    } catch (_) {}
    
    throw Exception('OCR API é”™è¯¯ ${resp.statusCode}: $errorDetail');
  }

  /// Generate file-type aware summary for knowledge base indexing
  Future<String> _generateKnowledgeSummary(String chunk, String filename) async {
    final config = await _getWorkerConfig();
    final ext = filename.toLowerCase().split('.').last;
    
    // Determine file type and appropriate prompt
    String typeHint;
    String extractionFocus;
    
    // Code files
    if (['dart', 'py', 'js', 'ts', 'jsx', 'tsx', 'java', 'kt', 'swift', 'go', 'rs', 'rb', 'php', 'c', 'cpp', 'cs', 'scala'].contains(ext)) {
      typeHint = 'This is SOURCE CODE';
      extractionFocus = '''Extract and list:
1. Class/Function/Method names with their purpose (one line each)
2. Key imports/dependencies
3. Main logic flow or algorithm summary
4. Important variables/constants
Format: Use bullet points. Be technical and precise.''';
    }
    // Config/Data files
    else if (['json', 'yaml', 'yml', 'toml', 'xml', 'ini', 'cfg', 'conf'].contains(ext)) {
      typeHint = 'This is a CONFIGURATION/DATA file';
      extractionFocus = '''Extract and list:
1. Top-level keys/sections
2. Important configuration values
3. Data structure overview
4. Any URLs, paths, or credentials (redact sensitive values)
Format: Hierarchical bullet points showing structure.''';
    }
    // Documentation/Text
    else if (['md', 'markdown', 'rst', 'txt', 'log', 'pdf', 'docx'].contains(ext)) {
      typeHint = 'This is DOCUMENTATION/TEXT';
      extractionFocus = '''Extract and list:
1. Main topics/headings
2. Key concepts or definitions
3. Important conclusions or action items
4. Any code examples or commands mentioned
Format: Concise bullet points preserving key information.''';
    }
    // Data files
    else if (['csv', 'tsv', 'ndjson', 'jsonl'].contains(ext)) {
      typeHint = 'This is TABULAR/STRUCTURED DATA';
      extractionFocus = '''Extract and list:
1. Column names/field names
2. Data types for each column
3. Sample values (first 2-3 rows)
4. Total approximate row count if visible
Format: Table-like description.''';
    }
    // SQL/Query
    else if (['sql', 'graphql', 'gql'].contains(ext)) {
      typeHint = 'This is DATABASE/QUERY code';
      extractionFocus = '''Extract and list:
1. Table/Collection names involved
2. Query types (SELECT, INSERT, CREATE, etc.)
3. Key conditions/filters
4. Joins or relationships
Format: Technical bullet points.''';
    }
    // Web files
    else if (['html', 'htm', 'vue', 'svelte'].contains(ext)) {
      typeHint = 'This is WEB MARKUP/COMPONENT';
      extractionFocus = '''Extract and list:
1. Page/Component structure
2. Key elements (forms, buttons, sections)
3. Any embedded scripts or styles
4. Data bindings or props
Format: Structural outline.''';
    }
    // Shell/Scripts
    else if (['sh', 'bash', 'ps1', 'bat', 'cmd'].contains(ext)) {
      typeHint = 'This is a SHELL SCRIPT';
      extractionFocus = '''Extract and list:
1. Main commands being executed
2. Variables and their purposes
3. Control flow (if/else, loops)
4. File/directory operations
Format: Step-by-step summary.''';
    }
    // Default
    else {
      typeHint = 'This is a TEXT file';
      extractionFocus = '''Summarize the key content:
1. Main topics covered
2. Important facts or data
3. Any structured information
Format: Concise bullet points.''';
    }
    
    final prompt = '''$typeHint (.$ext file)

TASK: Create a searchable index summary for this content chunk.
The summary will be used to help an AI assistant find relevant information later.

$extractionFocus

CONTENT:
$chunk

OUTPUT REQUIREMENTS:
- Maximum 300 words
- Use keywords that would help find this content
- Be specific, not vague
- Chinese response preferred if content is Chinese''';

    try {
      String apiEndpoint = config.base.replaceAll(RegExp(r'/+$'), '');
      apiEndpoint = '$apiEndpoint/chat/completions';
      
      final uri = Uri.parse(apiEndpoint);
      final body = json.encode({
        'model': config.model,
        'messages': [
          {'role': 'system', 'content': 'You are an expert at creating searchable index summaries for code and documents. Be concise but comprehensive.'},
          {'role': 'user', 'content': prompt}
        ],
        'temperature': 0.3,
        'stream': false,
      });

      final resp = await http.post(
        uri,
        headers: {
          'Authorization': 'Bearer ${config.key}',
          'Content-Type': 'application/json',
        },
        body: body,
      ).timeout(const Duration(minutes: 3));

      if (resp.statusCode == 200) {
        final decodedBody = utf8.decode(resp.bodyBytes);
        final data = json.decode(decodedBody);
        return data['choices'][0]['message']['content'] ?? _fallbackSummary(chunk, ext);
      } else {
        debugPrint('Knowledge summary API error: ${resp.statusCode}');
      }
    } catch (e) {
      debugPrint('Knowledge summary failed: $e');
    }
    return _fallbackSummary(chunk, ext);
  }

  /// Fallback summary when API fails - extract key patterns
  String _fallbackSummary(String chunk, String ext) {
    final lines = chunk.split('\n').where((l) => l.trim().isNotEmpty).toList();
    final buffer = StringBuffer();
    buffer.writeln('[Fallback Summary - API unavailable]');
    
    // For code: extract function/class definitions
    if (['dart', 'py', 'js', 'ts', 'java', 'kt', 'go', 'rs'].contains(ext)) {
      final patterns = [
        RegExp(r'(class|interface|enum)\s+(\w+)'),
        RegExp(r'(def|func|function|fn)\s+(\w+)'),
        RegExp(r'(public|private|async)?\s*(static)?\s*\w+\s+(\w+)\s*\('),
      ];
      final matches = <String>{};
      for (var line in lines.take(50)) {
        for (var pattern in patterns) {
          final match = pattern.firstMatch(line);
          if (match != null) {
            matches.add(line.trim().substring(0, line.trim().length.clamp(0, 80)));
          }
        }
      }
      if (matches.isNotEmpty) {
        buffer.writeln('Definitions found:');
        for (var m in matches.take(10)) {
          buffer.writeln('  - $m');
        }
      }
    }
    
    // Show first few meaningful lines
    buffer.writeln('Content preview:');
    for (var line in lines.take(5)) {
      final trimmed = line.trim();
      if (trimmed.length > 100) {
        buffer.writeln('  ${trimmed.substring(0, 100)}...');
      } else {
        buffer.writeln('  $trimmed');
      }
    }
    
    return buffer.toString();
  }

  Future<void> _performDeepProfiling() async {
    if (_profileBase.contains('your-oneapi-host') || _profileKey.isEmpty) {
      _showError('è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½® Profiler API');
      _openSettings();
      return;
    }

    // Use a notifier to update a modal progress dialog so the UI doesn't appear to "hang".
    final ValueNotifier<String> progress = ValueNotifier<String>('ğŸ”® å‡†å¤‡è¯»å–å†å²è®°å½•...');
    final ValueNotifier<double> progressValue = ValueNotifier<double>(0.0);
    final ValueNotifier<String> funFact = ValueNotifier<String>('');

    // Fun facts to display during profiling
    final funFacts = [
      'ğŸ’¡ æ­£åœ¨åˆ†æä½ çš„æ€ç»´æ¨¡å¼...',
      'ğŸ¨ æ¢ç´¢ä½ çš„å®¡ç¾åå¥½...',
      'ğŸ§  è§£ç ä½ çš„å†³ç­–é£æ ¼...',
      'â¤ï¸ æ„ŸçŸ¥ä½ çš„æƒ…æ„Ÿç‰¹å¾...',
      'ğŸ¯ ç†è§£ä½ çš„ç›®æ ‡ä¸è¿½æ±‚...',
      'ğŸ” å‘ç°éšè—çš„è¡Œä¸ºè§„å¾‹...',
      'âœ¨ æ„å»ºä¸“å±äºä½ çš„ç”»åƒ...',
      'ğŸŒŸ æ¯ä¸€æ¬¡å¯¹è¯éƒ½è®©æˆ‘æ›´æ‡‚ä½ ...',
    ];
    int factIndex = 0;

    // Rotate fun facts
    Timer? factTimer;
    factTimer = Timer.periodic(const Duration(seconds: 3), (_) {
      factIndex = (factIndex + 1) % funFacts.length;
      funFact.value = funFacts[factIndex];
    });
    funFact.value = funFacts[0];

    if (!mounted) return;

    // Show non-dismissible progress dialog with enhanced UI
    showDialog(
      context: context,
      barrierDismissible: false,
      builder: (ctx) => PopScope(
        canPop: false,
        child: AlertDialog(
          shape: RoundedRectangleBorder(borderRadius: BorderRadius.circular(20)),
          content: SizedBox(
            width: 320,
            child: Column(
              mainAxisSize: MainAxisSize.min,
              children: [
                // Animated gradient icon
                Container(
                  width: 80,
                  height: 80,
                  decoration: BoxDecoration(
                    gradient: AppColors.primaryGradient,
                    shape: BoxShape.circle,
                    boxShadow: [
                      BoxShadow(
                        color: AppColors.primaryStart.withOpacity(0.4),
                        blurRadius: 20,
                        spreadRadius: 2,
                      ),
                    ],
                  ),
                  child: const Icon(Icons.psychology_rounded, size: 40, color: Colors.white),
                ),
                const SizedBox(height: 20),
                // Title
                const Text(
                  'æ·±åº¦åˆ»ç”»è¿›è¡Œä¸­',
                  style: TextStyle(fontSize: 18, fontWeight: FontWeight.bold),
                ),
                const SizedBox(height: 8),
                // Fun fact with animation
                ValueListenableBuilder<String>(
                  valueListenable: funFact,
                  builder: (context, fact, _) => AnimatedSwitcher(
                    duration: const Duration(milliseconds: 500),
                    child: Text(
                      fact,
                      key: ValueKey(fact),
                      style: TextStyle(fontSize: 13, color: Colors.grey[600]),
                      textAlign: TextAlign.center,
                    ),
                  ),
                ),
                const SizedBox(height: 20),
                // Progress bar
                ValueListenableBuilder<double>(
                  valueListenable: progressValue,
                  builder: (context, value, _) => Column(
                    children: [
                      ClipRRect(
                        borderRadius: BorderRadius.circular(10),
                        child: LinearProgressIndicator(
                          value: value > 0 ? value : null,
                          minHeight: 8,
                          backgroundColor: Colors.grey[200],
                          valueColor: const AlwaysStoppedAnimation<Color>(AppColors.primaryStart),
                        ),
                      ),
                      if (value > 0) ...[
                        const SizedBox(height: 8),
                        Text(
                          '${(value * 100).toInt()}%',
                          style: TextStyle(fontSize: 12, color: Colors.grey[500], fontWeight: FontWeight.w500),
                        ),
                      ],
                    ],
                  ),
                ),
                const SizedBox(height: 12),
                // Status text
                ValueListenableBuilder<String>(
                  valueListenable: progress,
                  builder: (context, value, _) => Text(
                    value, 
                    textAlign: TextAlign.center,
                    style: TextStyle(fontSize: 12, color: Colors.grey[600]),
                  ),
                ),
              ],
            ),
          ),
        ),
      ),
    );

    // CRITICAL: Wait for dialog to render before heavy operations
    await Future.delayed(const Duration(milliseconds: 50));

    setState(() {
      _loadingStatus = 'æ­£åœ¨è¯»å–å…¨é‡å†å²è®°å½•...';
      _sending = true;
    });

    // Yield to UI thread to ensure dialog is visible
    await Future.delayed(const Duration(milliseconds: 50));

    try {
      debugPrint('Deep profiling started');
      progressValue.value = 0.05;

      // 1. Gather ALL History (Archive + Active)
      final dir = await getApplicationDocumentsDirectory();
      final archivePath = '${dir.path}/chat_archive.jsonl';
      final allHistoryBuffer = StringBuffer();

      // Read Archive in Isolate (non-blocking) with error handling
      progress.value = 'ğŸ“š è¯»å–å½’æ¡£è®°å½•...';
      progressValue.value = 0.1;
      debugPrint('Reading archive from $archivePath');
      String archiveContent = '';
      try {
        archiveContent = await compute(_processHistoryInIsolate, archivePath)
            .timeout(const Duration(seconds: 30));
      } catch (e) {
        debugPrint('Archive read failed (non-fatal): $e');
        // Continue without archive - not fatal
      }
      allHistoryBuffer.write(archiveContent);
      debugPrint('Archive read complete, length: ${archiveContent.length}');
      progressValue.value = 0.2;

      // Add unarchived active messages
      progress.value = 'ğŸ’¬ åˆå¹¶å½“å‰ä¼šè¯æ¶ˆæ¯...';
      for (var m in _messages) {
        if (!m.isArchived) {
          allHistoryBuffer.writeln('[${_activePersona.id}] ${m.role}: ${m.content}');
        }
      }

      final fullText = allHistoryBuffer.toString();
      if (fullText.isEmpty) {
        progress.value = 'âš ï¸ æ— è¶³å¤Ÿå†å²è®°å½•';
        _showError('æ²¡æœ‰è¶³å¤Ÿçš„å†å²è®°å½•è¿›è¡Œåˆ»ç”»');
        setState(() {
          _loadingStatus = '';
          _sending = false;
        });
        factTimer?.cancel();
        return;
      }

      // 2. Chunking (Safe limit: 10000 chars to avoid token limits)
      const int chunkSize = 10000;
      final chunks = <String>[];
      for (int i = 0; i < fullText.length; i += chunkSize) {
        int end = (i + chunkSize < fullText.length) ? i + chunkSize : fullText.length;
        chunks.add(fullText.substring(i, end));
      }
      progressValue.value = 0.25;

      // Gather user-initiated content only (NOT search results - those are already processed by AI)
      // Focus on: user-uploaded images analysis, user's creative requests
      progress.value = 'ğŸ–¼ï¸ æ”¶é›†ç”¨æˆ·ä¸»åŠ¨åˆ†äº«å†…å®¹...';
      final refsHistoryBuffer = StringBuffer();
      
      // Get stored references from reference manager
      final allRefs = await _refManager.getAllStoredReferences();
      if (allRefs.isNotEmpty) {
        // Only user-initiated content: vision (user uploaded images) and generated (user's creative intent)
        // Skip search refs - they are raw materials already processed into conversation
        final visionRefs = allRefs.where((r) => r.sourceType == 'vision').toList();
        final generatedRefs = allRefs.where((r) => r.sourceType == 'generated').toList();
        
        if (visionRefs.isNotEmpty) {
          refsHistoryBuffer.writeln('ã€ç”¨æˆ·ä¸Šä¼ å›¾ç‰‡åˆ†æ - ${visionRefs.length}æ¬¡ã€‘');
          refsHistoryBuffer.writeln('ï¼ˆç”¨æˆ·ä¸»åŠ¨åˆ†äº«çš„å›¾ç‰‡åæ˜ å…¶å…³æ³¨ç‚¹å’Œå®¡ç¾ï¼‰');
          for (var r in visionRefs.take(15)) {
            final snippet = r.snippet.length > 150 ? '${r.snippet.substring(0, 150)}...' : r.snippet;
            refsHistoryBuffer.writeln('- $snippet');
          }
        }
        if (generatedRefs.isNotEmpty) {
          refsHistoryBuffer.writeln('\nã€ç”¨æˆ·åˆ›ä½œè¯·æ±‚ - ${generatedRefs.length}æ¬¡ã€‘');
          refsHistoryBuffer.writeln('ï¼ˆç”¨æˆ·çš„ç”Ÿå›¾è¯·æ±‚åæ˜ å…¶åˆ›æ„éœ€æ±‚å’Œå®¡ç¾å–å‘ï¼‰');
          for (var r in generatedRefs.take(15)) {
            refsHistoryBuffer.writeln('- ${r.snippet}');
          }
        }
      }
      final refsHistory = refsHistoryBuffer.toString();
      progressValue.value = 0.3;

      String currentProfile = _globalMemoryCache;

      // 3. PHASE 1: Deep Conversation Analysis (chunked)
      progress.value = 'ğŸ§  ç¬¬ä¸€é˜¶æ®µï¼šå¯¹è¯æ·±åº¦åˆ†æ...';
      final totalChunks = chunks.length;
      for (int i = 0; i < chunks.length; i++) {
        final chunk = chunks[i];
        final chunkProgress = 0.3 + (0.65 * (i + 1) / totalChunks);
        progressValue.value = chunkProgress;
        final statusText = 'ğŸ” æ·±åº¦åˆ»ç”»ä¸­... (${i + 1}/$totalChunks)';
        progress.value = statusText;
        setState(() => _loadingStatus = statusText);

        // Include refs history only in the first chunk to provide full context
        final refsContext = (i == 0 && refsHistory.isNotEmpty) 
            ? '\n\nã€ç”¨æˆ·è¡Œä¸ºè¶³è¿¹ - æœç´¢/è§†è§‰/åˆ›ä½œå†å²ã€‘ï¼š\n$refsHistory\n' 
            : '';

        // Build prompt with multi-dimensional profiling framework
        final prompt = '''
ã€é¦–å¸­ç”¨æˆ·ä¾§å†™å¸ˆ - æ ¸å¿ƒä½¿å‘½ã€‘
ä½ çš„å”¯ä¸€ç›®æ ‡æ˜¯"å®Œå…¨ç†è§£è¿™ä¸ªç”¨æˆ·"ã€‚é€šè¿‡ç”¨æˆ·çš„ä¸€åˆ‡ç›´æ¥ç—•è¿¹ï¼Œæ„å»ºä¸€ä»½èƒ½è®©ä»»ä½•AIç¬é—´ç†è§£è¿™ä¸ªäººçš„å®Œæ•´ç”»åƒã€‚

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€æœ€æ ¸å¿ƒè¾“å…¥ï¼šå½“å‰ç”¨æˆ·ç”»åƒã€‘ï¼ˆä¸¥ç¦ä¿¡æ¯ä¸¢å¤±ï¼ï¼‰
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
$currentProfile
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ã€é‡è¦æ€§è¯´æ˜ã€‘
ä¸Šè¿°ã€å½“å‰ç”¨æˆ·ç”»åƒã€‘æ˜¯ä¹‹å‰æ‰€æœ‰å¯¹è¯å’Œåˆ»ç”»çš„ç»“æ™¶ï¼Œä»£è¡¨å¯¹ç”¨æˆ·çš„ç´¯ç§¯ç†è§£ã€‚
âš ï¸ ä¸¥ç¦ç›´æ¥è¦†ç›–ï¼å¿…é¡»åœ¨æ­¤åŸºç¡€ä¸Šæ‰©å±•ã€æ·±åŒ–ã€ç²¾ç‚¼ã€‚
âš ï¸ å·²æœ‰ç»´åº¦å¿…é¡»ä¿ç•™ï¼å¯ä»¥æ–°å¢ç»´åº¦ï¼Œä½†ä¸èƒ½åˆ é™¤ä»»ä½•å·²å­˜åœ¨çš„åˆ†æç»´åº¦ã€‚

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€æœ¬è½®åˆ†æç´ æã€‘ï¼ˆç¬¬ ${i + 1}/${chunks.length} éƒ¨åˆ†ï¼‰
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€ç”¨æˆ·ç›´æ¥å¯¹è¯å†…å®¹ã€‘ï¼š
$chunk

ã€ç”¨æˆ·ä¸»åŠ¨åˆ†äº«çš„å†…å®¹ã€‘ï¼ˆå¦‚æœ‰ï¼‰ï¼š
$refsContext
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ã€åŠ¨æ€ç»´åº¦å‘ç°æœºåˆ¶ã€‘
ä¸è¦ä½¿ç”¨å›ºå®šçš„åˆ†ææ¡†æ¶ï¼è¯·æ ¹æ®ç”¨æˆ·çš„å®é™…å†…å®¹ï¼Œè‡ªä¸»å‘ç°å¹¶æ„å»ºæœ€é€‚åˆè¿™ä¸ªç”¨æˆ·çš„åˆ†æç»´åº¦ã€‚

æ€è€ƒè·¯å¾„ï¼š
1. è¿™ä¸ªç”¨æˆ·åœ¨å¯¹è¯ä¸­å±•ç°äº†å“ªäº›ç‹¬ç‰¹ç‰¹å¾ï¼Ÿ
2. ç°æœ‰ç”»åƒä¸­æœ‰å“ªäº›ç»´åº¦ï¼Ÿå¿…é¡»å…¨éƒ¨ä¿ç•™å¹¶æ·±åŒ–
3. æœ¬è½®å¯¹è¯æ­ç¤ºäº†å“ªäº›æ–°çš„ç»´åº¦ï¼Ÿåº”è¯¥æ–°å¢
4. ä¸åŒä¿¡æ¯ä¹‹é—´æœ‰ä»€ä¹ˆå…³è”å’ŒçŸ›ç›¾ï¼Ÿ
5. è¡¨é¢ä¿¡æ¯èƒŒåéšè—ç€ä»€ä¹ˆæ·±å±‚æ´å¯Ÿï¼Ÿ

å¯èƒ½çš„ç»´åº¦æ–¹å‘ï¼ˆä»…ä¾›å‚è€ƒï¼Œè¯·è‡ªä¸»æ‰©å±•ï¼‰ï¼š
- è®¤çŸ¥ä¸æ€ç»´æ¨¡å¼
- æƒ…æ„Ÿä¸ä»·å€¼è§‚
- è¡Œä¸ºä¸ä¹ æƒ¯
- çŸ¥è¯†ä¸æŠ€èƒ½
- ç¤¾äº¤ä¸äººé™…
- éœ€æ±‚ä¸æœŸæœ›
- æ€§æ ¼ä¸ç‰¹è´¨
- ç›®æ ‡ä¸è¿½æ±‚
- ç—›ç‚¹ä¸å›°æ‰°
- è¡¨è¾¾é£æ ¼
- å†³ç­–åå¥½
- æ—¶é—´æ„ŸçŸ¥
- å®¡ç¾å–å‘
- ç”Ÿæ´»çŠ¶æ€
- ...ï¼ˆè¯·æ ¹æ®ç”¨æˆ·ç‰¹ç‚¹è‡ªç”±æ‰©å±•ï¼‰

ã€æ ¸å¿ƒæŒ‡ä»¤ã€‘
1. ã€ä¸¥æ ¼ç»§æ‰¿ã€‘å½“å‰ç”»åƒä¸­çš„æ‰€æœ‰ç»´åº¦å’Œæ ¸å¿ƒä¿¡æ¯å¿…é¡»ä¿ç•™
2. ã€å¢é‡æ›´æ–°ã€‘åœ¨ç»§æ‰¿åŸºç¡€ä¸Šèåˆæœ¬è½®æ–°å‘ç°
3. ã€ç»´åº¦æ‰©å±•ã€‘å‘ç°æ–°ç»´åº¦æ—¶ç›´æ¥æ–°å¢ï¼Œæ°¸ä¸åˆ é™¤æ—§ç»´åº¦
4. ã€æ·±åº¦æŒ–æ˜ã€‘é€è¿‡ç°è±¡çœ‹æœ¬è´¨ï¼Œæ¨æ–­éšå«ä¿¡æ¯
5. ã€çŸ›ç›¾æ ‡æ³¨ã€‘å‘ç°ä¸ç°æœ‰ç”»åƒçŸ›ç›¾æ—¶ï¼Œæ ‡æ³¨å¹¶åˆ†æåŸå› 
6. ã€ä¿¡æ¯æº¯æºã€‘æ–°å¢ä¿¡æ¯æ—¶å¯æ³¨æ˜æ¥æºï¼ˆå¦‚"ä»æœ¬è½®å¯¹è¯æ¨æ–­"ï¼‰

ã€è¾“å‡ºè¦æ±‚ã€‘
ç›´æ¥è¾“å‡ºå®Œæ•´çš„ç”¨æˆ·ç”»åƒï¼Œä½¿ç”¨æ¸…æ™°çš„ç»“æ„åŒ–æ ¼å¼ã€‚
æ— éœ€ä»»ä½•å…ƒè¯„è®ºæˆ–è§£é‡Šã€‚
å­—æ•°ä¸é™ï¼Œè¶Šè¯¦ç»†è¶Šå¥½ï¼Œä½†è¯·ä¿æŒæ¡ç†æ¸…æ™°ã€‚
''';

        // Normalize URL - only remove trailing slashes, respect user's path
        String cleanProfileBase = _profileBase.replaceAll(RegExp(r'/+$'), '');
        final uri = Uri.parse('$cleanProfileBase/chat/completions');
        final body = json.encode({
          'model': _profileModel,
          'messages': [
            {'role': 'system', 'content': 'You are a helpful memory assistant.'},
            {'role': 'user', 'content': prompt}
          ],
          'stream': false,
        });

        // Retry logic for each chunk
        String? newProfile;
        const int maxRetries = 2;
        int attempt = 0;
        while (attempt <= maxRetries) {
          try {
            final resp = await http.post(
              uri,
              headers: {
                'Authorization': 'Bearer $_profileKey',
                'Content-Type': 'application/json',
              },
              body: body,
            ).timeout(const Duration(minutes: 2));

            if (resp.statusCode == 200) {
              final decodedBody = utf8.decode(resp.bodyBytes);
              final data = json.decode(decodedBody);
              final candidate = data['choices']?[0]?['message']?['content'] ?? '';
              if (candidate != null && candidate.toString().trim().isNotEmpty) {
                newProfile = candidate.toString();
              }
              break;
            } else {
              debugPrint('Profiling chunk $i attempt $attempt failed: ${resp.statusCode}');
            }
          } catch (e) {
            debugPrint('Profiling chunk $i attempt $attempt error: $e');
          }

          attempt++;
          // Backoff before retrying
          await Future.delayed(Duration(seconds: 1 + attempt * 2));
        }

        if (newProfile != null && newProfile.isNotEmpty) {
          currentProfile = newProfile;
        } else {
          debugPrint('Profiling chunk $i failed after $maxRetries retries. Continuing.');
        }

        // Yield to UI to keep it responsive
        await Future.delayed(const Duration(milliseconds: 100));
      }

      // 4. Final Save with celebration
      progressValue.value = 1.0;
      progress.value = 'âœ¨ ç”»åƒæ„å»ºå®Œæˆï¼';
      await Future.delayed(const Duration(milliseconds: 500));
      
      setState(() {
        _globalMemoryCache = currentProfile;
        _saveChatHistory();
        _loadingStatus = '';
        _sending = false;
      });
      
      // Show success with confetti-style message
      _showSuccessSnackBar('ğŸ‰ æ·±åº¦åˆ»ç”»å®Œæˆï¼æˆ‘æ›´æ‡‚ä½ äº†~');
    } catch (e) {
      debugPrint('Deep profiling exception: $e');
      _showError('åˆ»ç”»å¤±è´¥: $e');
      setState(() {
        _loadingStatus = '';
        _sending = false;
      });
    } finally {
      // Clean up timer
      factTimer?.cancel();
      
      if (mounted) {
        try {
          await Navigator.of(context, rootNavigator: true).maybePop();
        } catch (_) {}
      }
      try {
        progress.dispose();
        progressValue.dispose();
        funFact.dispose();
      } catch (_) {}
    }
  }

  /// Use Worker API to semantically parse natural language into a structured AgentDecision
  /// This is smarter than regex because it understands meaning, not just keywords
  Future<AgentDecision?> _parseIntentWithWorker(String rawResponse) async {
    // Get Worker API config
    final prefs = await SharedPreferences.getInstance();
    String workerBase = prefs.getString('worker_base') ?? '';
    String workerKeys = prefs.getString('worker_keys') ?? '';
    String workerModel = prefs.getString('worker_model') ?? 'gpt-3.5-turbo';
    
    // Fallback to chat API if worker not configured
    if (workerBase.isEmpty || workerKeys.isEmpty) {
      workerBase = _chatBase;
      workerKeys = _chatKey;
      workerModel = _chatModel;
    }
    
    // Pick a random key if multiple
    final keyList = workerKeys.split(',').map((k) => k.trim()).where((k) => k.isNotEmpty).toList();
    if (keyList.isEmpty) return null;
    final selectedKey = keyList[DateTime.now().millisecond % keyList.length];
    
    // Super simple prompt for intent extraction
    const systemPrompt = '''You are an intent parser. Given text that describes an action, output ONLY a JSON object.

Available types: search, read_url, draw, vision, save_file, system_control, search_knowledge, read_knowledge, delete_knowledge, take_note, reflect, hypothesize, clarify, answer

Examples:
Input: "æˆ‘è§‰å¾—éœ€è¦å»ç½‘ä¸ŠæŸ¥ä¸€ä¸‹æœ€æ–°ä»·æ ¼"
Output: {"type":"search","query":"æœ€æ–°ä»·æ ¼","continue":true}

Input: "è®©æˆ‘ä»”ç»†çœ‹çœ‹è¿™ä¸ªç½‘é¡µçš„å†…å®¹"
Output: {"type":"read_url","content":"https://example.com","continue":true}

Input: "å¸®ç”¨æˆ·ç”»ä¸€å¼ æ—¥è½çš„å›¾"
Output: {"type":"draw","content":"beautiful sunset, warm colors","continue":false}

Input: "åˆ†æä¸€ä¸‹è¿™å¼ å›¾ç‰‡é‡Œæœ‰ä»€ä¹ˆ"
Output: {"type":"vision","content":"è¯·è¯¦ç»†æè¿°å›¾ç‰‡å†…å®¹","continue":true}

Input: "æŠŠè¿™æ®µä»£ç ä¿å­˜ä¸‹æ¥"
Output: {"type":"save_file","filename":"code.txt","content":"ä»£ç å†…å®¹","continue":false}

Input: "å›åˆ°ä¸»å±å¹•"
Output: {"type":"system_control","content":"home","continue":false}

Input: "åœ¨çŸ¥è¯†åº“é‡Œæœç´¢å…³äºPythonçš„å†…å®¹"
Output: {"type":"search_knowledge","content":"Python","continue":true}

Input: "è¯»å–çŸ¥è¯†å—chunk_001çš„å†…å®¹"
Output: {"type":"read_knowledge","content":"chunk_001","continue":true}

Input: "åˆ é™¤è¿™ä¸ªçŸ¥è¯†æ–‡ä»¶"
Output: {"type":"delete_knowledge","content":"file_id","continue":false}

Input: "è®°ä¸‹æ¥è¿™ä¸ªé‡è¦ä¿¡æ¯"
Output: {"type":"take_note","content":"é‡è¦ä¿¡æ¯å†…å®¹","continue":true}

Input: "éœ€è¦ä»”ç»†æƒ³æƒ³è¿™ä¸ªé—®é¢˜"
Output: {"type":"reflect","content":"åˆ†æé—®é¢˜çš„å¤šä¸ªè§’åº¦","continue":true}

Input: "æƒ³æƒ³æœ‰å“ªäº›å¯èƒ½çš„æ–¹æ¡ˆ"
Output: {"type":"hypothesize","hypotheses":["æ–¹æ¡ˆ1","æ–¹æ¡ˆ2"],"selectedHypothesis":"æ–¹æ¡ˆ1","continue":true}

Input: "éœ€è¦é—®ç”¨æˆ·æ›´å¤šä¿¡æ¯"
Output: {"type":"clarify","content":"è¯·é—®æ‚¨å…·ä½“æŒ‡çš„æ˜¯ä»€ä¹ˆï¼Ÿ","continue":false}

Input: "ç›´æ¥å‘Šè¯‰ç”¨æˆ·ç­”æ¡ˆå°±è¡Œ"
Output: {"type":"answer","content":"","continue":false}

ONLY output JSON. No explanation.''';

    try {
      final cleanBase = workerBase.replaceAll(RegExp(r'/+$'), '');
      final uri = Uri.parse('$cleanBase/chat/completions');
      
      // ä½¿ç”¨å¸¦é‡è¯•çš„è¯·æ±‚ï¼ˆWorker è¯·æ±‚å¯ä»¥å¿«é€Ÿå¤±è´¥ï¼‰
      final resp = await _postWithRetry(
        uri,
        headers: {
          'Authorization': 'Bearer $selectedKey',
          'Content-Type': 'application/json',
        },
        body: json.encode({
          'model': workerModel,
          'messages': [
            {'role': 'system', 'content': systemPrompt},
            {'role': 'user', 'content': 'Parse this: $rawResponse'}
          ],
          'temperature': 0,
          'max_tokens': 500,
        }),
        timeout: const Duration(seconds: 15),
        maxRetries: 1, // Worker å¿«é€Ÿé‡è¯•ä¸€æ¬¡å³å¯
      );
      
      if (resp.statusCode == 200) {
        final data = json.decode(utf8.decode(resp.bodyBytes));
        final workerOutput = data['choices'][0]['message']['content'] ?? '';
        
        // Extract JSON from worker output
        final jsonStart = workerOutput.indexOf('{');
        final jsonEnd = workerOutput.lastIndexOf('}');
        if (jsonStart != -1 && jsonEnd > jsonStart) {
          final jsonStr = workerOutput.substring(jsonStart, jsonEnd + 1);
          final parsed = json.decode(jsonStr);
          debugPrint('ğŸ¤– Worker parsed intent: $parsed');
          return AgentDecision.fromJson(parsed);
        }
      }
    } catch (e) {
      debugPrint('Worker intent parse error: $e');
    }
    
    return null;
  }

  Future<AgentDecision> _planAgentStep(String userText, List<ReferenceItem> sessionRefs, List<AgentDecision> previousDecisions) async {
    // Use Router config for planning
    final effectiveBase = (_routerKey.isNotEmpty && !_routerBase.contains('your-oneapi-host')) ? _routerBase : _chatBase;
    final effectiveKey = (_routerKey.isNotEmpty && !_routerBase.contains('your-oneapi-host')) ? _routerKey : _chatKey;
    final effectiveModel = (_routerKey.isNotEmpty && !_routerBase.contains('your-oneapi-host')) ? _routerModel : _chatModel;

    // 1. Prepare Context Data
    final now = DateTime.now();
    final timeString = "${now.year}å¹´${now.month}æœˆ${now.day}æ—¥ ${now.hour}:${now.minute} (æ˜ŸæœŸ${['','ä¸€','äºŒ','ä¸‰','å››','äº”','å…­','æ—¥'][now.weekday]})";
    
    // User Profile (No truncation - critical context)
    String memoryContent = _globalMemoryCache.isNotEmpty ? _globalMemoryCache : "æš‚æ— ";
    
    // Get historical activity summary (cross-session context)
    String historicalSummary = '';
    try {
      final historicalRefs = await _refManager.getExternalReferences();
      if (historicalRefs.isNotEmpty) {
        final visionHistory = historicalRefs.where((r) => r.sourceType == 'vision').take(5).toList();
        final searchHistory = historicalRefs.where((r) => r.sourceType != 'vision' && r.sourceType != 'generated').take(5).toList();
        
        final summaryBuffer = StringBuffer();
        if (visionHistory.isNotEmpty) {
          summaryBuffer.writeln('ğŸ“· æœ€è¿‘åˆ†æçš„å›¾ç‰‡ (${visionHistory.length}):');
          for (var r in visionHistory) {
            final shortSnippet = r.snippet.length > 80 ? '${r.snippet.substring(0, 80)}...' : r.snippet;
            summaryBuffer.writeln('  â€¢ $shortSnippet');
          }
        }
        if (searchHistory.isNotEmpty) {
          summaryBuffer.writeln('ğŸ” æœ€è¿‘çš„æœç´¢/æµè§ˆ (${searchHistory.length}):');
          for (var r in searchHistory) {
            summaryBuffer.writeln('  â€¢ ${r.title}');
          }
        }
        historicalSummary = summaryBuffer.toString();
      }
    } catch (e) {
      debugPrint('Failed to get historical refs: $e');
    }
    
    // Format References (Observations) with rich metadata AND strict limits
    final refsBuffer = StringBuffer();
    if (sessionRefs.isNotEmpty) {
      // Group by source type for clarity
      final synthesisRefs = sessionRefs.where((r) => r.sourceType == 'synthesis').toList();
      final visionRefs = sessionRefs.where((r) => r.sourceType == 'vision').toList();
      final generatedRefs = sessionRefs.where((r) => r.sourceType == 'generated').toList();
      final knowledgeRefs = sessionRefs.where((r) => r.sourceType == 'knowledge').toList();
      final knowledgeSearchRefs = sessionRefs.where((r) => r.sourceType == 'knowledge_search').toList();
      final thinkingRefs = sessionRefs.where((r) => 
        r.sourceType == 'reflection' || r.sourceType == 'hypothesis' || r.sourceType == 'system' || r.sourceType == 'system_note'
      ).toList();
      
      // ğŸ’¡ System feedback (observations for Agent to consider)
      final feedbackRefs = sessionRefs.where((r) => r.sourceType == 'feedback').toList();
      
      // URL content (deep read results)
      final urlContentRefs = sessionRefs.where((r) => r.sourceType == 'url_content').toList();
      
      // Filter web refs (exclude all special types)
      var webRefs = sessionRefs.where((r) => 
        r.sourceType != 'vision' && r.sourceType != 'generated' && 
        r.sourceType != 'reflection' && r.sourceType != 'hypothesis' && 
        r.sourceType != 'system' && r.sourceType != 'system_note' && r.sourceType != 'synthesis' &&
        r.sourceType != 'knowledge' && r.sourceType != 'knowledge_search' && r.sourceType != 'url_content' &&
        r.sourceType != 'feedback' && r.sourceType != 'ocr' && r.sourceType != 'pending_image'
      ).toList();
      
      // LIMIT CONTEXT: Keep only recent/relevant references to prevent context explosion
      if (webRefs.length > 15) {
        // Keep first 3 (often most relevant) and last 12 (most recent)
        final first3 = webRefs.take(3).toList();
        final last12 = webRefs.skip(webRefs.length - 12).toList();
        webRefs = [...first3, ...last12];
        refsBuffer.writeln('âš ï¸ (Note: Some older search results were hidden to save context space)');
      }
      
      int idx = 1;
      
      // ğŸ’¡ SYSTEM FEEDBACK FIRST (most important for decision-making)
      // This ensures Agent sees the feedback prominently before other data
      if (feedbackRefs.isNotEmpty) {
        refsBuffer.writeln('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
        refsBuffer.writeln('ğŸ’¡ [ç³»ç»Ÿè§‚å¯Ÿåé¦ˆ - è¯·é˜…è¯»åè‡ªè¡Œå†³ç­–]');
        refsBuffer.writeln('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
        for (var r in feedbackRefs) {
          refsBuffer.writeln(r.snippet);
          refsBuffer.writeln('');
        }
      }
      
      // Global Synthesis first (most important overview)
      if (synthesisRefs.isNotEmpty) {
        refsBuffer.writeln('ğŸŒ [å…¨å±€è§†è§’ç»¼åˆåˆ†æ]');
        refsBuffer.writeln('âš¡ ä»¥ä¸‹æ˜¯ AI Worker å¯¹æ‰€æœ‰æœç´¢ç»“æœçš„ç»¼åˆåˆ†æï¼Œæä¾›å…¨å±€è§†è§’ï¼š');
        // Keep only last 2 synthesis results
        for (var r in synthesisRefs.reversed.take(2).toList().reversed) {
          refsBuffer.writeln('${r.snippet}');
          idx++;
        }
        refsBuffer.writeln('');
      }
      
      // Knowledge Base search results (summaries for selection)
      if (knowledgeSearchRefs.isNotEmpty) {
        refsBuffer.writeln('ğŸ” [çŸ¥è¯†åº“æœç´¢ç»“æœ - æ‘˜è¦åˆ—è¡¨]');
        // Only keep latest search result (previous ones are superseded)
        final latestSearch = knowledgeSearchRefs.last;
        refsBuffer.writeln('  $idx. ${latestSearch.title}');
        refsBuffer.writeln('${latestSearch.snippet}');
        idx++;
        refsBuffer.writeln('');
      }
      
      // Knowledge Base content (actual content from read_knowledge)
      if (knowledgeRefs.isNotEmpty) {
        refsBuffer.writeln('ğŸ“– [çŸ¥è¯†åº“å†…å®¹ - å®é™…æ–‡æœ¬]');
        for (var r in knowledgeRefs) {
          refsBuffer.writeln('  $idx. ${r.title}');
          refsBuffer.writeln('${r.snippet}');
          idx++;
        }
        refsBuffer.writeln('');
      }
      
      // URL Content (deep read results from read_url action)
      if (urlContentRefs.isNotEmpty) {
        refsBuffer.writeln('ğŸ“„ [ç½‘é¡µæ·±åº¦é˜…è¯»å†…å®¹]');
        // Keep last 3 URL reads to prevent context explosion
        for (var r in urlContentRefs.skip(urlContentRefs.length > 3 ? urlContentRefs.length - 3 : 0)) {
          String snippet = r.snippet;
          // ç”¨æˆ·APIæ”¯æŒ60K tokensï¼Œå…è®¸æ›´å®Œæ•´çš„å†…å®¹
          if (snippet.length > 8000) snippet = '${snippet.substring(0, 8000)}...[æˆªæ–­]';
          refsBuffer.writeln('  $idx. ${r.title}');
          refsBuffer.writeln('     æ¥æº: ${r.url}');
          refsBuffer.writeln('     å†…å®¹: $snippet');
          idx++;
        }
        refsBuffer.writeln('');
      }
      
      // Deep Think observations (recent context)
      if (thinkingRefs.isNotEmpty) {
        refsBuffer.writeln('ğŸ§  [æ·±åº¦æ€è€ƒ/ç³»ç»Ÿè®°å½•]');
        // Keep last 10 thinking notes
        for (var r in thinkingRefs.skip(thinkingRefs.length > 10 ? thinkingRefs.length - 10 : 0)) {
          refsBuffer.writeln('  $idx. ${r.title}');
          refsBuffer.writeln('     ${r.snippet}');
          idx++;
        }
      }
      
      if (visionRefs.isNotEmpty) {
        refsBuffer.writeln('ğŸ“· [å›¾ç‰‡åˆ†æç»“æœ]');
        // Keep last 5 vision results
        for (var r in visionRefs.skip(visionRefs.length > 5 ? visionRefs.length - 5 : 0)) {
          String snippet = r.snippet;
          if (snippet.length > 2000) snippet = '${snippet.substring(0, 2000)}...';
          refsBuffer.writeln('  $idx. ${r.title}: $snippet');
          idx++;
        }
      }
      
      // OCR results
      final ocrRefs = sessionRefs.where((r) => r.sourceType == 'ocr').toList();
      if (ocrRefs.isNotEmpty) {
        refsBuffer.writeln('ğŸ“ [OCR æ–‡å­—æå–ç»“æœ]');
        for (var r in ocrRefs) {
          String snippet = r.snippet;
          if (snippet.length > 3000) snippet = '${snippet.substring(0, 3000)}...[æˆªæ–­]';
          refsBuffer.writeln('  $idx. ${r.title}');
          refsBuffer.writeln('$snippet');
          idx++;
        }
      }
      
      // Pending images (not yet analyzed)
      final pendingImageRefs = sessionRefs.where((r) => r.sourceType == 'pending_image').toList();
      if (pendingImageRefs.isNotEmpty) {
        refsBuffer.writeln('ğŸ“· [å¾…å¤„ç†å›¾ç‰‡ - éœ€è¦ä½ é€‰æ‹©åˆ†ææ–¹å¼]');
        for (var r in pendingImageRefs) {
          refsBuffer.writeln('${r.snippet}');
          idx++;
        }
      }
      
      if (generatedRefs.isNotEmpty) {
        refsBuffer.writeln('ğŸ¨ [å·²ç”Ÿæˆå›¾ç‰‡]');
        for (var r in generatedRefs) {
          refsBuffer.writeln('  $idx. ${r.title}: ${r.snippet}');
          idx++;
        }
      }
      
      if (webRefs.isNotEmpty) {
        refsBuffer.writeln('ğŸ” [ç½‘ç»œæœç´¢ç»“æœ - æ˜¾ç¤º${webRefs.length}æ¡]');
        for (var r in webRefs) {
          String snippet = r.snippet;
          // ç”¨æˆ·APIæ”¯æŒ60K tokens
          if (snippet.length > 1500) snippet = '${snippet.substring(0, 1500)}...';
          
          // Add reliability indicator
          String reliabilityIcon = 'âšª';
          if (r.reliability != null) {
            if (r.reliability! >= 0.8) {
              reliabilityIcon = 'ğŸŸ¢'; // High reliability
            } else if (r.reliability! >= 0.6) {
              reliabilityIcon = 'ğŸŸ¡'; // Medium reliability
            } else {
              reliabilityIcon = 'ğŸ”´'; // Low reliability
            }
          }
          
          // Add authority tag
          String authorityTag = '';
          if (r.authorityLevel != null && r.authorityLevel != 'unknown') {
            final authorityLabels = {
              'official': 'å®˜æ–¹',
              'academic': 'å­¦æœ¯',
              'professional': 'ä¸“ä¸š',
              'ugc': 'UGC',
            };
            authorityTag = ' [${authorityLabels[r.authorityLevel] ?? r.authorityLevel}]';
          }
          
          refsBuffer.writeln('  $idx. $reliabilityIcon [${r.sourceName}]$authorityTag ${r.title}');
          refsBuffer.writeln('     æ‘˜è¦: $snippet');
          refsBuffer.writeln('     æ¥æº: ${r.url}');
          idx++;
        }
      }
    } else {
      refsBuffer.writeln('None yet.');
    }

    // Format Previous Actions with clear status indicators and Deep Think info
    final prevActionsBuffer = StringBuffer();
    
    // META-COGNITION: Detect patterns in action history
    int consecutiveSearches = 0;
    int failedSearches = 0;
    int totalReflections = 0;
    AgentActionType? lastActionType;
    
    if (previousDecisions.isNotEmpty) {
      for (var i = 0; i < previousDecisions.length; i++) {
        final d = previousDecisions[i];
        final contentInfo = d.query ?? d.content ?? 'N/A';
        
        // Track patterns for meta-cognition
        if (d.type == AgentActionType.search) {
          if (lastActionType == AgentActionType.search) {
            consecutiveSearches++;
          } else {
            consecutiveSearches = 1;
          }
          if (d.reason?.contains('failed') == true || d.reason?.contains('No results') == true) {
            failedSearches++;
          }
        }
        if (d.type == AgentActionType.reflect) totalReflections++;
        lastActionType = d.type;
        
        // Extract result status from reason if present
        String status = 'â³ pending';
        String typeIcon = 'ğŸ”§';
        
        if (d.type == AgentActionType.reflect) {
          typeIcon = 'ğŸ§ ';
          status = 'ğŸ’­ reflected';
        } else if (d.type == AgentActionType.hypothesize) {
          typeIcon = 'ğŸ’¡';
          status = 'ğŸ”€ ${d.hypotheses?.length ?? 0} hypotheses';
        } else if (d.type == AgentActionType.clarify) {
          typeIcon = 'â“';
          status = 'ğŸ—£ï¸ awaiting user input';
        } else if (d.reason?.contains('[RESULT:') == true) {
          if (d.reason!.contains('successfully') || d.reason!.contains('complete')) {
            status = 'âœ… success';
          } else if (d.reason!.contains('failed') || d.reason!.contains('No results') || d.reason!.contains('error')) {
            status = 'âŒ failed';
          } else {
            status = 'âœ… done';
          }
        }
        
        // Add confidence indicator
        String confidenceStr = '';
        if (d.confidence != null) {
          final pct = (d.confidence! * 100).toInt();
          confidenceStr = pct >= 80 ? ' ğŸŸ¢$pct%' : (pct >= 50 ? ' ğŸŸ¡$pct%' : ' ğŸ”´$pct%');
        }
        
        prevActionsBuffer.writeln('Step ${i + 1}: $typeIcon ${d.type.name.toUpperCase()} $status$confidenceStr');
        prevActionsBuffer.writeln('  Target: "$contentInfo"');
        if (d.uncertainties != null && d.uncertainties!.isNotEmpty) {
          prevActionsBuffer.writeln('  Uncertainties: ${d.uncertainties!.join(", ")}');
        }
        if (d.selectedHypothesis != null) {
          prevActionsBuffer.writeln('  Selected: ${d.selectedHypothesis}');
        }
        if (d.reason != null && d.reason!.isNotEmpty) {
          prevActionsBuffer.writeln('  Notes: ${d.reason}');
        }
      }
      
      // META-COGNITION ALERTS
      prevActionsBuffer.writeln('\n--- META-COGNITION ALERTS ---');
      if (consecutiveSearches >= 2) {
        prevActionsBuffer.writeln('âš ï¸ PATTERN: $consecutiveSearches consecutive searches. Consider: REFLECT on current approach or HYPOTHESIZE alternatives.');
      }
      if (failedSearches >= 2) {
        prevActionsBuffer.writeln('ğŸš¨ ALERT: $failedSearches failed searches. MUST change strategy: use different keywords, broader/narrower scope, or HYPOTHESIZE new angle.');
      }
      if (previousDecisions.length >= 5 && totalReflections == 0) {
        prevActionsBuffer.writeln('ğŸ’¡ SUGGESTION: 5+ steps without reflection. Consider REFLECT to ensure you\'re on the right track.');
      }
      if (previousDecisions.length >= 3 && !previousDecisions.any((d) => d.type == AgentActionType.hypothesize)) {
        final hasFailure = previousDecisions.any((d) => d.reason?.contains('failed') == true || d.reason?.contains('No results') == true);
        if (hasFailure) {
          prevActionsBuffer.writeln('ğŸ’¡ SUGGESTION: Multiple failures without hypothesizing. Use HYPOTHESIZE to explore alternative approaches.');
        }
      }
    } else {
      prevActionsBuffer.writeln('None yet - this is the first planning step.');
    }

    // Format Chat Historyï¼ˆæ”¹ä¸ºâ€œå…ˆå‹ç¼©åé™é•¿â€ï¼Œä¸å†ç›´æ¥ä¸¢å¼ƒæ—§æ¶ˆæ¯ï¼‰
    var contextMsgs = List<ChatMessage>.from(_messages);

    // è®¡ç®—æ€»é•¿ï¼Œå¦‚è¶…é™åˆ™å¯¹æ—§æ¶ˆæ¯åˆ†å—æ‘˜è¦ï¼Œä¿ç•™æœ€è¿‘å‡ æ¡åŸæ–‡
    const int agentCharBudget = 50000; // ç”¨æˆ·APIæ”¯æŒ60K tokens
    final agentTotal = contextMsgs.fold(0, (p, c) => p + c.content.length);
    if (agentTotal > agentCharBudget) {
      contextMsgs = await _compressHistoryForTransport(
        contextMsgs,
        targetChars: agentCharBudget,
        keepTail: 8, // ä¿ç•™æœ€è¿‘äº¤äº’ï¼Œæ—§çš„è½¬ä¸ºæ‘˜è¦å¡ç‰‡
      );
      // _compressHistoryForTransport å†…éƒ¨ä¼šå†™ _lastCompressionNote ä¾› UI ä½¿ç”¨
    } else {
      _lastCompressionNote = null;
    }
        
    final contextBuffer = StringBuffer();
    for (var m in contextMsgs) {
      String roleName;
      if (m.role == 'user') {
        roleName = 'User';
      } else if (m.role == 'system') {
        roleName = 'System';
      } else {
        roleName = 'Assistant (${_activePersona.name})';
      }
      contextBuffer.writeln('$roleName: ${m.content}');
    }

    // Tool availability summary so the planner knows what it can actually use
    final prefs = await SharedPreferences.getInstance();
    final searchProviderPref = prefs.getString('search_provider') ?? 'auto';
    final exaKey = prefs.getString('exa_key') ?? '';
    final youKey = prefs.getString('you_key') ?? '';
    final braveKey = prefs.getString('brave_key') ?? '';

    String? resolvedSearchProvider;
    if (searchProviderPref == 'exa' && exaKey.isNotEmpty) {
      resolvedSearchProvider = 'Exa';
    } else if (searchProviderPref == 'you' && youKey.isNotEmpty) {
      resolvedSearchProvider = 'You.com';
    } else if (searchProviderPref == 'brave' && braveKey.isNotEmpty) {
      resolvedSearchProvider = 'Brave';
    } else if (searchProviderPref == 'auto') {
      if (exaKey.isNotEmpty) {
        resolvedSearchProvider = 'Exa';
      } else if (youKey.isNotEmpty) {
        resolvedSearchProvider = 'You.com';
      } else if (braveKey.isNotEmpty) {
        resolvedSearchProvider = 'Brave';
      }
    }

    final searchAvailable = resolvedSearchProvider != null;
    final drawAvailable = !_imgBase.contains('your-oneapi-host') && _imgKey.isNotEmpty;
    final visionAvailable = !_visionBase.contains('your-oneapi-host') && _visionKey.isNotEmpty;
    final ocrAvailable = !_ocrBase.contains('your-oneapi-host') && _ocrKey.isNotEmpty;

    // Check if we have an active image in this session (either vision or ocr analyzed)
    final hasSessionImage = sessionRefs.any((r) => r.sourceType == 'vision' || r.sourceType == 'ocr');
    // Check if user just uploaded an image that hasn't been analyzed yet
    final hasUnanalyzedImage = currentSessionImagePath.isNotEmpty && 
        !sessionRefs.any((r) => r.imageId == currentSessionImagePath);

    // Check if knowledge base has content
    final hasKnowledge = _knowledgeService.hasKnowledge;
    final knowledgeOverview = hasKnowledge ? _knowledgeService.getKnowledgeOverview() : '';
    AgentDecision finalizeDecision(AgentDecision d) => _finalizeDecision(userText, d, hasKnowledge: hasKnowledge);

    // Auto-trigger hints to push tool usage proactively
    final lowerUser = userText.toLowerCase();
    final autoHints = <String>[];
    if (RegExp(r'(æ•°æ®|ç»Ÿè®¡|è¶‹åŠ¿|æ¥æº|æƒå¨|æœ€æ–°|å¸‚åœº|æŒ‡æ ‡|åˆ†æ)').hasMatch(userText)) {
      autoHints.add('æ£€æµ‹åˆ°æ•°æ®/è¶‹åŠ¿è¯‰æ±‚ â†’ å…ˆ search/read_url è·å–æƒå¨æ¥æºï¼Œå†ç»“åˆ search_knowledge/read_knowledgeï¼›ç¼ºæ¥æºç¦æ­¢ç›´æ¥ answerã€‚');
    }
    if (RegExp(r'(pdf|æ‰«æ|å›¾ç‰‡|æˆªå›¾|ocr)', caseSensitive: false).hasMatch(lowerUser)) {
      autoHints.add('æ£€æµ‹åˆ°æ–‡ä»¶/å›¾ç‰‡/æ‰«æ â†’ ä½¿ç”¨ vision æˆ– OCR è·å–å†…å®¹ï¼ˆPDF ä¼˜å…ˆ OCRï¼‰ã€‚');
    }
    if (RegExp(r'(è®¡åˆ’|æ­¥éª¤|è·¯çº¿å›¾|æ—¶é—´è¡¨|é‡Œç¨‹ç¢‘|æ–¹æ¡ˆ|ä»»åŠ¡|è¿›åº¦|é£é™©|é¢„ç®—|æˆæœ¬|èµ„æº)').hasMatch(userText)) {
      autoHints.add('æ£€æµ‹åˆ°è§„åˆ’/æ‰§è¡Œè¯‰æ±‚ â†’ å…ˆ search/knowledge æ”¶é›†ä¿¡æ¯ï¼Œå†ç”¨ take_note è®°å½•è®¡åˆ’/é£é™©ï¼Œå¿…è¦æ—¶ save_file å¯¼å‡ºã€‚');
    }
    final autoTriggerSection = autoHints.isNotEmpty
        ? 'AUTO_TRIGGER_HINTS:\\n- ${autoHints.join('\\n- ')}'
        : '';
    final deepReasoningSection = _deepReasoningMode
        ? '''
## DEEP REASONING MODE (å·²å¼€å¯)
- ä¸Šä¸‹æ–‡è¦æ±‚ï¼šæ¨ç†å¿…é¡»ç»“åˆ <user_profile>ã€<chat_history>ã€<current_observations>ï¼Œä¸å¯åªçœ‹å½“å‰è¾“å…¥ã€‚
- æµç¨‹ï¼šå‡è®¾/ç–‘é—® â†’ search/read_url/search_knowledge éªŒè¯ â†’ ç”Ÿæˆå¤šæ–¹æ¡ˆ A/B/Cï¼ˆæ¯ä¸ªç»™å¯è¡Œæ€§/æˆæœ¬/é£é™©è¯„åˆ†ï¼Œ0-1ï¼‰â†’ é€‰æ‹©æ–¹æ¡ˆå¹¶ç»™è¡ŒåŠ¨é¡¹ â†’ æŒ‡æ ‡ä¸é£é™©ã€‚
- éªŒè¯ï¼šè‡³å°‘ä¸€æ¬¡ reflect æˆ– hypothesizeï¼›è‡³å°‘ä¸€æ¬¡ search æˆ– search_knowledgeï¼ˆé™¤éæ˜ç¡®é—²èŠï¼‰ï¼›ç»“è®ºå‰å†åšä¸€æ¬¡æ ¡éªŒï¼ˆsearch/knowledgeï¼Œæˆ–ç»™å‡ºéœ€è¦è¡¥å……çš„ä¿¡æ¯ï¼‰ã€‚
- è¾“å‡ºï¼šæ¥æº/è¯æ®ã€æ´å¯Ÿ/è¶‹åŠ¿ã€æ–¹æ¡ˆå¯¹æ¯”ï¼ˆå«è¯„åˆ†ï¼‰ã€æœ€ç»ˆé€‰æ‹©ç†ç”±ã€è¡ŒåŠ¨é¡¹ã€æŒ‡æ ‡ã€é£é™©ä¸ç¼“è§£ã€‚é‡è¦è¦ç‚¹ç”¨ take_noteï¼Œå¿…è¦æ—¶ save_fileã€‚
- è¿­ä»£ï¼šå¿…é¡»å›é¡¾ <action_history> å’Œ <current_observations> é‡Œçš„å·²æœ‰æ–¹æ¡ˆ/è¯„åˆ†/æœªè§£å†³ç‚¹ï¼Œå…ˆæ€»ç»“å†è¿­ä»£ï¼Œç¦æ­¢å¿½è§†å‰åºä¿¡æ¯ã€‚
- ç¦æ­¢å‡­ç©ºç¼–é€ ï¼Œç¼ºä¿¡æ¯æ—¶ä¸»åŠ¨è¯´æ˜å¹¶æå‡ºè·å–è·¯å¾„ï¼ˆæœç´¢/è¿½é—®ï¼‰ã€‚
'''
        : '';

    final toolbelt = '''
### TOOLBELT (what you can call)
$deepReasoningSection

## âš ï¸ REQUIRED JSON FIELDS FOR ALL TOOLS:
Every tool output MUST include: type, reason, confidence(0-1), continue(true/false)

**ğŸ”§ ACTION TOOLS:**

- search: ${searchAvailable ? "AVAILABLE via $resolvedSearchProvider" : "UNAVAILABLE (no search key configured; do NOT pick search)"}
  * **JSON**: {"type":"search","query":"æœç´¢å…³é”®è¯","reason":"P1:...|P2:...|P3:...","confidence":0.9,"continue":true}
  * query: The search keywords (REQUIRED - NOT content!)
  * Returns: Short references/snippets from web search
  * continue: Usually true (you'll answer after seeing results)

- draw: ${drawAvailable ? "AVAILABLE (image generation)" : "UNAVAILABLE (image API not configured; do NOT pick draw)"}
  * **JSON**: {"type":"draw","content":"detailed image prompt in English","reason":"...","confidence":0.95,"continue":false}
  * content: Full image prompt (REQUIRED)
  * continue: false (image is shown to user) or true (if you want to comment)

- vision: ${visionAvailable ? "AVAILABLE - å¤šæ¨¡æ€ç†è§£æ¨¡å‹ (GPT-4V/Geminiç­‰)" : "UNAVAILABLE (vision API not configured)"}
  * **JSON**: {"type":"vision","content":"analysis prompt","reason":"...","confidence":0.85,"continue":true}
  * **APIèƒ½åŠ›**: ç†è§£å›¾ç‰‡æ•´ä½“å†…å®¹ã€åœºæ™¯æè¿°ã€ç‰©ä½“è¯†åˆ«ã€å›¾è¡¨è§£è¯»ã€æƒ…æ„Ÿåˆ†æ
  * **é€‚ç”¨åœºæ™¯**: "è¿™æ˜¯ä»€ä¹ˆ"ã€"æè¿°å›¾ç‰‡"ã€"åˆ†æè¿™å¼ å›¾"ã€"å›¾é‡Œæœ‰ä»€ä¹ˆ"
  * **å±€é™æ€§**: æ–‡å­—æå–ä¸ç²¾ç¡®ï¼Œå¯èƒ½æ¼å­—æˆ–è¯¯è¯†åˆ«
  * NOTE: å¦‚æœ <current_observations> å·²æœ‰åˆ†æç»“æœï¼Œå…ˆçœ‹å·²æœ‰ä¿¡æ¯

- ocr: ${ocrAvailable ? "AVAILABLE - ä¸“ä¸šOCRæ¨¡å‹ (ç²¾ç¡®æ–‡å­—æå–)" : "UNAVAILABLE (OCR API not configured)"}
  * **JSON**: {"type":"ocr","content":"optional prompt","reason":"...","confidence":0.9,"continue":true}
  * **APIèƒ½åŠ›**: ç²¾ç¡®æå–å›¾ç‰‡/PDFä¸­çš„æ‰€æœ‰æ–‡å­—ï¼Œä¿æŒæ ¼å¼
  * **é€‚ç”¨åœºæ™¯**: æ–‡æ¡£æ‰«æã€æˆªå›¾æ–‡å­—ã€å‘ç¥¨è¯†åˆ«ã€è¡¨æ ¼æ•°æ®ã€PDFè½¬æ–‡å­—
  * **ä¼˜åŠ¿**: æ–‡å­—æå–å‡†ç¡®ç‡è¿œé«˜äº visionï¼Œæ”¯æŒ PDF è‡ªåŠ¨æ‹†é¡µ
  * Returns: Markdownæ ¼å¼çš„æå–æ–‡å­—

**ğŸ¯ VISION vs OCR é€‰æ‹©é€»è¾‘ (ä»¥ç”¨æˆ·ç›®çš„ä¸ºå‡†):**
ç”¨æˆ·ç›®çš„æ˜¯ä»€ä¹ˆï¼Ÿ
â”œâ”€ éœ€è¦**ç²¾ç¡®è·å–æ–‡å­—å†…å®¹** (å¤åˆ¶ã€å¼•ç”¨ã€æ•°æ®å¤„ç†) â†’ **ocr**
â”œâ”€ éœ€è¦**ç†è§£å›¾ç‰‡å«ä¹‰** (è¿™æ˜¯ä»€ä¹ˆã€æè¿°ã€åˆ†æ) â†’ **vision**
â”œâ”€ æ–‡æ¡£/PDF/æˆªå›¾ + è¦æå–ä¿¡æ¯ â†’ **ocr** (æ›´å‡†ç¡®)
â”œâ”€ ç…§ç‰‡/åœºæ™¯/å›¾è¡¨ + è¦ç†è§£å†…å®¹ â†’ **vision** (æ›´æ™ºèƒ½)
â””â”€ ä¸ç¡®å®šï¼Ÿçœ‹å›¾ç‰‡ç±»å‹ï¼šæ–‡æ¡£ç±»â†’ocrï¼Œåœºæ™¯ç±»â†’vision

${!ocrAvailable && visionAvailable ? "âš ï¸ OCRæœªé…ç½®ï¼švision ä¹Ÿèƒ½æå–æ–‡å­—ï¼Œä½†å‡†ç¡®ç‡è¾ƒä½ï¼Œæ–‡æ¡£ç±»å»ºè®®ç”¨æˆ·é…ç½®OCR" : ""}
${ocrAvailable && !visionAvailable ? "âš ï¸ Visionæœªé…ç½®ï¼šocr åªèƒ½æå–æ–‡å­—ï¼Œæ— æ³•ç†è§£å›¾ç‰‡å†…å®¹/å«ä¹‰" : ""}

- read_url: ${searchAvailable ? "AVAILABLE - Deep read a webpage for full content" : "UNAVAILABLE (no network access)"}
  * **JSON**: {"type":"read_url","content":"https://example.com/article","reason":"...","confidence":0.85,"continue":true}
  * content: The full URL to read (REQUIRED)
  * Returns: Title + extracted main content (up to 8000 chars)
  * USE WHEN: Search gave you a relevant URL but snippet is too short
  * WORKFLOW: search â†’ review results â†’ read_url on promising link â†’ answer

**ğŸ“š KNOWLEDGE BASE TOOLS (3-Step Retrieval Flow):**
${hasKnowledge ? '''
- search_knowledge: AVAILABLE - Search the knowledge base by keywords.
  * **JSON**: {"type":"search_knowledge","content":"keyword1, keyword2","reason":"...","confidence":0.8,"continue":true}
  * content: Comma-separated keywords (REQUIRED)
  * Returns: Chunk summaries WITH CHUNK IDs (e.g., "file123_0", "file123_3000")
  * âš ï¸ IMPORTANT: Note down the Chunk IDs from results - you need them for read_knowledge!
  
- take_note: AVAILABLE - Save notes to temporary memory.
  * **JSON**: {"type":"take_note","content":"your notes here","reason":"...","confidence":0.9,"continue":true}
  * content: Your notes text (REQUIRED)
  * ğŸ’¡ TIP: Write down relevant Chunk IDs here! e.g., "file123_0 covers auth, file123_3000 covers tokens"

- read_knowledge: AVAILABLE - Read full content of specific chunks.
  * **JSON**: {"type":"read_knowledge","content":"file123_0, file123_3000","reason":"...","confidence":0.85,"continue":true}
  * content: Comma-separated Chunk IDs from search results (REQUIRED)
  * âš ï¸ CRITICAL: Use the EXACT Chunk IDs returned by search_knowledge! Format: "fileId_offset"
  * Returns: Full text content of the chunks (up to 15000 chars total)

- delete_knowledge: AVAILABLE - Delete content from knowledge base.
  * **JSON**: {"type":"delete_knowledge","content":"file_id or chunk_id","reason":"...","confidence":0.9,"continue":false}
  * content: file_id or chunk_id to delete (REQUIRED)
  * NOTE: Irreversible. Confirm with user first.

**âš ï¸ Knowledge Workflow - INDEX IS CRITICAL:**
1. search_knowledge â†’ Get Chunk IDs (e.g., "doc1_0", "doc1_3000")
2. (optional) take_note â†’ Record which Chunk IDs are relevant
3. read_knowledge â†’ Use EXACT Chunk IDs to fetch content
4. answer â†’ Synthesize information
Example: search returns [doc1_0, doc1_3000] â†’ read_knowledge with "doc1_0, doc1_3000"
''' : '''
- search_knowledge: UNAVAILABLE (knowledge base is empty - no files uploaded)
- read_knowledge: UNAVAILABLE (knowledge base is empty)
- delete_knowledge: UNAVAILABLE (knowledge base is empty)
'''}

- save_file: ALWAYS AVAILABLE - Save text or code to a local file.
  * **JSON**: {"type":"save_file","filename":"code.py","content":"file content here","reason":"...","confidence":1.0,"continue":false}
  * filename: File name with extension (REQUIRED)
  * content: File content to save (REQUIRED)
  * Use when user asks to "save", "download", "create file", or "export"

- system_control: AVAILABLE - Control device global actions.
  * **JSON**: {"type":"system_control","content":"home","reason":"...","confidence":1.0,"continue":false}
  * content: One of: "home", "back", "recents", "notifications", "lock", "screenshot" (REQUIRED)
  * NOTE: Requires Accessibility Service. If action fails, ask user to enable it.

**ğŸ§  THINKING TOOLS:**

- reflect: Pause and self-critique. Use when confused or stuck.
  * **JSON**: {"type":"reflect","content":"My analysis of this situation...","reason":"...","confidence":0.6,"continue":true}
  * content: Your reflection/analysis text (REQUIRED)
  * continue: Usually true (you'll take action after reflecting)

- hypothesize: Generate 2-3 alternative approaches.
  * **JSON**: {"type":"hypothesize","hypotheses":["approach A","approach B","approach C"],"selected_hypothesis":"approach A because...","reason":"...","confidence":0.7,"continue":true}
  * hypotheses: Array of alternative approaches (REQUIRED)
  * selected_hypothesis: Which one you chose and why (REQUIRED)
  * Use when one path fails and you need new ideas

- clarify: Ask user for missing info.
  * **JSON**: {"type":"clarify","content":"Your question to the user","reason":"...","confidence":0.5,"continue":false}
  * content: The question to ask user (REQUIRED)
  * continue: false (wait for user response)
  * Use ONLY when you truly cannot proceed without user input

**ğŸ“ OUTPUT:**

- answer: Final response to user.
  * **JSON**: {"type":"answer","content":"Your response here","reason":"...","confidence":0.95,"continue":false}
  * content: Your natural language response (REQUIRED)
  * continue: Usually false (conversation ends)
  * âš ï¸ Use ONLY after gathering info with tools, or for simple greetings
${hasUnanalyzedImage ? """

âš ï¸ **IMAGE PENDING ANALYSIS**: User uploaded an image that needs processing!
- Check <current_observations> for the pending image marker
- You MUST choose either **ocr** (to extract text) or **vision** (to understand content)
- Base your choice on user's request and the image context
""" : hasSessionImage ? """

âš ï¸ **IMAGE ALREADY ANALYZED**: Check <current_observations> for vision/OCR results.
""" : ""}
''';

    // 2. Construct System Prompt with XML Tags for strict separation
    final systemPrompt = '''
You are NOT a chatbot. You are an autonomous AGENT with tools.

## âš ï¸ OUTPUT REQUIREMENT: JSON ONLY âš ï¸
**YOU MUST OUTPUT ONLY A JSON OBJECT. NO EXPLANATIONS. NO MARKDOWN.**
If you write anything other than JSON, THE SYSTEM CANNOT UNDERSTAND YOU.
Your "hands" and "feet" (tools) are controlled by JSON. Natural language = paralysis.

WRONG OUTPUT (system ignores this):
"æˆ‘è®¤ä¸ºéœ€è¦å…ˆæœç´¢ä¸€ä¸‹å…³äºè¿™ä¸ªè¯é¢˜çš„æœ€æ–°ä¿¡æ¯..."

CORRECT OUTPUT (system executes this):
{"type":"search","query":"topic name 2024","reason":"Need latest info","confidence":0.7,"continue":true}

$deepReasoningSection

## ğŸ§  THREE-PASS DECISION PROCESS (CRITICAL!)
Before outputting your JSON decision, you MUST internally perform THREE rounds of thinking:

### PASS 1: INTENT UNDERSTANDING (æ„å›¾ç†è§£)
- What does the user REALLY want? (not just surface request)
- What is the underlying goal or problem?
- What would make the user truly satisfied?

### PASS 2: CAPABILITY REVIEW (èƒ½åŠ›å®¡æŸ¥)
- What tools/APIs do I have available? (search, draw, vision, knowledge, reflect, hypothesize, etc.)
- Am I FULLY utilizing my capabilities?
- Is there a tool I'm FORGETTING to use?
- Am I being lazy by jumping to "answer" without gathering real info?
- Could COMBINING multiple tools give better results?

### PASS 3: OUTCOME PREDICTION (æ•ˆæœé¢„åˆ¤)
- If I execute this action, what will happen?
- Will the result actually satisfy the user's underlying goal (from P1)?
- Am I just "doing something" or truly ADVANCING toward the solution?
- What's the probability of success? If low, consider alternatives.

**Include your three-pass reasoning in the "reason" field:**
Example: "P1:ç”¨æˆ·æƒ³äº†è§£æœ€æ–°åŠ¨æ€ | P2:searchå¯è·å®æ—¶æ•°æ®,å·²æ·»åŠ æ—¥æœŸé™å®š | P3:é«˜è´¨é‡æœç´¢ç»“æœå°†ç›´æ¥æ»¡è¶³éœ€æ±‚âœ“"

## âš ï¸ CRITICAL RULE: TOOL-FIRST PRINCIPLE âš ï¸
**BEFORE using "answer", carefully consider if ANY tool can improve your response.**

ğŸ§  **SELF-CHECK BEFORE "answer":**
1. Is <current_observations> EMPTY or just system notes? â†’ Tools might provide better data
2. Does user ask about facts/news/prices/events? â†’ search usually helps
3. Does user want an image? â†’ draw is the right choice
4. Is this a complex question? â†’ reflect can help, then maybe search
5. ONLY for simple greetings (ä½ å¥½/hi/è°¢è°¢) â†’ answer directly is fine

### HARD TRIGGERS (å¿…é¡»å…ˆç”¨å·¥å…·)
- å‡ºç°â€œæ•°æ®/è¶‹åŠ¿/ç»Ÿè®¡/æ¥æº/æƒå¨/æœ€æ–°/å¸‚åœº/æŒ‡æ ‡/åˆ†æâ€ â†’ å…ˆ search æˆ– read_url æ‹¿æƒå¨æ¥æºï¼›æœ‰æ–‡ä»¶/çŸ¥è¯†åº“åˆ™ search_knowledge/read_knowledge ç»“åˆå¼•ç”¨ã€‚
- å‡ºç°â€œPDF/å›¾ç‰‡/æ‰«æ/æ–‡æ¡£æˆªå›¾â€ â†’ ç”¨ vision æˆ– OCRï¼ˆPDF ä¼˜å…ˆ OCRï¼‰ã€‚
- å‡ºç°â€œè®¡åˆ’/æ­¥éª¤/è·¯çº¿å›¾/æ—¶é—´è¡¨/é‡Œç¨‹ç¢‘/æ–¹æ¡ˆ/ä»»åŠ¡/è¿›åº¦/é£é™©/é¢„ç®—/æˆæœ¬/èµ„æºâ€ â†’ å…ˆ search/knowledge æ”¶é›†ä¿¡æ¯ï¼Œå†ç”¨ take_note è®°å½•è®¡åˆ’/é£é™©ï¼›å¿…è¦æ—¶ save_file å¯¼å‡ºã€‚
- ä¸çŸ¥é“å°±å»æœï¼Œç¦æ­¢å‡­ç©ºç¼–é€ æˆ–ç›´æ¥ answerã€‚

### ç»“æ„åŒ–è¾“å‡ºè¦æ±‚ï¼ˆå½“ä½¿ç”¨ answer æ—¶ï¼‰
- å¿…é¡»åŒ…å«ï¼šæ¥æº/è¯æ®ï¼ˆæ ‡æ³¨æœç´¢æˆ–çŸ¥è¯†æ¥æºï¼‰ã€æ´å¯Ÿ/è¶‹åŠ¿ã€è¡ŒåŠ¨é¡¹ï¼ˆå«è´Ÿè´£äººæˆ–ä¸‹ä¸€æ­¥ï¼‰ã€æŒ‡æ ‡/è¡¡é‡æ–¹å¼ã€é£é™©ä¸ç¼“è§£ã€‚ç¼ºå°‘æ¥æºæ—¶å¿…é¡»å…ˆè°ƒç”¨ search æˆ– knowledgeã€‚
- å…³é”®è¦ç‚¹ç”¨ take_note ä¿å­˜ï¼›éœ€è¦æ–‡ä»¶è¾“å‡ºæ—¶ç”¨ save_file ç”Ÿæˆ markdownï¼ˆå¦‚è®¡åˆ’/é£é™©/æŒ‡æ ‡è¡¨ï¼‰ã€‚

**SYSTEM FEEDBACK:**
- If you choose "answer" without tool usage, system will provide OBSERVATIONS (not commands)
- You can then DECIDE whether to use a tool or stick with your answer
- This is YOUR decision - system just provides information to help you think

- The user installed this app FOR THE TOOLS. Consider if tools add value.
- Review your available tools: search, draw, vision, read_url, save_file, system_control, search_knowledge, read_knowledge, reflect, hypothesize, clarify, take_note

## ğŸ”„ ITERATIVE DECISION LOOP
You are called MULTIPLE times in a loop. Each time you see:
- <current_observations>: Results from previous tools (search results, vision analysis, etc.)
- <action_history>: What you already tried and their results

**YOUR DECISION PROCESS:**
1. **IF <current_observations> is EMPTY or minimal:**
   â†’ This is your FIRST step. Choose a tool to gather info.
   â†’ Questions about facts/news/data â†’ search
   â†’ User uploaded image â†’ vision (but check if already analyzed in observations)
   â†’ Complex question â†’ reflect first, then search

2. **IF <current_observations> has search/vision/knowledge results:**
   â†’ Review the results. Are they SUFFICIENT to answer?
   â†’ If YES: Use "answer" with synthesized info from observations
   â†’ If NO (need more): Use another tool (search with different keywords, read_url for details, etc.)
   â†’ Consider: Could I enrich my answer with additional tools? (e.g., draw a diagram, save a summary)

3. **IF <action_history> shows FAILED attempts:**
   â†’ Don't repeat the same thing! Try a different approach.
   â†’ Multiple failed searches â†’ hypothesize alternative angles
   â†’ Tool returned error â†’ try a different tool

**EXAMPLE MULTI-STEP FLOW:**
Step 1 (observations empty): {"type":"search","query":"AI news December 2024","reason":"P1:ç”¨æˆ·æƒ³äº†è§£æœ€æ–°AIåŠ¨æ€ | P2:searchæ˜¯è·å–å®æ—¶ä¿¡æ¯çš„æœ€ä½³å·¥å…· | P3:æœç´¢ç»“æœå°†ç›´æ¥æ»¡è¶³ç”¨æˆ·éœ€æ±‚âœ“","confidence":0.9,"continue":true}
Step 2 (observations have search results): {"type":"answer","content":"æ ¹æ®æœç´¢ç»“æœï¼Œä»Šå¤©çš„AIæ–°é—»æœ‰...","reason":"P1:ç”¨æˆ·è¦æœ€æ–°ä¿¡æ¯ | P2:å·²æœ‰å……åˆ†æ•°æ®,æ— éœ€æ›´å¤šå·¥å…· | P3:ç»¼åˆå›ç­”æ»¡è¶³ç”¨æˆ·æœŸæœ›âœ“","confidence":0.95,"continue":false}

$toolbelt

## âš ï¸ OUTPUT MUST BE PURE JSON âš ï¸
Do NOT write natural language. Do NOT explain. Just output a JSON object like:
{"type":"search","query":"xxx","reason":"P1:... | P2:... | P3:...","confidence":0.8,"continue":true}

If you write anything other than JSON, the system cannot understand you!

## âœ… EXAMPLE OUTPUTS (copy these patterns!)

**User: "ä»Šå¤©æœ‰ä»€ä¹ˆæ–°é—»"**
â†’ {"type":"search","query":"ä»Šæ—¥æ–°é—» 2025å¹´12æœˆ","reason":"P1:éœ€å®æ—¶æ•°æ® | P2:å…³é”®è¯å«æ—¥æœŸæ›´ç²¾å‡† | P3:ç›´æ¥è·å–ç”¨æˆ·è¦çš„ä¿¡æ¯âœ“","confidence":0.9,"continue":true}

**User: "ç”»ä¸€åªçŒ«"**
â†’ {"type":"draw","content":"a cute cat, digital art style, warm colors","reason":"P1:ç”¨æˆ·è¦å›¾ | P2:å·²æ·»åŠ é£æ ¼ç»†èŠ‚æå‡è´¨é‡ | P3:æ»¡è¶³ç”¨æˆ·åˆ›ä½œéœ€æ±‚âœ“","confidence":0.95,"continue":false}

**User: "å¸®æˆ‘ä¿å­˜è¿™æ®µä»£ç "**
â†’ {"type":"save_file","filename":"code.py","content":"print('hello')","reason":"P1:æ˜ç¡®ä¿å­˜éœ€æ±‚ | P2:æ–‡ä»¶ååˆç† | P3:å®Œæˆç”¨æˆ·ä»»åŠ¡âœ“","confidence":1.0,"continue":false}

**User: "å›æ¡Œé¢"**
â†’ {"type":"system_control","content":"home","reason":"P1:ç”¨æˆ·è¦æ§åˆ¶è®¾å¤‡ | P2:system_controlæ˜¯å”¯ä¸€èƒ½æ‰§è¡Œæ­¤æ“ä½œçš„å·¥å…· | P3:ç›´æ¥æ‰§è¡Œæ»¡è¶³éœ€æ±‚âœ“","confidence":1.0,"continue":false}

**User: "é”å±"**
â†’ {"type":"system_control","content":"lock","reason":"P1:é”å±éœ€æ±‚ | P2:system_control.lockæ˜¯æ­£ç¡®å·¥å…· | P3:å³æ—¶æ‰§è¡Œâœ“","confidence":1.0,"continue":false}

**User: "æˆªä¸ªå›¾"**
â†’ {"type":"system_control","content":"screenshot","reason":"P1:æˆªå›¾éœ€æ±‚ | P2:system_control.screenshotä¸“ä¸ºæ­¤è®¾è®¡ | P3:ç«‹å³å®Œæˆâœ“","confidence":1.0,"continue":false}

**User: "åˆ†æä¸€ä¸‹è¿™ä¸ªé—®é¢˜"**
â†’ {"type":"reflect","content":"è®©æˆ‘ä»å¤šè§’åº¦åˆ†æè¿™ä¸ªé—®é¢˜...","reason":"P1:ç”¨æˆ·éœ€è¦æ·±åº¦åˆ†æ | P2:reflecté€‚åˆå¤æ‚æ¨ç†,åç»­å¯èƒ½éœ€è¦searchéªŒè¯ | P3:ä¸ºå†³ç­–å¥ å®šæ€è€ƒåŸºç¡€âœ“","confidence":0.7,"continue":true}

**User: "ä½ å¥½"**
â†’ {"type":"answer","content":"ä½ å¥½å‘€ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„ï¼Ÿ","reason":"P1:ç®€å•ç¤¾äº¤é—®å€™ | P2:æ— éœ€å·¥å…·,çº¯å¯¹è¯å³å¯ | P3:å‹å¥½å›åº”å»ºç«‹è¿æ¥âœ“","confidence":1.0,"continue":false}

## âœ… MULTI-STEP DECISION EXAMPLES (CRITICAL!)

**Scenario: User asks "ä»Šå¤©æ¯”ç‰¹å¸ä»·æ ¼å¤šå°‘"**

*Step 1 - Observations empty:*
â†’ {"type":"search","query":"æ¯”ç‰¹å¸ä»·æ ¼ ä»Šå¤© 2024å¹´12æœˆ","reason":"P1:ç”¨æˆ·éœ€è¦å®æ—¶ä»·æ ¼æ•°æ® | P2:searchæ˜¯è·å–å®æ—¶ä¿¡æ¯çš„æœ€ä½³å·¥å…·,å·²åŠ æ—¥æœŸé™å®š | P3:é«˜è´¨é‡æœç´¢å°†ç›´æ¥æä¾›æ‰€éœ€æ•°æ®âœ“","confidence":0.9,"continue":true}

*Step 2 - Observations now contain search results with price info:*
â†’ {"type":"answer","content":"æ ¹æ®æœ€æ–°æœç´¢ç»“æœï¼Œæ¯”ç‰¹å¸ä»Šå¤©çš„ä»·æ ¼æ˜¯...","reason":"P1:ç”¨æˆ·è¦ä»·æ ¼ä¿¡æ¯ | P2:å·²æœ‰å……åˆ†æ•°æ®,æ‰€æœ‰å¯ç”¨å·¥å…·å·²å‘æŒ¥ä½œç”¨ | P3:å¯ç»¼åˆå›ç­”æ»¡è¶³ç”¨æˆ·âœ“","confidence":0.95,"continue":false}

**Scenario: Search returned no useful results**

*Step 1:*
â†’ {"type":"search","query":"obscure topic","reason":"P1:éœ€æŸ¥è¯¢ä¿¡æ¯ | P2:searchæ˜¯é¦–é€‰ä¿¡æ¯è·å–å·¥å…· | P3:åˆæ­¥å°è¯•âœ“","continue":true}

*Step 2 - Observations show "Search returned 0 results":*
â†’ {"type":"hypothesize","content":"æœç´¢å¤±è´¥,è€ƒè™‘:1)æ¢åŒä¹‰è¯ 2)åˆ†è§£é—®é¢˜ 3)æŸ¥ç›¸å…³é¢†åŸŸ","reason":"P1:éœ€è¦æ–°æ€è·¯ | P2:hypothesizeå¸®åŠ©ç”Ÿæˆæ›¿ä»£æ–¹æ¡ˆ,é¿å…é‡å¤å¤±è´¥ | P3:ä¸ºä¸‹ä¸€æ­¥æœç´¢æä¾›æ›´å¥½æ–¹å‘âœ“","confidence":0.6,"continue":true}

*Step 3 - After hypothesizing:*
â†’ {"type":"search","query":"broader topic related terms","reason":"P1:ç»§ç»­å¯»æ‰¾ä¿¡æ¯ | P2:åŸºäºhypothesizeçš„å»ºè®®æ”¹è¿›å…³é”®è¯ | P3:æ›´é«˜æˆåŠŸæ¦‚ç‡âœ“","confidence":0.7,"continue":true}

## ğŸš« FORBIDDEN (These will FAIL!)
âŒ "æˆ‘è®¤ä¸ºéœ€è¦æœç´¢ä¸€ä¸‹..." â† è¿™ä¸æ˜¯ JSONï¼
âŒ "è®©æˆ‘å¸®ä½ æŸ¥æ‰¾..." â† è¿™ä¸æ˜¯ JSONï¼
âŒ "å¥½çš„ï¼Œæˆ‘æ¥ç”»ä¸€å¼ ..." â† è¿™ä¸æ˜¯ JSONï¼
âŒ ä»»ä½•ä¸ä»¥ { å¼€å¤´çš„å›å¤ï¼

## ğŸ“‹ DECISION RULES (Apply THREE-PASS to each!)
**FIRST, check <current_observations>:**
- If observations HAVE useful results â†’ Use "answer" to synthesize them
- If observations are EMPTY/insufficient â†’ Use tools below:

**THEN, match user intent (P1) and review tools (P2):**
1. "æœ€æ–°/ä»Šå¤©/å¤©æ°”/æ–°é—»/è‚¡ä»·/å¤šå°‘é’±" â†’ search (å®æ—¶æ•°æ®)
2. "ç”»/ç”Ÿæˆå›¾/è®¾è®¡å›¾" â†’ draw (åˆ›æ„ç”Ÿæˆ)
3. "ä¿å­˜/å¯¼å‡º/ä¸‹è½½" â†’ save_file (æ–‡ä»¶æ“ä½œ)
4. "å›æ¡Œé¢/è¿”å›/é”å±/æˆªå›¾/é€šçŸ¥" â†’ system_control (è®¾å¤‡æ§åˆ¶)
5. "åˆ†æ/æ€è€ƒ/å¤æ‚é—®é¢˜" â†’ reflect (æ·±åº¦æ¨ç†)
6. "æ¢ä¸ªè§’åº¦/è¯•è¯•åˆ«çš„" â†’ hypothesize (ç­–ç•¥è°ƒæ•´)
7. "ä½ å¥½/è°¢è°¢/å†è§" AND no complex question â†’ answer (ç¤¾äº¤å¯¹è¯)
8. æœç´¢ç»“æœä¸å¤Ÿè¯¦ç»† â†’ read_url (æ·±åº¦é˜…è¯»)
9. éœ€è¦è®°ä½/ä¿å­˜æƒ³æ³• â†’ take_note (çŸ¥è¯†ç§¯ç´¯)
10. æŸ¥è¯¢å·²ä¿å­˜çŸ¥è¯† â†’ search_knowledge / read_knowledge

## ğŸ­ PERSONA
<persona>
${_activePersona.prompt}
</persona>
å›ç­”æ—¶ç”¨è¿™ä¸ªäººæ ¼è¯­æ°”ï¼Œä½†å·¥å…·è°ƒç”¨ä¸å˜ã€‚

## ğŸ“¤ OUTPUT FORMAT: PLAN (Multi-Step) or SINGLE (One Action)

**PLAN FORMAT (for complex tasks requiring multiple API calls):**
```json
{
  "mode": "plan",
  "P1": "ç”¨æˆ·çœŸæ­£æƒ³è¦çš„æ˜¯...",
  "P2": "å°†ä½¿ç”¨ä»¥ä¸‹å·¥å…·: searchè·å–æ•°æ®, reflectåˆ†æ, answerç»¼åˆå›ç­”",
  "P3": "é¢„æœŸè¾¾æˆ: ç”¨æˆ·è·å¾—å…¨é¢å‡†ç¡®çš„ä¿¡æ¯",
  "confidence": 0.85,
  "steps": [
    {"step": 1, "type": "search", "query": "å…³é”®è¯", "purpose": "è·å–æœ€æ–°æ•°æ®", "output_as": "search_results"},
    {"step": 2, "type": "reflect", "content": "åŸºäºæœç´¢ç»“æœåˆ†æ...", "purpose": "æ·±å…¥ç†è§£", "depends_on": [1]},
    {"step": 3, "type": "answer", "content": "ç»¼åˆä»¥ä¸Šä¿¡æ¯...", "purpose": "æœ€ç»ˆå›ç­”", "depends_on": [1,2]}
  ],
  "fallback": "å¦‚æœæœç´¢å¤±è´¥ï¼Œä½¿ç”¨çŸ¥è¯†åº“æˆ–ç›´æ¥åŸºäºå·²æœ‰ä¿¡æ¯å›ç­”"
}
```

**SINGLE FORMAT (for simple one-step tasks):**
```json
{
  "mode": "single",
  "type": "search",
  "query": "æœç´¢è¯",
  "reason": "P1:ç”¨æˆ·éœ€è¦X | P2:searchæœ€é€‚åˆ | P3:å°†è·å¾—æ‰€éœ€ä¿¡æ¯",
  "confidence": 0.9,
  "continue": true
}
```

**WHEN TO USE PLAN vs SINGLE:**
- PLAN: Complex questions needing multiple tools (searchâ†’read_urlâ†’answer)
- PLAN: Tasks requiring parallel API calls (search A + search B â†’ combine)
- PLAN: Multi-phase operations (reflectâ†’searchâ†’hypothesizeâ†’answer)
- SINGLE: Simple direct actions (greetings, system control, simple search)

**PLAN STEP FIELDS:**
- step: Step number (1, 2, 3...)
- type: Tool to use (search/draw/read_url/reflect/answer/etc.)
- query/content/filename/url: Parameters for the tool
- purpose: Why this step (brief)
- depends_on: Array of step numbers that must complete first (e.g., [1,2])
- output_as: Variable name to store result for later steps (optional)
- continue_on_fail: If true, continue plan even if this step fails

## ğŸš€ PLAN TRIGGER CONDITIONS (å¿…é¡»ä½¿ç”¨PLANçš„åœºæ™¯)

**ğŸ“‹ USE PLAN MODE WHEN ANY OF THESE ARE TRUE:**
1. User asks a question needing RESEARCH + ANALYSIS + ANSWER (3+ steps)
2. User wants COMPARISON (æœç´¢A â†’ æœç´¢B â†’ å¯¹æ¯”åˆ†æ)
3. User asks "è¯¦ç»†åˆ†æ/æ·±å…¥ç ”ç©¶/å…¨é¢äº†è§£" (comprehensive request)
4. Task involves MULTIPLE data sources (ç½‘ç»œ + çŸ¥è¯†åº“ + å›¾ç‰‡)
5. User asks about pros/cons, recommendations, or complex decisions
6. First step may fail and needs fallback strategy

**ğŸ“‹ PLAN EXAMPLES:**

**User: "å¸®æˆ‘å¯¹æ¯”ä¸€ä¸‹iPhoneå’Œå®‰å“æ‰‹æœºçš„ä¼˜ç¼ºç‚¹"**
```json
{
  "mode": "plan",
  "P1": "ç”¨æˆ·éœ€è¦ä¸¤ä¸ªå¹³å°çš„å®¢è§‚å¯¹æ¯”åˆ†æ",
  "P2": "å°†ä½¿ç”¨searchè·å–ä¸¤æ–¹ä¿¡æ¯,reflectæ•´ç†å¯¹æ¯”,answerè¾“å‡ºç»“è®º",
  "P3": "é¢„æœŸ:ç”¨æˆ·è·å¾—æ¸…æ™°çš„ä¼˜ç¼ºç‚¹å¯¹æ¯”è¡¨",
  "confidence": 0.85,
  "steps": [
    {"step": 1, "type": "search", "query": "iPhoneä¼˜ç‚¹ç¼ºç‚¹ 2024", "purpose": "è·å–iOSå¹³å°ä¿¡æ¯"},
    {"step": 2, "type": "search", "query": "å®‰å“æ‰‹æœºä¼˜ç‚¹ç¼ºç‚¹ 2024", "purpose": "è·å–Androidå¹³å°ä¿¡æ¯"},
    {"step": 3, "type": "reflect", "content": "æ•´ç†ä¸¤ä¸ªå¹³å°çš„ä¼˜ç¼ºç‚¹å¯¹æ¯”...", "purpose": "æ·±å…¥åˆ†æ", "depends_on": [1,2]},
    {"step": 4, "type": "answer", "content": "å¯¹æ¯”åˆ†æç»“æœ...", "purpose": "æœ€ç»ˆå›ç­”", "depends_on": [3]}
  ],
  "fallback": "å¦‚æœæœç´¢å¤±è´¥ï¼ŒåŸºäºé€šç”¨çŸ¥è¯†å›ç­”"
}
```

**User: "æˆ‘æƒ³äº†è§£æœ€è¿‘çš„AIæ–°é—»ï¼Œå¹¶åˆ†æä¸€ä¸‹è¶‹åŠ¿"**
```json
{
  "mode": "plan",
  "P1": "ç”¨æˆ·è¦AIæ–°é—»+è¶‹åŠ¿åˆ†æ(ä¸¤ä¸ªå­ä»»åŠ¡)",
  "P2": "searchè·å–æ–°é—»,reflectåˆ†æè¶‹åŠ¿,answerç»¼åˆ",
  "P3": "é¢„æœŸ:æ–°é—»æ‘˜è¦+è¶‹åŠ¿æ´å¯Ÿ",
  "confidence": 0.8,
  "steps": [
    {"step": 1, "type": "search", "query": "AIæ–°é—» 2024å¹´12æœˆ", "purpose": "è·å–æœ€æ–°æ–°é—»"},
    {"step": 2, "type": "reflect", "content": "åˆ†æè¿™äº›æ–°é—»èƒŒåçš„è¶‹åŠ¿...", "purpose": "è¶‹åŠ¿åˆ†æ", "depends_on": [1]},
    {"step": 3, "type": "answer", "content": "", "purpose": "è¾“å‡ºæ–°é—»æ‘˜è¦å’Œè¶‹åŠ¿åˆ†æ", "depends_on": [1,2]}
  ]
}
```

**User: "æ ¹æ®æˆ‘çš„çŸ¥è¯†åº“å›ç­”è¿™ä¸ªé—®é¢˜"**
```json
{
  "mode": "plan",
  "P1": "ç”¨æˆ·è¦ä»çŸ¥è¯†åº“æå–ä¿¡æ¯",
  "P2": "search_knowledgeæ‰¾ç´¢å¼•,read_knowledgeè¯»å†…å®¹,answerå›å¤",
  "P3": "é¢„æœŸ:åŸºäºç”¨æˆ·çŸ¥è¯†åº“çš„ç²¾å‡†å›ç­”",
  "confidence": 0.9,
  "steps": [
    {"step": 1, "type": "search_knowledge", "content": "ç›¸å…³å…³é”®è¯", "purpose": "æœç´¢çŸ¥è¯†åº“æ‰¾åˆ°Chunk ID"},
    {"step": 2, "type": "read_knowledge", "content": "chunk_ids", "purpose": "è¯»å–å®Œæ•´å†…å®¹", "depends_on": [1]},
    {"step": 3, "type": "answer", "content": "", "purpose": "åŸºäºçŸ¥è¯†åº“å›ç­”", "depends_on": [2]}
  ]
}
```

**ğŸ“‹ USE SINGLE MODE WHEN:**
- Simple greeting or farewell (ä½ å¥½/è°¢è°¢/å†è§)
- Single direct action (ç”»å›¾/æœç´¢/ä¿å­˜æ–‡ä»¶/ç³»ç»Ÿæ§åˆ¶)
- User explicitly asks for ONE thing only
- <action_history> already shows progress, just need final answer

**âš ï¸ DEFAULT TO PLAN FOR COMPLEX QUESTIONS. When in doubt, use PLAN!**
''';

    final userPrompt = '''
<current_time>
$timeString
</current_time>

${autoTriggerSection.isNotEmpty ? '''
<auto_triggers>
$autoTriggerSection
</auto_triggers>
''' : ''}

<user_profile>
$memoryContent
</user_profile>
${historicalSummary.isNotEmpty ? '''
<historical_activity>
$historicalSummary
</historical_activity>
''' : ''}
<knowledge_overview>
$knowledgeOverview
</knowledge_overview>

<chat_history>
$contextBuffer
</chat_history>


<current_observations>
${refsBuffer.toString()}
</current_observations>

<action_history>
${prevActionsBuffer.toString()}
</action_history>

<user_input>
$userText
</user_input>
''';

    try {
      // Normalize URL - only remove trailing slashes, respect user's path
      String cleanBase = effectiveBase.replaceAll(RegExp(r'/+$'), '');
      final uri = Uri.parse('$cleanBase/chat/completions');
      
      // Build messages array with REAL multi-turn conversation
      // This is CRITICAL: the model needs to see its previous decisions as assistant messages
      // 
      // CUMULATIVE LEARNING: Each step must include ALL necessary context:
      // 1. System prompt (agent behavior + three-pass decision framework)
      // 2. Full user context (profile, knowledge, chat history, time, etc.)
      // 3. ALL previous decisions with their results (cumulative chain)
      // 4. Current observations (accumulated from all previous actions)
      // 5. Prompt for next decision
      //
      // The model gets SMARTER with each step because it sees:
      // - What it tried before
      // - What worked/failed
      // - All accumulated information
      // - The complete context to make better decisions
      //
      final List<Map<String, dynamic>> messages = [
        {'role': 'system', 'content': systemPrompt},
      ];
      
      // Build PLAN status indicator if we have an active plan
      String planStatusSection = '';
      if (_currentPlan != null) {
        final plan = _currentPlan!;
        final remainingSteps = plan.steps.length - _currentPlanStep;
        
        if (remainingSteps <= 0) {
          // Plan completed
          planStatusSection = '''
<plan_status>
ğŸ [PLAN COMPLETED]
Original Plan: ${plan.steps.length} steps
P1 (æ„å›¾): ${plan.userIntent}
P2 (èƒ½åŠ›): ${plan.capabilityReview}
P3 (æ•ˆæœ): ${plan.expectedOutcome}
æ‰€æœ‰è®¡åˆ’æ­¥éª¤å·²æ‰§è¡Œå®Œæ¯•ã€‚ç°åœ¨è¯·å†³å®šï¼š
- å¦‚æœä¿¡æ¯è¶³å¤Ÿ â†’ è¾“å‡º type: "answer" ç”Ÿæˆæœ€ç»ˆå›ç­”
- å¦‚æœå‘ç°æ–°éœ€æ±‚ â†’ è¾“å‡ºæ–°çš„ "mode": "plan" ç»§ç»­æ¢ç´¢
</plan_status>
''';
        } else {
          // Plan in progress (but this shouldn't happen in _planAgentStep since we execute from plan directly)
          planStatusSection = '''
<plan_status>
ğŸ“‹ [ACTIVE PLAN]
Progress: ${_currentPlanStep}/${plan.steps.length} steps completed ($remainingSteps remaining)
P1 (æ„å›¾): ${plan.userIntent}
Next Planned: Step ${_currentPlanStep + 1} - ${plan.steps[_currentPlanStep].action.name}
Note: Plan is executing. This call may be for replanning due to step failure.
</plan_status>
''';
        }
      }
      
      // ALWAYS include full context - this is the "memory" that makes the agent smarter
      // Build comprehensive context that includes EVERYTHING the model needs
      final fullContextPrompt = '''
<current_time>
$timeString
</current_time>

<user_profile>
$memoryContent
</user_profile>
${historicalSummary.isNotEmpty ? '''
<historical_activity>
$historicalSummary
</historical_activity>
''' : ''}
<knowledge_overview>
$knowledgeOverview
</knowledge_overview>
$planStatusSection
<chat_history>
$contextBuffer
</chat_history>

<user_input>
$userText
</user_input>
''';

      if (previousDecisions.isNotEmpty) {
        // ===== CUMULATIVE MULTI-STEP MODE =====
        // Each step builds on all previous knowledge
        
        // First message: Complete context + step indicator
        messages.add({'role': 'user', 'content': '''$fullContextPrompt

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š DECISION CHAIN STATUS: Step ${previousDecisions.length + 1}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
You have made ${previousDecisions.length} decision(s) so far. 
Review the complete chain below to understand what you've learned.
Each step adds to your knowledge - USE IT to make SMARTER decisions.
'''});
        
        // Add each decision-result pair as assistant-user turn
        // This creates the "learning chain" - model sees its own reasoning evolve
        for (int i = 0; i < previousDecisions.length; i++) {
          final d = previousDecisions[i];
          
          // Reconstruct the decision JSON (what the model outputted)
          final decisionJson = json.encode({
            'type': d.type.name,
            'query': d.query,
            'content': d.content,
            'filename': d.filename,
            'reason': d.reason?.replaceAll(RegExp(r'\[RESULT:[^\]]+\]'), '').trim(),
            'confidence': d.confidence,
            'continue': d.continueAfter,
          });
          
          // Add as assistant message (model's own past decision)
          messages.add({'role': 'assistant', 'content': decisionJson});
          
          // Extract result from the decision
          String resultInfo = 'Action completed.';
          if (d.reason != null && d.reason!.contains('[RESULT:')) {
            final resultMatch = RegExp(r'\[RESULT:([^\]]+)\]').firstMatch(d.reason!);
            if (resultMatch != null) {
              resultInfo = resultMatch.group(1)!.trim();
            }
          }
          
          // Build result message with learning cues
          final isLastStep = i == previousDecisions.length - 1;
          String resultMessage = '''
â•â•â• STEP ${i + 1} EXECUTION RESULT â•â•â•
$resultInfo
''';

          if (isLastStep) {
            // Final step gets full current observations and decision prompt
            resultMessage += '''

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“š ACCUMULATED OBSERVATIONS (from all ${previousDecisions.length} actions)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
${refsBuffer.toString()}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¯ DECISION REQUIRED: Step ${previousDecisions.length + 1}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“‹ CHECK OBSERVATIONS ABOVE: Look for any "ç³»ç»Ÿè§‚å¯Ÿåé¦ˆ" - these contain helpful information.

Review everything above. Apply THREE-PASS thinking:
- P1 (æ„å›¾): What does the user REALLY need?
- P2 (èƒ½åŠ›): Am I FULLY utilizing my tools? (search/draw/vision/reflect/hypothesize/read_url/knowledge...)
- P3 (æ•ˆæœ): Will this action actually achieve the user's goal?

DECISION GUIDANCE:
- If observations contain feedback about missing data â†’ Consider if a tool would help
- If you have SUFFICIENT data from real tool results â†’ type: "answer"
- If you need MORE info â†’ use appropriate tool
- If previous approach FAILED â†’ try a DIFFERENT strategy
- YOU decide - feedback is informational, not mandatory

Output your decision as JSON:
''';
          } else {
            resultMessage += '\n[Proceeding to next step...]';
          }
          
          messages.add({'role': 'user', 'content': resultMessage});
        }
      } else {
        // ===== FIRST STEP MODE =====
        // Complete context + current observations (if any from image upload etc.)
        messages.add({'role': 'user', 'content': '''$fullContextPrompt

<current_observations>
${refsBuffer.toString().isEmpty ? 'None yet - this is the FIRST planning step.' : refsBuffer.toString()}
</current_observations>

<action_history>
${prevActionsBuffer.toString()}
</action_history>

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¯ FIRST DECISION REQUIRED
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
This is Step 1. Analyze the user's request and context above.

â­ IMPORTANT: ä½ æœ‰ä¸¤ç§è¾“å‡ºæ¨¡å¼ï¼
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ PLAN MODE (mode: "plan") - ç”¨äºå¤æ‚å¤šæ­¥ä»»åŠ¡:
   é€‚ç”¨åœºæ™¯ï¼š
   - ç”¨æˆ·è¯´"ç ”ç©¶/åˆ†æ/è°ƒç ”..." â†’ éœ€è¦æœç´¢+é˜…è¯»+ç»¼åˆ
   - ç”¨æˆ·è¯´"æ¯”è¾ƒAå’ŒB" â†’ éœ€è¦å¤šæ¬¡æœç´¢+å¯¹æ¯”åˆ†æ
   - ç”¨æˆ·è¯´"å†™ä¸€ç¯‡å…³äºXçš„æŠ¥å‘Š" â†’ éœ€è¦è°ƒç ”+ç»„ç»‡+æ’°å†™
   - ä»»ä½•éœ€è¦2ä¸ªä»¥ä¸Šæ­¥éª¤æ‰èƒ½å®Œæˆçš„ä»»åŠ¡
   
ğŸ”¹ SINGLE MODE (mode: "single") - ç”¨äºå•æ­¥ä»»åŠ¡:
   é€‚ç”¨åœºæ™¯ï¼š
   - ç®€å•é—®å€™ â†’ ç›´æ¥å›ç­”
   - å•ä¸€æœç´¢é—®é¢˜ â†’ ä¸€æ¬¡æœç´¢è¶³å¤Ÿ
   - ç®€å•ç”»å›¾è¯·æ±‚ â†’ ç›´æ¥ç”»å›¾
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ’¡ STEP 1 GUIDANCE:
- If <current_observations> is empty â†’ Consider if a tool could provide useful data
- Questions about facts/news/data â†’ search usually provides better answers
- Image requests â†’ draw is the right tool
- Complex multi-step tasks â†’ USE PLAN MODE (mode: "plan")
- Simple greetings â†’ answer directly is fine

Apply THREE-PASS thinking:
- P1 (æ„å›¾): What does the user REALLY want? (underlying goal)
- P2 (èƒ½åŠ›): What tools do I have? Could any of them improve my response?
- P3 (æ•ˆæœ): Will this action lead to user satisfaction?

ğŸ“Œ IF THIS IS A COMPLEX TASK, OUTPUT PLAN FORMAT:
{
  "mode": "plan",
  "P1": "ç”¨æˆ·çœŸæ­£çš„éœ€æ±‚",
  "P2": "æˆ‘ä¼šä½¿ç”¨å“ªäº›èƒ½åŠ›",
  "P3": "é¢„æœŸè¾¾æˆä»€ä¹ˆæ•ˆæœ",
  "steps": [...]
}

ğŸ“Œ IF THIS IS A SIMPLE TASK, OUTPUT SINGLE FORMAT:
{
  "mode": "single",
  "type": "search/answer/draw/...",
  "query": "...",
  "reason": "..."
}

Output your decision as JSON:
'''});
      }
      
      final body = json.encode({
        'model': effectiveModel,
        'messages': messages,
        'stream': false,
        'temperature': 0.1, // Low temp for precise decision
        'max_tokens': 4096, // Ensure response isn't truncated
      });

      // ä½¿ç”¨å¸¦é‡è¯•çš„è¯·æ±‚
      final resp = await _postWithRetry(
        uri,
        headers: {
          'Authorization': 'Bearer $effectiveKey',
          'Content-Type': 'application/json',
        },
        body: body,
        timeout: const Duration(minutes: 3),
        maxRetries: 2,
      );

      if (resp.statusCode == 200) {
        final decodedBody = utf8.decode(resp.bodyBytes);
        final data = json.decode(decodedBody);
        String content = data['choices'][0]['message']['content'] ?? '';
        
        // DEBUG: Log the raw response to see what model actually returned
        debugPrint('=== AGENT RAW RESPONSE ===');
        debugPrint(content.length > 500 ? '${content.substring(0, 500)}...' : content);
        debugPrint('=== END RAW RESPONSE ===');
        
        // Strategy 1: Try to extract JSON directly
        final jsonStart = content.indexOf('{');
        final jsonEnd = content.lastIndexOf('}');
        
        if (jsonStart != -1 && jsonEnd != -1 && jsonEnd > jsonStart) {
          final jsonStr = content.substring(jsonStart, jsonEnd + 1);
          try {
            final parsed = json.decode(jsonStr);
            
            // Check if this is a PLAN or SINGLE mode
            final mode = parsed['mode'] as String?;
            
            if (mode == 'plan' && parsed['steps'] != null) {
              // ===== PLAN MODE: Multi-step execution =====
              debugPrint('ğŸ“‹ Detected PLAN mode with ${(parsed['steps'] as List).length} steps');
              
              final plan = AgentPlan.fromJson(parsed);
              _currentPlan = plan;
              _currentPlanStep = 0;
              
              // æ›´æ–°æ¨ç†é“¾é¢æ¿
              if (mounted) {
                setState(() {
                  _reasoningSteps = [
                    'ğŸ“‹ ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ (${plan.steps.length} æ­¥)',
                    'ğŸ¯ æ„å›¾: ${plan.userIntent}',
                    'ğŸ”§ èƒ½åŠ›: ${plan.capabilityReview}',
                    'âœ¨ é¢„æœŸ: ${plan.expectedOutcome}',
                  ];
                  _currentReasoning = 'å‡†å¤‡æ‰§è¡Œç¬¬ 1 æ­¥: ${plan.steps.first.action.name}';
                });
              }
              
              // Log the plan
              debugPrint('ğŸ“‹ Plan P1 (Intent): ${plan.userIntent}');
              debugPrint('ğŸ“‹ Plan P2 (Capability): ${plan.capabilityReview}');
              debugPrint('ğŸ“‹ Plan P3 (Outcome): ${plan.expectedOutcome}');
              for (var step in plan.steps) {
                debugPrint('   Step ${step.stepNumber}: ${step.action.name} - ${step.purpose}');
              }
              
                // Return the first step as AgentDecision
                if (plan.steps.isNotEmpty) {
                  final firstStep = plan.steps[0];
                  final rawDecision = AgentDecision(
                    type: firstStep.action,
                    query: firstStep.query,
                    content: firstStep.content,
                    filename: firstStep.filename,
                    reason: '[PLAN Step 1/${plan.steps.length}] ${firstStep.purpose} | P1:${plan.userIntent} | P2:${plan.capabilityReview} | P3:${plan.expectedOutcome}',
                    confidence: plan.overallConfidence,
                    continueAfter: plan.steps.length > 1, // Continue if more steps
                  );
                  return finalizeDecision(rawDecision);
                }
              }
              
              // ===== SINGLE MODE or legacy format =====
              debugPrint('âœ… Successfully parsed JSON (single mode), type: ${parsed['type']}');
              _currentPlan = null; // Clear any previous plan
              _currentPlanStep = 0;
              final singleDecision = AgentDecision.fromJson(parsed);
              return finalizeDecision(singleDecision);
            } catch (jsonError) {
              debugPrint('âŒ JSON parse failed: $jsonError');
              // Continue to Strategy 2
            }
          }
        
        // Strategy 2: Use Worker API to semantically parse natural language into structured intent
        // IMPORTANT: Worker parses model's "thinking" text, not user input
        // Only trust Worker if it extracts an ACTION (not just "answer")
        debugPrint('ğŸ”„ JSON parse failed, using Worker API for semantic intent extraction...');
        
        try {
          final workerDecision = await _parseIntentWithWorker(content);
            if (workerDecision != null) {
              // ğŸ”´ CRITICAL: If Worker returns "answer", it means model just rambled text
              // In this case, we should NOT trust it and fall through to regex on USER input
              if (workerDecision.type == AgentActionType.answer) {
                debugPrint('âš ï¸ Worker returned "answer" (model rambling). Falling through to regex on USER input.');
                // Don't return - fall through to Strategy 3
              } else {
                debugPrint('âœ… Worker extracted ACTION: ${workerDecision.type}');
                _currentPlan = null; // Clear plan for worker-parsed decisions
                return finalizeDecision(workerDecision);
              }
            }
        } catch (workerError) {
          debugPrint('âš ï¸ Worker intent parsing failed: $workerError, falling back to regex');
        }
        
        // Strategy 3: Fallback to regex-based extraction
        // IMPORTANT: We should analyze USER'S ORIGINAL REQUEST (userText), not model's rambling (content)
        debugPrint('ğŸ”„ Falling back to regex-based intent extraction on USER INPUT...');
        _currentPlan = null; // Clear plan for regex-parsed decisions
        
        // Use userText (user's original request) for intent detection, not model output
        final lowerUserText = userText.toLowerCase();
        
        // ====== SEARCH INTENT ======
        final searchPatterns = [
          RegExp(r'(æœç´¢|æŸ¥æ‰¾|æŸ¥è¯¢|æœä¸€ä¸‹|æŸ¥ä¸€ä¸‹|search|look up|find|å».*?æ‰¾|ç½‘ä¸Š.*?æŸ¥|äº†è§£|è·å–ä¿¡æ¯|æœ€æ–°|ä»Šå¤©|å¤šå°‘é’±|ä»·æ ¼|æ–°é—»|å¤©æ°”)', caseSensitive: false),
        ];
        for (var pattern in searchPatterns) {
          if (pattern.hasMatch(userText)) {
            // Extract any quoted text as query, or use user's input cleaned up
            final quoteMatch = RegExp('["\'â€œâ€]([^"\'â€œâ€]+)["\'â€œâ€]').firstMatch(userText);
            String query = quoteMatch?.group(1) ?? '';
            if (query.isEmpty) {
              // Use the user's text directly as search query
              query = userText.replaceAll(RegExp(r'(è¯·|å¸®æˆ‘|å‘Šè¯‰æˆ‘|æˆ‘æƒ³çŸ¥é“|ä»€ä¹ˆæ˜¯|æ€ä¹ˆ|å¦‚ä½•|å‘¢|å—|å§)'), '').trim();
            }
            if (query.length > 80) query = query.substring(0, 80);
            if (query.isEmpty) query = userText.split(' ').first;
            debugPrint('ğŸ” Regex inferred SEARCH from user input: "$query"');
            return finalizeDecision(AgentDecision(
              type: AgentActionType.search,
              query: query.isNotEmpty ? query : userText,
              reason: '[REGEX-FALLBACK] Detected search intent in user query.',
              continueAfter: true,
            ));
          }
        }
        
        // ====== DRAW INTENT ======
        final drawPatterns = [
          RegExp('(ç”»|ç»˜åˆ¶|ç”Ÿæˆå›¾ç‰‡|draw|generate image|create image)\\s*[ï¼š:"\']?(.+)', caseSensitive: false),
          RegExp('(åº”è¯¥|éœ€è¦|å¯ä»¥)\\s*(ç”»|ç»˜åˆ¶|ç”Ÿæˆ)', caseSensitive: false),
        ];
        for (var pattern in drawPatterns) {
          final match = pattern.firstMatch(userText);
          if (match != null) {
            String? prompt = match.groupCount >= 2 ? match.group(2)?.trim() : null;
            if (prompt == null || prompt.isEmpty) {
              final quoteMatch = RegExp('["\'â€œâ€]([^"\'â€œâ€]+)["\'â€œâ€]').firstMatch(userText);
              prompt = quoteMatch?.group(1) ?? userText.replaceAll(RegExp(r'(ç”»|ç»˜åˆ¶|ç”Ÿæˆ|å¸®æˆ‘|è¯·)'), '').trim();
            }
            debugPrint('ğŸ¨ Inferred DRAW from user input: "$prompt"');
            return finalizeDecision(AgentDecision(
              type: AgentActionType.draw,
              content: prompt.isNotEmpty ? prompt : 'user requested image',
              reason: '[AUTO-INFERRED] Detected draw intent in user query.',
              continueAfter: false,
            ));
          }
        }
        
        // ====== SAVE FILE INTENT ======
        if (lowerUserText.contains('ä¿å­˜') || lowerUserText.contains('save') || 
            lowerUserText.contains('å¯¼å‡º') || lowerUserText.contains('export') ||
            lowerUserText.contains('ä¸‹è½½') || lowerUserText.contains('download')) {
          // Try to find filename
          final filenameMatch = RegExp(r'[\w\-]+\.(txt|md|py|js|json|html|css|csv)').firstMatch(userText);
          final filename = filenameMatch?.group(0) ?? 'output.txt';
          debugPrint('ğŸ’¾ Inferred SAVE_FILE: $filename');
          return finalizeDecision(AgentDecision(
            type: AgentActionType.save_file,
            filename: filename,
            content: userText,
            reason: '[AUTO-INFERRED] Detected save intent.',
            continueAfter: false,
          ));
        }
        
        // ====== SYSTEM CONTROL INTENT ======
        final controlMap = {
          'home': ['å›æ¡Œé¢', 'å›ä¸»é¡µ', 'go home', 'home'],
          'back': ['è¿”å›', 'åé€€', 'go back', 'back'],
          'lock': ['é”å±', 'lock'],
          'screenshot': ['æˆªå›¾', 'æˆªå±', 'screenshot'],
          'notifications': ['é€šçŸ¥', 'é€šçŸ¥æ ', 'notifications'],
          'recents': ['æœ€è¿‘ä»»åŠ¡', 'å¤šä»»åŠ¡', 'recents', 'recent apps'],
        };
        for (var entry in controlMap.entries) {
          for (var keyword in entry.value) {
            if (lowerUserText.contains(keyword.toLowerCase())) {
              debugPrint('ğŸ“± Inferred SYSTEM_CONTROL: ${entry.key}');
              return finalizeDecision(AgentDecision(
                type: AgentActionType.system_control,
                content: entry.key,
                reason: '[AUTO-INFERRED] Detected system control intent.',
                continueAfter: false,
              ));
            }
          }
        }
        
        // ====== REFLECT INTENT ======
        if (lowerUserText.contains('åæ€') || lowerUserText.contains('æ€è€ƒ') || 
            lowerUserText.contains('åˆ†æ') || lowerUserText.contains('reflect') ||
            lowerUserText.contains('think') || lowerUserText.contains('consider')) {
          debugPrint('ğŸ¤” Inferred REFLECT');
          return finalizeDecision(AgentDecision(
            type: AgentActionType.reflect,
            content: userText.length > 300 ? userText.substring(0, 300) : userText,
            reason: '[AUTO-INFERRED] Detected reflection/thinking intent.',
            continueAfter: true,
          ));
        }
        
        // ====== CLARIFY INTENT ======
        if (userText.contains('?') || userText.contains('ï¼Ÿ') ||
            lowerUserText.contains('è¯·é—®') || lowerUserText.contains('èƒ½å¦å‘Šè¯‰') ||
            lowerUserText.contains('éœ€è¦æ›´å¤šä¿¡æ¯') || lowerUserText.contains('clarify')) {
          // This might be a question that needs search, not clarification
          // Check if it's asking about something factual
          if (lowerUserText.contains('æ˜¯ä»€ä¹ˆ') || lowerUserText.contains('å¤šå°‘') ||
              lowerUserText.contains('æ€ä¹ˆ') || lowerUserText.contains('å¦‚ä½•') ||
              lowerUserText.contains('ä¸ºä»€ä¹ˆ') || lowerUserText.contains('å“ªé‡Œ')) {
            // This is a factual question, use search
            debugPrint('ğŸ” Question detected, using SEARCH');
            return finalizeDecision(AgentDecision(
              type: AgentActionType.search,
              query: userText.replaceAll(RegExp(r'[\?ï¼Ÿ]'), '').trim(),
              reason: '[AUTO-INFERRED] User question detected, searching for answer.',
              continueAfter: true,
            ));
          }
        }
        
        // ====== KNOWLEDGE BASE INTENT ======
        if (lowerUserText.contains('çŸ¥è¯†åº“') || lowerUserText.contains('ä¸Šä¼ çš„æ–‡ä»¶') ||
            lowerUserText.contains('knowledge') || lowerUserText.contains('uploaded file')) {
          final keywordMatch = RegExp('["\'â€œâ€]([^"\'â€œâ€]+)["\'â€œâ€]').firstMatch(userText);
          final keywords = keywordMatch?.group(1) ?? userText.split('\n').first;
          debugPrint('ğŸ“š Inferred SEARCH_KNOWLEDGE: $keywords');
          return finalizeDecision(AgentDecision(
            type: AgentActionType.search_knowledge,
            content: keywords,
            reason: '[AUTO-INFERRED] Detected knowledge base search intent.',
            continueAfter: true,
          ));
        }
        
        // ====== READ URL INTENT ======
        final urlMatch = RegExp(r'https?://[^\s<>"]+').firstMatch(userText);
        if (urlMatch != null) {
          final url = urlMatch.group(0)!;
          debugPrint('ğŸŒ Inferred READ_URL: $url');
          return finalizeDecision(AgentDecision(
            type: AgentActionType.read_url,
            content: url,
            reason: '[AUTO-INFERRED] URL detected in user input.',
            continueAfter: true,
          ));
        }
        
        // ====== VISION INTENT ======
        if (lowerUserText.contains('çœ‹å›¾') || lowerUserText.contains('åˆ†æå›¾') || 
            lowerUserText.contains('å›¾ç‰‡é‡Œ') || lowerUserText.contains('å›¾ä¸­') ||
            lowerUserText.contains('analyze image') || lowerUserText.contains('çœ‹çœ‹å›¾') ||
            lowerUserText.contains('è¿™å¼ å›¾') || lowerUserText.contains('å›¾ç‰‡')) {
          debugPrint('ğŸ‘ï¸ Inferred VISION');
          return finalizeDecision(AgentDecision(
            type: AgentActionType.vision,
            content: userText,
            reason: '[AUTO-INFERRED] Detected image analysis intent.',
            continueAfter: true,
          ));
        }
        
        // ====== READ KNOWLEDGE INTENT ======
        final chunkIdMatch = RegExp(r'(chunk_\w+|è¯»å–\s*[\w_]+)').firstMatch(userText);
        if (chunkIdMatch != null || lowerUserText.contains('è¯»å–çŸ¥è¯†') || lowerUserText.contains('è·å–å—')) {
          final chunkId = chunkIdMatch?.group(0)?.replaceAll('è¯»å–', '').trim() ?? '';
          debugPrint('ğŸ“– Inferred READ_KNOWLEDGE: $chunkId');
          return finalizeDecision(AgentDecision(
            type: AgentActionType.read_knowledge,
            content: chunkId.isNotEmpty ? chunkId : userText,
            reason: '[AUTO-INFERRED] Detected knowledge reading intent.',
            continueAfter: true,
          ));
        }
        
        // ====== DELETE KNOWLEDGE INTENT ======
        if (lowerUserText.contains('åˆ é™¤çŸ¥è¯†') || lowerUserText.contains('ç§»é™¤') ||
            lowerUserText.contains('delete knowledge') || lowerUserText.contains('remove file')) {
          final idMatch = RegExp(r'[\w_-]+\.(txt|md|pdf|docx?)').firstMatch(userText);
          debugPrint('ğŸ—‘ï¸ Inferred DELETE_KNOWLEDGE');
          return finalizeDecision(AgentDecision(
            type: AgentActionType.delete_knowledge,
            content: idMatch?.group(0) ?? userText,
            reason: '[AUTO-INFERRED] Detected knowledge deletion intent.',
            continueAfter: false,
          ));
        }
        
        // ====== TAKE NOTE INTENT ======
        if (lowerUserText.contains('è®°ä¸‹') || lowerUserText.contains('è®°å½•') || 
            lowerUserText.contains('note') || lowerUserText.contains('è®°ä½')) {
          debugPrint('ğŸ“ Inferred TAKE_NOTE');
          return finalizeDecision(AgentDecision(
            type: AgentActionType.take_note,
            content: userText,
            reason: '[AUTO-INFERRED] Detected note-taking intent.',
            continueAfter: true,
          ));
        }
        
        // ====== HYPOTHESIZE INTENT ======
        if (lowerUserText.contains('å‡è®¾') || lowerUserText.contains('å¯èƒ½çš„æ–¹æ¡ˆ') || 
            lowerUserText.contains('å‡ ç§æ–¹æ³•') || lowerUserText.contains('hypothes') ||
            lowerUserText.contains('alternatives') || lowerUserText.contains('options')) {
          debugPrint('ğŸ’¡ Inferred HYPOTHESIZE');
          return finalizeDecision(AgentDecision(
            type: AgentActionType.hypothesize,
            content: userText,
            hypotheses: ['æ–¹æ¡ˆ1', 'æ–¹æ¡ˆ2'], // Placeholder
            selectedHypothesis: 'æ–¹æ¡ˆ1',
            reason: '[AUTO-INFERRED] Detected hypothesis generation intent.',
            continueAfter: true,
          ));
        }
        
        // ====== DEFAULT: Force SEARCH for any non-trivial query ======
        // If we got here, model failed to produce JSON and no specific intent matched
        final isSimpleGreeting = userText.length < 10 && 
            (lowerUserText.contains('ä½ å¥½') || lowerUserText.contains('hi') || 
             lowerUserText.contains('hello') || lowerUserText.contains('è°¢è°¢') ||
             lowerUserText.contains('å¥½çš„') || lowerUserText.contains('ok'));
        
        if (isSimpleGreeting) {
          debugPrint('ğŸ‘‹ Simple greeting detected');
          return finalizeDecision(AgentDecision(
            type: AgentActionType.answer,
            content: '',
            reason: '[GREETING] Simple greeting, no tools needed.',
          ));
        }
        
        // Check if search is available before forcing it
        if (searchAvailable) {
          // For everything else, force a search
          String searchQuery = userText.replaceAll(RegExp(r'(è¯·|å¸®æˆ‘|å‘Šè¯‰æˆ‘|æˆ‘æƒ³çŸ¥é“|ä»€ä¹ˆæ˜¯|æ€ä¹ˆ|å¦‚ä½•|å‘¢|å—|å§|ï¼Ÿ|\?)'), '').trim();
          if (searchQuery.length > 80) searchQuery = searchQuery.substring(0, 80);
          if (searchQuery.isEmpty) searchQuery = userText.split(' ').take(5).join(' ');
          
          debugPrint('ğŸ” Default fallback: SEARCH with "$searchQuery"');
          return finalizeDecision(AgentDecision(
            type: AgentActionType.search,
            query: searchQuery,
            reason: '[DEFAULT FALLBACK] No specific intent matched, using search.',
            continueAfter: true,
          ));
        } else {
          // No search available, fall back to direct answer
          debugPrint('ğŸ“ Default fallback: No search available, using answer');
          return finalizeDecision(AgentDecision(
            type: AgentActionType.answer,
            content: '',
            reason: '[DEFAULT FALLBACK] No search API configured, using direct answer.',
            continueAfter: false,
          ));
        }
        
      } else {
        debugPrint('âŒ Agent API returned status ${resp.statusCode}: ${resp.body}');
      }
    } catch (e) {
      debugPrint('âŒ Agent planning exception: $e');
    }
    
    // Fallback - API failed completely, still try to help user
    // Check if search is available before using it
    if (searchAvailable) {
      debugPrint('âš ï¸ API failed, forcing search on user query');
      String fallbackQuery = userText.replaceAll(RegExp(r'[ï¼Ÿ\?]'), '').trim();
      if (fallbackQuery.length > 60) fallbackQuery = fallbackQuery.substring(0, 60);
      
      return finalizeDecision(AgentDecision(
        type: AgentActionType.search,
        query: fallbackQuery.isNotEmpty ? fallbackQuery : 'user question',
        reason: '[API FALLBACK] API error, attempting search.',
        continueAfter: true,
      ));
    } else {
      debugPrint('âš ï¸ API failed and no search available, using direct answer');
      return finalizeDecision(AgentDecision(
        type: AgentActionType.answer,
        content: '',
        reason: '[API FALLBACK] API error and no search configured, using direct answer.',
        continueAfter: false,
      ));
    }
  }

  // _analyzeIntent removed as it is superseded by _planAgentStep and the Agent Loop.

  Future<void> _send() async {
    // Prevent concurrent sends
    if (_sending) return;
    
    final content = _inputCtrl.text.trim();
    if (content.isEmpty && _selectedImage == null) return;

    String? currentSessionImagePath;
    List<ReferenceItem> sessionRefs = [];
    
    // Knowledge search state: track pagination for batch processing
    int knowledgeSearchBatchIndex = 0;
    String lastKnowledgeSearchKeywords = '';
    
    // åˆå§‹åŒ–æ¨ç†é“¾æ˜¾ç¤º
    setState(() {
      _showReasoningPanel = true;
      _reasoningSteps = ['æ¥æ”¶ç”¨æˆ·è¯·æ±‚...'];
      _currentReasoning = 'æ­£åœ¨åˆ†ææ„å›¾...';
    });

    // 1. Handle Image Input - DON'T auto-analyze, let Agent decide between Vision and OCR
    if (_selectedImage != null) {
      // Persist the picked image
      currentSessionImagePath = await savePickedImage(_selectedImage!);
      
      setState(() {
        _messages.add(ChatMessage('user', content, localImagePath: currentSessionImagePath));
        _saveChatHistory();
        _inputCtrl.clear();
        _selectedImage = null;
        _sending = true;
        _loadingStatus = 'å‡†å¤‡å¤„ç†å›¾ç‰‡...';
      });
      _scrollToBottom();
      
      _addReasoningStep('ğŸ“· æ£€æµ‹åˆ°å›¾ç‰‡ä¸Šä¼ ');

      // Check if we have historical analysis for this image
      final historicalRefs = await _refManager.getReferencesByImageId(currentSessionImagePath);
      if (historicalRefs.isNotEmpty) {
        // Found historical analysis - use it as context
        debugPrint('Found ${historicalRefs.length} historical analysis for image');
        sessionRefs.addAll(historicalRefs);
        _addReasoningStep('ğŸ“š æ‰¾åˆ°å†å²åˆ†æè®°å½•: ${historicalRefs.length} æ¡');
      }

      // Determine user intent from text to help Agent decide
      final lowerContent = content.toLowerCase();
      final wantsOcr = RegExp(r'(ocr|è¯†åˆ«|æå–|è¯»å–|æ‰«æ|æ–‡å­—|æ–‡æœ¬|å†…å®¹|è½¬|ç¿»è¯‘|å¤åˆ¶)').hasMatch(lowerContent);
      final wantsVision = RegExp(r'(æè¿°|åˆ†æ|çœ‹|ä»€ä¹ˆ|è¿™æ˜¯|é‡Œé¢|åœºæ™¯|å›¾ç‰‡|è¯†å›¾|è§£é‡Š|ç†è§£)').hasMatch(lowerContent);
      
      // Add a pending image placeholder - Agent will decide how to analyze
      String intentHint = '';
      if (wantsOcr && !wantsVision) {
        intentHint = 'ğŸ’¡ ç”¨æˆ·æ„å›¾: æå–æ–‡å­— â†’ å»ºè®®ä½¿ç”¨ OCR';
        _addReasoningStep(intentHint);
      } else if (wantsVision && !wantsOcr) {
        intentHint = 'ğŸ’¡ ç”¨æˆ·æ„å›¾: ç†è§£å›¾ç‰‡ â†’ å»ºè®®ä½¿ç”¨ Vision';
        _addReasoningStep(intentHint);
      } else if (content.isEmpty) {
        intentHint = 'ğŸ’¡ ç”¨æˆ·æœªè¯´æ˜æ„å›¾ â†’ ç­‰å¾… Agent æ ¹æ®å›¾ç‰‡å†…å®¹å†³ç­–';
        _addReasoningStep('â³ ç­‰å¾… Agent å†³å®šåˆ†ææ–¹å¼ (Vision/OCR)');
      } else {
        intentHint = 'ğŸ’¡ æ„å›¾ä¸æ˜ç¡® â†’ Agent å°†æ™ºèƒ½åˆ¤æ–­';
        _addReasoningStep(intentHint);
      }
      
      // Add unanalyzed image marker so Agent knows there's a pending image
      sessionRefs.add(ReferenceItem(
        title: 'ğŸ“· å¾…å¤„ç†å›¾ç‰‡',
        url: currentSessionImagePath,
        snippet: '''âš ï¸ å›¾ç‰‡å·²ä¸Šä¼ ï¼Œç­‰å¾…ä½ å†³å®šå¦‚ä½•å¤„ç†ã€‚
$intentHint

æ ¹æ®ç”¨æˆ·ç›®çš„é€‰æ‹©å·¥å…·:
â€¢ ç”¨æˆ·è¦**è·å–/å¤åˆ¶/ä½¿ç”¨æ–‡å­—å†…å®¹** â†’ **ocr** (ç²¾ç¡®æå–)
â€¢ ç”¨æˆ·è¦**ç†è§£/æè¿°/åˆ†æå›¾ç‰‡** â†’ **vision** (æ™ºèƒ½ç†è§£)
â€¢ PDF/æ–‡æ¡£/æˆªå›¾ç±» â†’ é€šå¸¸ **ocr** æ›´åˆé€‚
â€¢ ç…§ç‰‡/åœºæ™¯/å›¾è¡¨ç±» â†’ é€šå¸¸ **vision** æ›´åˆé€‚

ç”¨æˆ·è¯´: ${content.isEmpty ? "(æœªè¯´æ˜ï¼Œè¯·æ ¹æ®å›¾ç‰‡ç±»å‹åˆ¤æ–­)" : content}''',
        sourceName: 'System',
        imageId: currentSessionImagePath,
        sourceType: 'pending_image',
      ));
    } else {
      // Text Only Input
      setState(() {
        _messages.add(ChatMessage('user', content));
        _saveChatHistory();
        _inputCtrl.clear();
        _sending = true; 
        _loadingStatus = 'æ­£åœ¨æ€è€ƒ...';
      });
      _scrollToBottom();
    }

    // --- Agent Execution Loop ---
    List<AgentDecision> sessionDecisions = []; // Track decisions in this session
    int steps = 0;
    const int maxSteps = 20; 
    
    // Handle Pending Clarification - restore context from previous clarify request
    if (_pendingClarification != null) {
      debugPrint('Resuming from pending clarification...');
      
      // Restore previous session context
      final prevRefs = _pendingClarification!['sessionRefs'] as List?;
      final prevDecisions = _pendingClarification!['sessionDecisions'] as List?;
      
      if (prevRefs != null) {
        for (var refJson in prevRefs) {
          sessionRefs.add(ReferenceItem.fromJson(refJson as Map<String, dynamic>));
        }
      }
      
      if (prevDecisions != null) {
        for (var decJson in prevDecisions) {
          sessionDecisions.add(AgentDecision.fromJson(decJson as Map<String, dynamic>));
        }
        steps = sessionDecisions.length; // Continue from where we left off
      }
      
      // Add user's clarification response as a special reference
      sessionRefs.add(ReferenceItem(
        title: 'âœ… ç”¨æˆ·è¡¥å……ä¿¡æ¯',
        url: 'internal://user-clarification/${DateTime.now().millisecondsSinceEpoch}',
        snippet: 'ã€åŸå§‹é—®é¢˜ã€‘${_pendingClarification!['originalQuery']}\nã€ç”¨æˆ·å›å¤ã€‘$content',
        sourceName: 'User',
        sourceType: 'user_input',
      ));
      
      // Clear pending state
      _pendingClarification = null;
    }

    // If content is empty but we have an image, provide a default context for the Agent
    final effectiveUserText = content.isEmpty && currentSessionImagePath != null 
        ? "Please analyze the image I just sent." 
        : content;

    try {
      while (steps < maxSteps) {
        AgentDecision decision;
        bool isFromPlan = false;
        int planStepIndex = -1;
        
        // Check if we have an active plan with remaining steps
        if (_currentPlan != null && _currentPlanStep < _currentPlan!.steps.length) {
          // ===== PLAN MODE: Execute next step from existing plan =====
          planStepIndex = _currentPlanStep;
          final step = _currentPlan!.steps[planStepIndex];
          isFromPlan = true;
          
          setState(() {
            _loadingStatus = 'æ‰§è¡Œè®¡åˆ’ [${planStepIndex + 1}/${_currentPlan!.steps.length}]: ${step.action.name}...';
            _currentReasoning = step.purpose;
            if (!_reasoningSteps.contains('æ‰§è¡Œ: ${step.action.name}')) {
              _reasoningSteps.add('æ‰§è¡Œ: ${step.action.name}');
            }
          });
          debugPrint('ğŸ“‹ Executing plan step ${planStepIndex + 1}: ${step.action.name}');
          
          // Check dependencies - verify that dependent steps succeeded
          bool dependenciesMet = true;
          String? failedDependency;
          for (var depStep in step.dependsOn) {
            // depStep is 1-indexed, sessionDecisions contains results
            if (depStep > sessionDecisions.length) {
              dependenciesMet = false;
              failedDependency = 'Step $depStep not yet executed';
              break;
            }
            // Check if the dependent step failed
            final depDecision = sessionDecisions[depStep - 1];
            if (depDecision.reason?.contains('FAILED') == true || 
                depDecision.reason?.contains('error') == true ||
                depDecision.reason?.contains('returned 0') == true) {
              dependenciesMet = false;
              failedDependency = 'Step $depStep failed: ${depDecision.reason}';
              break;
            }
          }
          
          if (!dependenciesMet) {
            debugPrint('âš ï¸ Step ${planStepIndex + 1} dependency failed: $failedDependency');
            
            if (step.continueOnFail) {
              // Skip this step but continue plan
              debugPrint('â­ï¸ Skipping step ${planStepIndex + 1} (continue_on_fail=true)');
              _currentPlanStep++;
              continue;
            } else {
              // Dependency failed, need to REPLAN
              debugPrint('ğŸ”„ Dependency failed, triggering REPLAN...');
              
              // Add failure note to refs so model can see what happened
              sessionRefs.add(ReferenceItem(
                title: 'âš ï¸ è®¡åˆ’æ‰§è¡Œä¸­æ–­',
                url: 'internal://plan/replan/${DateTime.now().millisecondsSinceEpoch}',
                snippet: 'åŸè®¡åˆ’æ­¥éª¤ ${planStepIndex + 1} æ— æ³•æ‰§è¡Œï¼Œä¾èµ–æ¡ä»¶æœªæ»¡è¶³: $failedDependency\n\nåŸè®¡åˆ’: P1:${_currentPlan!.userIntent} | P2:${_currentPlan!.capabilityReview}\n\nè¯·æ ¹æ®å½“å‰æƒ…å†µé‡æ–°è§„åˆ’ã€‚',
                sourceName: 'System',
                sourceType: 'system_note',
              ));
              
              // Clear plan and let model replan
              _currentPlan = null;
              _currentPlanStep = 0;
              
              // Fall through to normal planning mode
              setState(() => _loadingStatus = 'æ­£åœ¨é‡æ–°è§„åˆ’ (Step ${steps + 1})...');
              decision = await _planAgentStep(effectiveUserText, sessionRefs, sessionDecisions);
              isFromPlan = false;
            }
          } else {
            // Dependencies met, create decision from plan step
            decision = AgentDecision(
              type: step.action,
              query: step.query,
              content: step.content,
              filename: step.filename,
              reason: '[PLAN ${planStepIndex + 1}/${_currentPlan!.steps.length}] ${step.purpose}',
              confidence: _currentPlan!.overallConfidence,
              continueAfter: true, // Let plan control continuation
            );
            
            _currentPlanStep++;
          }
        } else {
          // ===== NORMAL MODE: Get next decision from API =====
          // This also handles replanning after plan completion or failure
          setState(() => _loadingStatus = 'æ­£åœ¨è§„åˆ’ (Step ${steps + 1})...');
          decision = await _planAgentStep(effectiveUserText, sessionRefs, sessionDecisions);
          
          // If a new plan was created, reset the step counter
          if (_currentPlan != null && _currentPlanStep == 0) {
            // Plan was just created in _planAgentStep, first step is already returned
            _currentPlanStep = 1;
            isFromPlan = true;
            planStepIndex = 0;
          }
        }
        
        sessionDecisions.add(decision); // Record decision
        
        // Handle Reminders (Side Effect)
        if (decision.reminders != null) {
          for (var r in decision.reminders!) {
            if (r['time'] != null && r['message'] != null) {
              try {
                final time = DateTime.parse(r['time']);
                if (time.isAfter(DateTime.now())) {
                  _scheduleReminder(_activePersona.name, r['message'], time);
                }
              } catch (e) {
                debugPrint('Error parsing reminder time: $e');
              }
            }
          }
        }

        // B. Act (Execute Decision) - with plan-aware result handling
        bool stepSucceeded = true;
        String stepResult = '';
        
        if (decision.type == AgentActionType.search && decision.query != null) {
          // Action: Search
          setState(() => _loadingStatus = 'æ­£åœ¨æœç´¢: ${decision.query}...');
          debugPrint('Agent searching for: ${decision.query}');
          
          try {
            final newRefs = await _refManager.search(decision.query!);
            if (newRefs.isNotEmpty) {
              // Deduplicate by URL before adding
              final existingUrls = sessionRefs.map((r) => r.url).toSet();
              final uniqueNewRefs = newRefs.where((r) => !existingUrls.contains(r.url)).toList();
              if (uniqueNewRefs.isNotEmpty) {
                stepSucceeded = true;
                stepResult = 'Found ${uniqueNewRefs.length} results';
                
                // æ›´æ–°æ¨ç†é“¾
                setState(() {
                  _reasoningSteps.add('âœ… æœç´¢ "${decision.query}" è¿”å› ${uniqueNewRefs.length} æ¡ç»“æœ');
                });
                
                // Check if synthesis is enabled
                final prefs = await SharedPreferences.getInstance();
                final enableSynthesis = prefs.getBool('enable_search_synthesis') ?? true;
                
                // Track search count for context
                final searchCount = sessionDecisions.where((d) => d.type == AgentActionType.search).length;
                
                if (enableSynthesis) {
                  // Synthesize search results using Worker API for global perspective
                  setState(() => _loadingStatus = 'æ­£åœ¨ç»¼åˆåˆ†ææœç´¢ç»“æœ (æœç´¢#$searchCount)...');
                  try {
                    final synthesisResult = await _refManager.synthesizeSearchResults(
                      refs: uniqueNewRefs,
                      query: decision.query!,
                    );
                    
                    // Add synthesis first if available (so Agent sees global perspective first)
                    final synthesisRef = synthesisResult['synthesis'] as ReferenceItem?;
                    if (synthesisRef != null) {
                      // Enhance synthesis with search context
                      final enhancedSynthesis = ReferenceItem(
                        title: 'ğŸŒ æœç´¢#$searchCount ç»¼åˆåˆ†æ (æŸ¥è¯¢: ${decision.query})',
                        url: synthesisRef.url,
                        snippet: 'ã€æœ¬æ¬¡æœç´¢ã€‘"${decision.query}" è¿”å› ${uniqueNewRefs.length} æ¡ç»“æœ\nã€æ¥æºè¦†ç›–ã€‘${uniqueNewRefs.map((r) => r.sourceName).toSet().join(", ")}\n\n${synthesisRef.snippet}',
                        sourceName: synthesisRef.sourceName,
                        sourceType: 'synthesis',
                        reliability: synthesisRef.reliability,
                        authorityLevel: synthesisRef.authorityLevel,
                        contentDate: synthesisRef.contentDate,
                      );
                      sessionRefs.add(enhancedSynthesis);
                      debugPrint('Added global synthesis perspective for search #$searchCount');
                      
                      // Extract synthesis data for enhanced Agent decision feedback
                      final synthesisData = synthesisResult['synthesisData'] as Map<String, dynamic>?;
                      if (synthesisData != null) {
                        final blindSpots = synthesisData['blind_spots'] as List?;
                        final confidence = synthesisData['confidence_level'] as num?;
                        if (blindSpots != null && blindSpots.isNotEmpty) {
                          debugPrint('Synthesis identified blind spots: $blindSpots');
                          // Add blind spots info to action history for Agent awareness
                          sessionDecisions.last = AgentDecision(
                            type: AgentActionType.search,
                            query: decision.query,
                            reason: '${decision.reason} [RESULT: Found ${uniqueNewRefs.length} results. Synthesis confidence: ${((confidence ?? 0.7) * 100).round()}%. Blind spots: ${blindSpots.join("; ")}]',
                          );
                        }
                      }
                    }
                  } catch (synthError) {
                    debugPrint('Synthesis failed (non-critical): $synthError');
                    // Continue without synthesis - non-critical failure
                  }
                }
                
                // Add individual refs after synthesis
                sessionRefs.addAll(uniqueNewRefs);
                debugPrint('Added ${uniqueNewRefs.length} unique refs (${newRefs.length - uniqueNewRefs.length} duplicates skipped)');
                
                // Record success with result summary (if not already set by synthesis)
                if (sessionDecisions.last.reason?.contains('Blind spots') != true) {
                  final topTitles = uniqueNewRefs.take(3).map((r) => r.title).join(', ');
                  final avgReliability = uniqueNewRefs.fold(0.0, (sum, r) => sum + (r.reliability ?? 0.5)) / uniqueNewRefs.length;
                  sessionDecisions.last = AgentDecision(
                    type: AgentActionType.search,
                    query: decision.query,
                    reason: '${decision.reason} [RESULT: Found ${uniqueNewRefs.length} results (avg reliability: ${(avgReliability * 100).round()}%) - $topTitles]',
                  );
                }
              }
              // Continue loop to re-evaluate with new info
              steps++;
              continue;
            } else {
              // Search returned nothing - let planner decide next action (may rewrite query)
              debugPrint('Search returned no results. Continuing to let planner rewrite query.');
              stepSucceeded = false;
              stepResult = 'Search returned 0 results';
              
              // Explicitly add a system note to observations so the Agent SEES the failure
              sessionRefs.add(ReferenceItem(
                title: 'System Notification: Search Failed',
                url: 'internal://system/search-failed',
                snippet: 'Search for "${decision.query}" returned 0 results. Please try different keywords or a broader topic.',
                sourceName: 'System',
                sourceType: 'system_note',
              ));

              // Mark this in action history so planner knows to try different keywords
              final searchAttempt = sessionDecisions.where((d) => d.type == AgentActionType.search).length;
              sessionDecisions.last = AgentDecision(
                type: AgentActionType.search,
                query: decision.query,
                reason: '${decision.reason} [RESULT: FAILED - Search #$searchAttempt returned 0 results. Suggestions: 1) Use different keywords 2) Broaden query 3) Try English terms]',
              );
              
              // ğŸ”´ PLAN SELF-ADJUSTMENT: If this was from a plan, trigger replanning
              if (isFromPlan && _currentPlan != null) {
                debugPrint('ğŸ”„ Plan step failed (search 0 results), triggering REPLAN...');
                sessionRefs.add(ReferenceItem(
                  title: 'ğŸ”„ è®¡åˆ’è°ƒæ•´é€šçŸ¥',
                  url: 'internal://plan/replan/${DateTime.now().millisecondsSinceEpoch}',
                  snippet: 'åŸè®¡åˆ’æ­¥éª¤ ${planStepIndex + 1} æ‰§è¡Œå¤±è´¥: $stepResult\nåŸè®¡åˆ’ P1 æ„å›¾: ${_currentPlan!.userIntent}\nè¯·æ ¹æ®å½“å‰æƒ…å†µè°ƒæ•´è®¡åˆ’ã€‚',
                  sourceName: 'System',
                  sourceType: 'system_note',
                ));
                _currentPlan = null;
                _currentPlanStep = 0;
                steps++;
                continue; // Let next iteration call _planAgentStep to replan
              }
              
              // Check if we've had too many empty searches
              final emptySearches = sessionDecisions.where((d) => 
                d.type == AgentActionType.search && d.reason?.contains('[RESULT:') == true && d.reason?.contains('returned 0') == true
              ).length;
              if (emptySearches >= 3) {
                debugPrint('3+ empty searches, forcing answer.');
                setState(() => _loadingStatus = 'å¤šæ¬¡æœç´¢æ— ç»“æœï¼Œæ­£åœ¨ç”Ÿæˆå›ç­”...');
                await _performChatRequest(content, localImage: currentSessionImagePath, references: sessionRefs, manageSendingState: false);
                break;
              }
              // Otherwise continue loop - planner will see empty result in action history
              steps++;
              continue;
            }
          } catch (searchError) {
            // Search failed - record in action history for planner visibility
            debugPrint('Search failed: $searchError');
            stepSucceeded = false;
            stepResult = 'Search error: $searchError';
            
            // æ›´æ–°æ¨ç†é¢æ¿
            if (mounted) {
              setState(() {
                _reasoningSteps.add('âŒ æœç´¢å¤±è´¥: ${decision.query}');
                _currentReasoning = 'æ­£åœ¨è€ƒè™‘å¤‡é€‰æ–¹æ¡ˆ...';
              });
            }
            
            // Add error note so Agent can see and try alternative approach
            sessionRefs.add(ReferenceItem(
              title: 'âš ï¸ æœç´¢å¤±è´¥',
              url: 'internal://error/search/${DateTime.now().millisecondsSinceEpoch}',
              snippet: 'æœç´¢ "${decision.query}" å¤±è´¥: $searchError\n\nå¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:\n1. å°è¯•ä¸åŒçš„å…³é”®è¯\n2. ä½¿ç”¨çŸ¥è¯†åº“ (search_knowledge)\n3. ç›´æ¥å›ç­”å·²çŸ¥ä¿¡æ¯',
              sourceName: 'System',
              sourceType: 'system_note',
            ));
            
            sessionDecisions.last = AgentDecision(
              type: AgentActionType.search,
              query: decision.query,
              reason: '${decision.reason} [RESULT: FAILED - Search error - $searchError. Agent should try alternatives.]',
            );
            
            // ğŸ”´ PLAN SELF-ADJUSTMENT: If from plan, trigger replanning
            if (isFromPlan && _currentPlan != null) {
              debugPrint('ğŸ”„ Plan step failed (search error), triggering REPLAN...');
              sessionRefs.add(ReferenceItem(
                title: 'ğŸ”„ è®¡åˆ’è°ƒæ•´é€šçŸ¥',
                url: 'internal://plan/replan/${DateTime.now().millisecondsSinceEpoch}',
                snippet: 'åŸè®¡åˆ’æ­¥éª¤ ${planStepIndex + 1} æ‰§è¡Œå¤±è´¥: $stepResult\næœç´¢æœåŠ¡å¼‚å¸¸ï¼Œè¯·è°ƒæ•´ç­–ç•¥ï¼ˆå¦‚ä½¿ç”¨çŸ¥è¯†åº“æˆ–ç›´æ¥å›ç­”ï¼‰ã€‚',
                sourceName: 'System',
                sourceType: 'system_note',
              ));
              _currentPlan = null;
              _currentPlanStep = 0;
              steps++;
              continue;
            }
            
            // Count search failures
            final searchFailures = sessionDecisions.where((d) => 
              d.type == AgentActionType.search && d.reason?.contains('Search error') == true
            ).length;
            
            if (searchFailures >= 3) {
              // Too many failures, force answer
              debugPrint('3+ search failures, forcing answer.');
              setState(() => _loadingStatus = 'æœç´¢æœåŠ¡ä¸å¯ç”¨ï¼Œæ­£åœ¨ç”Ÿæˆå›ç­”...');
              await _performChatRequest(content, localImage: currentSessionImagePath, references: sessionRefs, manageSendingState: false);
              break;
            }
            
            // Continue loop - let Agent try alternative approach
            steps++;
            continue;
          }
        }
        else if (decision.type == AgentActionType.read_url && decision.content != null) {
          // Action: Read URL content - deep read a specific webpage
          final url = decision.content!.trim();
          
          // ğŸ”’ Pre-check: Network access requires search API to be configured
          final prefs = await SharedPreferences.getInstance();
          final hasNetworkAccess = (prefs.getString('exa_key') ?? '').isNotEmpty ||
                                   (prefs.getString('you_key') ?? '').isNotEmpty ||
                                   (prefs.getString('brave_key') ?? '').isNotEmpty;
          if (!hasNetworkAccess) {
            debugPrint('âš ï¸ read_url requested but no network API configured');
            sessionRefs.add(ReferenceItem(
              title: 'âš ï¸ ç½‘é¡µè¯»å–å¤±è´¥',
              url: 'internal://error/read_url-no-api/${DateTime.now().millisecondsSinceEpoch}',
              snippet: 'æ— æ³•è¯»å–ç½‘é¡µï¼šæœªé…ç½®æœç´¢/ç½‘ç»œAPIã€‚\nè¯·åœ¨è®¾ç½®ä¸­é…ç½® Exaã€You.com æˆ– Brave Search APIã€‚',
              sourceName: 'System',
              sourceType: 'feedback',
            ));
            sessionDecisions.last = AgentDecision(
              type: AgentActionType.read_url,
              content: url,
              reason: '${decision.reason} [RESULT: FAILED - No network API configured. Cannot access web.]',
            );
            steps++;
            continue;
          }
          
          setState(() {
            _loadingStatus = 'æ­£åœ¨é˜…è¯»ç½‘é¡µå†…å®¹...';
            _currentReasoning = 'è¯»å–: $url';
          });
          debugPrint('Agent reading URL: $url');
          
          try {
            final urlRef = await _refManager.fetchUrlContent(url);
            
            // Check if fetch was successful
            if ((urlRef.reliability ?? 0.0) > 0.0) {
              // Success - add to session refs
              sessionRefs.add(urlRef);
              stepSucceeded = true;
              stepResult = 'Read ${urlRef.snippet.length} chars from ${urlRef.sourceName}';
              
              // æ›´æ–°æ¨ç†é“¾
              if (mounted) {
                setState(() {
                  _reasoningSteps.add('âœ… è¯»å–ç½‘é¡µ "${urlRef.title}" (${urlRef.snippet.length} å­—ç¬¦)');
                });
              }
              
              final contentLength = urlRef.snippet.length;
              sessionDecisions.last = AgentDecision(
                type: AgentActionType.read_url,
                content: url,
                reason: '${decision.reason} [RESULT: Successfully read $contentLength chars from ${urlRef.sourceName}. Title: "${urlRef.title}"]',
                continueAfter: decision.continueAfter,
              );
              debugPrint('URL read success: $contentLength chars');
            } else {
              // Failed to fetch
              stepSucceeded = false;
              stepResult = 'Failed to read URL: ${urlRef.snippet}';
              
              // æ›´æ–°æ¨ç†é“¾
              if (mounted) {
                setState(() {
                  _reasoningSteps.add('âŒ è¯»å–ç½‘é¡µå¤±è´¥: $url');
                });
              }
              
              sessionRefs.add(urlRef); // Still add error ref for Agent awareness
              sessionDecisions.last = AgentDecision(
                type: AgentActionType.read_url,
                content: url,
                reason: '${decision.reason} [RESULT: FAILED to read URL. Error: ${urlRef.snippet}]',
              );
              
              // ğŸ”´ PLAN SELF-ADJUSTMENT: If from plan, trigger replanning
              if (isFromPlan && _currentPlan != null) {
                debugPrint('ğŸ”„ Plan step failed (URL read failed), triggering REPLAN...');
                sessionRefs.add(ReferenceItem(
                  title: 'ğŸ”„ è®¡åˆ’è°ƒæ•´é€šçŸ¥',
                  url: 'internal://plan/replan/${DateTime.now().millisecondsSinceEpoch}',
                  snippet: 'åŸè®¡åˆ’æ­¥éª¤ ${planStepIndex + 1} æ‰§è¡Œå¤±è´¥: æ— æ³•è¯»å–URL $url\nè¯·è°ƒæ•´ç­–ç•¥ï¼ˆå¦‚æœç´¢å…¶ä»–æ¥æºæˆ–ä½¿ç”¨å·²æœ‰ä¿¡æ¯ï¼‰ã€‚',
                  sourceName: 'System',
                  sourceType: 'system_note',
                ));
                _currentPlan = null;
                _currentPlanStep = 0;
                steps++;
                continue;
              }
            }
            
            if (!decision.continueAfter) {
              // No continue flag, trigger answer
              setState(() => _loadingStatus = 'æ­£åœ¨ç”Ÿæˆå›ç­”...');
              await _performChatRequest(content, localImage: currentSessionImagePath, references: sessionRefs, manageSendingState: false);
              break;
            }
            // Continue looping if continue flag is set
            steps++;
            continue;
          } catch (e) {
            debugPrint('read_url error: $e');
            stepSucceeded = false;
            stepResult = 'URL read exception: $e';
            
            sessionDecisions.last = AgentDecision(
              type: AgentActionType.read_url,
              content: url,
              reason: '${decision.reason} [RESULT: FAILED - Exception - $e]',
            );
            
            // ğŸ”´ PLAN SELF-ADJUSTMENT: If from plan, trigger replanning
            if (isFromPlan && _currentPlan != null) {
              debugPrint('ğŸ”„ Plan step failed (URL exception), triggering REPLAN...');
              sessionRefs.add(ReferenceItem(
                title: 'ğŸ”„ è®¡åˆ’è°ƒæ•´é€šçŸ¥',
                url: 'internal://plan/replan/${DateTime.now().millisecondsSinceEpoch}',
                snippet: 'åŸè®¡åˆ’æ­¥éª¤ ${planStepIndex + 1} æ‰§è¡Œå¤±è´¥: URLè¯»å–å¼‚å¸¸ - $e\nè¯·è°ƒæ•´ç­–ç•¥ã€‚',
                sourceName: 'System',
                sourceType: 'system_note',
              ));
              _currentPlan = null;
              _currentPlanStep = 0;
              steps++;
              continue;
            }
            
            // Fallback to answer
            setState(() => _loadingStatus = 'ç½‘é¡µè¯»å–å¤±è´¥ï¼Œæ­£åœ¨å›ç­”...');
            await _performChatRequest(content, localImage: currentSessionImagePath, references: sessionRefs, manageSendingState: false);
            break;
          }
        } 
        else if (decision.type == AgentActionType.draw && decision.content != null) {
          // Action: Draw
          
          // ğŸ”’ Pre-check: Is Draw API configured?
          if (_imgBase.contains('your-oneapi-host') || _imgKey.isEmpty) {
            debugPrint('âš ï¸ draw requested but Draw API not configured');
            if (mounted) {
              setState(() {
                _reasoningSteps.add('âŒ ç”Ÿå›¾APIæœªé…ç½®');
              });
            }
            sessionRefs.add(ReferenceItem(
              title: 'âš ï¸ å›¾ç‰‡ç”Ÿæˆå¤±è´¥',
              url: 'internal://error/draw-no-api/${DateTime.now().millisecondsSinceEpoch}',
              snippet: 'æ— æ³•ç”Ÿæˆå›¾ç‰‡ï¼šæœªé…ç½®ç”Ÿå›¾APIã€‚\nè¯·åœ¨è®¾ç½®ä¸­é…ç½®å›¾ç‰‡ç”ŸæˆAPIï¼ˆå¦‚ DALL-Eï¼‰ã€‚\nå»ºè®®ï¼šå‘ŠçŸ¥ç”¨æˆ·éœ€è¦å…ˆé…ç½®APIã€‚',
              sourceName: 'System',
              sourceType: 'feedback',
            ));
            sessionDecisions.last = AgentDecision(
              type: AgentActionType.draw,
              content: decision.content,
              reason: '${decision.reason} [RESULT: FAILED - Draw API not configured. Cannot generate images.]',
            );
            steps++;
            continue;
          }
          
          setState(() {
            _loadingStatus = 'æ­£åœ¨ç”Ÿæˆå›¾ç‰‡...';
            _currentReasoning = 'ç»˜åˆ¶: ${decision.content!.length > 30 ? decision.content!.substring(0, 30) + "..." : decision.content}';
          });
          final generatedPath = await _performImageGeneration(decision.content!, addUserMessage: false, manageSendingState: false);
          if (generatedPath != null) {
            // æ›´æ–°æ¨ç†é“¾
            if (mounted) {
              setState(() {
                _reasoningSteps.add('âœ… å›¾ç‰‡ç”ŸæˆæˆåŠŸ');
              });
            }
            
            // Auto-analyze the generated image to get rich semantic info
            setState(() => _loadingStatus = 'æ­£åœ¨åˆ†æç”Ÿæˆçš„å›¾ç‰‡...');
            String imageDescription = 'å›¾ç‰‡å·²æ ¹æ®æç¤ºè¯ç”Ÿæˆ: ${decision.content}';
            String analysisStatus = 'pending';
            try {
              final genVisionRefs = await analyzeImage(
                imagePath: generatedPath,
                baseUrl: _visionBase,
                apiKey: _visionKey,
                model: _visionModel,
                userPrompt: 'è¯·ç®€æ´æè¿°è¿™å¼ AIç”Ÿæˆçš„å›¾ç‰‡å†…å®¹ï¼ŒåŒ…æ‹¬ä¸»ä½“ã€é£æ ¼ã€è‰²è°ƒã€‚ä¸€æ®µè¯å³å¯ã€‚',
                fallbackBaseUrl: _chatBase,
                fallbackApiKey: _chatKey,
                fallbackModel: _chatModel,
              );
              if (genVisionRefs.isNotEmpty && !genVisionRefs.first.snippet.contains('âš ï¸')) {
                imageDescription = 'ã€æç¤ºè¯ã€‘${decision.content}\nã€å®é™…ç”Ÿæˆã€‘${genVisionRefs.first.snippet}';
                analysisStatus = 'analyzed';
              } else {
                analysisStatus = 'analysis_failed';
              }
            } catch (e) {
              debugPrint('Auto-analyze generated image failed: $e');
              analysisStatus = 'analysis_error';
            }
            
            // Count generated images for context
            final genCount = sessionRefs.where((r) => r.sourceType == 'generated').length + 1;
            
            // Success - record in action history with rich feedback
            sessionDecisions.last = AgentDecision(
              type: AgentActionType.draw,
              content: decision.content,
              reason: '${decision.reason} [RESULT: Image #$genCount generated successfully. Analysis: $analysisStatus. ${analysisStatus == 'analyzed' ? 'Content verified.' : 'Manual verification recommended.'}]',
              continueAfter: decision.continueAfter,
            );
            
            // Add generated image info with rich description to sessionRefs
            sessionRefs.add(ReferenceItem(
              title: 'ğŸ¨ ç”Ÿæˆçš„å›¾ç‰‡ #$genCount',
              url: generatedPath,
              snippet: imageDescription,
              sourceName: 'ImageGen',
              imageId: generatedPath,
              sourceType: 'generated',
            ));
            // If continue flag is set, keep looping (e.g., to add a comment about the image)
            if (!decision.continueAfter) {
              break;
            }
            steps++;
            continue;
          } else {
            // Generation returned null (failed)
            debugPrint('Draw returned null');
            stepSucceeded = false;
            stepResult = 'Image generation failed';
            
            final failedPrompt = decision.content ?? '';
            sessionDecisions.last = AgentDecision(
              type: AgentActionType.draw,
              content: decision.content,
              reason: '${decision.reason} [RESULT: FAILED - Draw FAILED. Possible causes: 1) Invalid prompt 2) Content policy violation 3) API error. Prompt was: "${failedPrompt.length > 50 ? failedPrompt.substring(0, 50) + "..." : failedPrompt}"]',
            );
            
            // ğŸ”´ PLAN SELF-ADJUSTMENT: If from plan, trigger replanning
            if (isFromPlan && _currentPlan != null) {
              debugPrint('ğŸ”„ Plan step failed (draw failed), triggering REPLAN...');
              sessionRefs.add(ReferenceItem(
                title: 'ğŸ”„ è®¡åˆ’è°ƒæ•´é€šçŸ¥',
                url: 'internal://plan/replan/${DateTime.now().millisecondsSinceEpoch}',
                snippet: 'åŸè®¡åˆ’æ­¥éª¤ ${planStepIndex + 1} æ‰§è¡Œå¤±è´¥: å›¾ç‰‡ç”Ÿæˆå¤±è´¥\næç¤ºè¯: "${failedPrompt.length > 100 ? failedPrompt.substring(0, 100) + "..." : failedPrompt}"\nè¯·è°ƒæ•´ç­–ç•¥ï¼ˆå¦‚ä¿®æ”¹æç¤ºè¯æˆ–å‘ŠçŸ¥ç”¨æˆ·ï¼‰ã€‚',
                sourceName: 'System',
                sourceType: 'system_note',
              ));
              _currentPlan = null;
              _currentPlanStep = 0;
              steps++;
              continue;
            }
            
            // Fallback to answer explaining the failure
            setState(() => _loadingStatus = 'ç”Ÿå›¾å¤±è´¥ï¼Œæ­£åœ¨å›å¤...');
            await _performChatRequest(content, localImage: currentSessionImagePath, references: sessionRefs, manageSendingState: false);
            break;
          }
        }
        else if (decision.type == AgentActionType.read_knowledge && decision.content != null) {
          // Action: Read Knowledge Chunk(s) - supports multiple IDs separated by comma
          setState(() => _loadingStatus = 'æ­£åœ¨è¯»å–çŸ¥è¯†åº“...');
          
          // Parse chunk IDs (support comma-separated for batch reading)
          final chunkIds = decision.content!
              .split(RegExp(r'[,\s]+'))
              .map((id) => id.trim())
              .where((id) => id.isNotEmpty)
              .toList();
          
          final successfulReads = <String>[];
          final failedReads = <String>[];
          final combinedContent = StringBuffer();
          int totalChars = 0;
          const maxTotalChars = 40000; // ç”¨æˆ·APIæ”¯æŒ60K tokens
          
          for (final chunkId in chunkIds) {
            if (totalChars >= maxTotalChars) {
              failedReads.add('$chunkId (skipped: context limit reached)');
              continue;
            }
            
            final chunkContent = _knowledgeService.getChunkContent(chunkId);
            if (chunkContent != null) {
              successfulReads.add(chunkId);
              
              // Calculate remaining budget
              final remaining = maxTotalChars - totalChars;
              String displayContent = chunkContent;
              if (chunkContent.length > remaining) {
                displayContent = '${chunkContent.substring(0, remaining)}\n[... truncated to fit context limit]';
              }
              
              combinedContent.writeln('â•â•â• Chunk [$chunkId] â•â•â•');
              combinedContent.writeln(displayContent);
              combinedContent.writeln('');
              totalChars += displayContent.length;
              // Don't add individual refs here - we'll add a combined one later
            } else {
              failedReads.add(chunkId);
            }
          }
          
          // Build result message
          String resultMsg;
          if (successfulReads.isNotEmpty) {
            resultMsg = 'Read ${successfulReads.length} chunk(s): ${successfulReads.join(", ")} ($totalChars chars total)';
            if (failedReads.isNotEmpty) {
              resultMsg += '. Failed: ${failedReads.join(", ")}';
            }
          } else {
            // All failed
            stepSucceeded = false;
            stepResult = 'All knowledge chunks not found';
            
            final availableIds = _knowledgeService.getAllChunkIds();
            final suggestion = availableIds.isNotEmpty 
                ? 'Available IDs: ${availableIds.take(5).join(", ")}${availableIds.length > 5 ? "..." : ""}'
                : 'Knowledge base is empty.';
            resultMsg = 'FAILED - All chunks NOT FOUND: ${failedReads.join(", ")}. $suggestion';
            
            sessionRefs.add(ReferenceItem(
              title: 'âš ï¸ çŸ¥è¯†åº“æŸ¥è¯¢å¤±è´¥',
              url: 'internal://knowledge/error',
              snippet: 'Requested chunks not found.\n$suggestion',
              sourceName: 'KnowledgeBase',
              sourceType: 'system_note',
            ));
            
            // ğŸ”´ PLAN SELF-ADJUSTMENT
            if (isFromPlan && _currentPlan != null) {
              debugPrint('ğŸ”„ Plan step failed (knowledge not found), triggering REPLAN...');
              sessionRefs.add(ReferenceItem(
                title: 'ğŸ”„ è®¡åˆ’è°ƒæ•´é€šçŸ¥',
                url: 'internal://plan/replan/${DateTime.now().millisecondsSinceEpoch}',
                snippet: 'åŸè®¡åˆ’æ­¥éª¤ ${planStepIndex + 1} æ‰§è¡Œå¤±è´¥: çŸ¥è¯†åº“å†…å®¹æœªæ‰¾åˆ°\nè¯·è°ƒæ•´ç­–ç•¥ï¼ˆå¦‚ä½¿ç”¨search_knowledgeæœç´¢æˆ–ä½¿ç”¨å…¶ä»–å·¥å…·ï¼‰ã€‚',
                sourceName: 'System',
                sourceType: 'system_note',
              ));
              _currentPlan = null;
              _currentPlanStep = 0;
            }
          }
          
          // Add combined content as a single comprehensive reference
          if (successfulReads.isNotEmpty) {
            sessionRefs.add(ReferenceItem(
              title: 'ğŸ“– çŸ¥è¯†åº“å†…å®¹ [${successfulReads.join(", ")}]',
              url: 'internal://knowledge/read',
              snippet: combinedContent.toString(),
              sourceName: 'KnowledgeBase',
              sourceType: 'knowledge',
            ));
          }
          
          sessionDecisions.last = AgentDecision(
            type: AgentActionType.read_knowledge,
            content: decision.content,
            reason: '${decision.reason} [RESULT: $resultMsg]',
            continueAfter: true,
          );
          
          // Explicitly continue loop - Agent needs to process the retrieved content
          steps++;
          continue;
        }
        else if (decision.type == AgentActionType.delete_knowledge && decision.content != null) {
          // Action: Delete from Knowledge Base
          setState(() => _loadingStatus = 'æ­£åœ¨åˆ é™¤çŸ¥è¯†åº“å†…å®¹...');
          final targetId = decision.content!;
          
          // Try to delete as file first, then as chunk
          bool deleted = await _knowledgeService.deleteFile(targetId);
          String deleteType = 'file';
          
          if (!deleted) {
            deleted = await _knowledgeService.deleteChunk(targetId);
            deleteType = 'chunk';
          }
          
          if (deleted) {
            final stats = _knowledgeService.getStats();
            sessionDecisions.last = AgentDecision(
              type: AgentActionType.delete_knowledge,
              content: targetId,
              reason: '${decision.reason} [RESULT: Successfully deleted $deleteType $targetId]',
              continueAfter: true,
            );
            
            sessionRefs.add(ReferenceItem(
              title: 'ğŸ—‘ï¸ çŸ¥è¯†åº“å·²æ›´æ–°',
              url: 'internal://knowledge/deleted/$targetId',
              snippet: 'å·²åˆ é™¤ $deleteType: $targetId\nå½“å‰çŸ¥è¯†åº“: ${stats['fileCount']} ä¸ªæ–‡ä»¶, ${stats['chunkCount']} ä¸ªçŸ¥è¯†å—',
              sourceName: 'KnowledgeBase',
              sourceType: 'system',
            ));
          } else {
            sessionDecisions.last = AgentDecision(
              type: AgentActionType.delete_knowledge,
              content: targetId,
              reason: '${decision.reason} [RESULT: Failed to delete - ID $targetId not found]',
              continueAfter: true,
            );
            
            sessionRefs.add(ReferenceItem(
              title: 'âš ï¸ åˆ é™¤å¤±è´¥',
              url: 'internal://knowledge/delete-error',
              snippet: 'ID "$targetId" åœ¨çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ã€‚',
              sourceName: 'KnowledgeBase',
              sourceType: 'system_note',
            ));
          }
          steps++;
          continue;
        }
        else if (decision.type == AgentActionType.search_knowledge && decision.content != null) {
          // Action: Search Knowledge Base
          setState(() {
            _loadingStatus = 'æ­£åœ¨æœç´¢çŸ¥è¯†åº“...';
            _currentReasoning = 'æœç´¢çŸ¥è¯†åº“: ${decision.content}';
          });
          final keywords = decision.content!;
          
          // Check if this is a continuation of previous search (for pagination)
          if (keywords == lastKnowledgeSearchKeywords) {
            knowledgeSearchBatchIndex++; // Next batch
          } else {
            knowledgeSearchBatchIndex = 0; // New search, reset
            lastKnowledgeSearchKeywords = keywords;
          }
          
          final searchResult = _knowledgeService.searchChunks(
            keywords: keywords,
            batchIndex: knowledgeSearchBatchIndex,
            batchSize: 5,
          );
          
          final results = searchResult['results'] as List<Map<String, dynamic>>;
          final totalMatches = searchResult['totalMatches'] as int;
          final hasMore = searchResult['hasMore'] as bool;
          final remainingCount = searchResult['remainingCount'] ?? 0;
          
          // Build result message for Agent
          final resultBuffer = StringBuffer();
          if (results.isEmpty) {
            resultBuffer.writeln('No matches found for keywords: "$keywords"');
            if (searchResult['message'] != null) {
              resultBuffer.writeln(searchResult['message']);
            }
          } else {
            resultBuffer.writeln('ğŸ“š Search Results (Batch ${knowledgeSearchBatchIndex + 1}, showing ${results.length} of $totalMatches matches):');
            resultBuffer.writeln('Keywords: $keywords\n');
            
            // Collect all chunk IDs for easy reference
            final chunkIdList = results.map((r) => r['id'] as String).toList();
            resultBuffer.writeln('ğŸ“‹ Available Chunk IDs: ${chunkIdList.join(', ')}');
            resultBuffer.writeln('   â†³ Use these IDs with read_knowledge to get full content!\n');
            
            for (var result in results) {
              resultBuffer.writeln('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
              resultBuffer.writeln('ğŸ“„ File: ${result['filename']}');
              resultBuffer.writeln('ğŸ”– Chunk ID: ${result['id']} â† Use this ID for read_knowledge');
              resultBuffer.writeln('ğŸ¯ Match Score: ${result['score']} keyword(s)');
              resultBuffer.writeln('ğŸ“ Summary: ${result['summary']}');
            }
            
            if (hasMore) {
              resultBuffer.writeln('\nâ³ More results available: $remainingCount remaining');
              resultBuffer.writeln('ğŸ’¡ Use search_knowledge with same keywords to see next batch.');
              resultBuffer.writeln('ğŸ’¡ Or use read_knowledge with IDs: ${chunkIdList.join(', ')}');
            } else {
              resultBuffer.writeln('\nâœ… All $totalMatches results shown.');
              resultBuffer.writeln('ğŸ’¡ Next: Use read_knowledge with content="${chunkIdList.join(', ')}" to read full content.');
            }
          }
          
          // Add to session refs for context (use different sourceType for search vs read)
          sessionRefs.add(ReferenceItem(
            title: 'ğŸ” çŸ¥è¯†åº“æœç´¢: "$keywords"',
            url: 'internal://knowledge/search',
            snippet: resultBuffer.toString(),
            sourceName: 'KnowledgeBase',
            sourceType: 'knowledge_search',
          ));
          
          // æ›´æ–°æ¨ç†é“¾
          if (mounted) {
            setState(() {
              _reasoningSteps.add('ğŸ“š çŸ¥è¯†åº“æœç´¢ "$keywords": æ‰¾åˆ° $totalMatches æ¡ç»“æœ');
            });
          }
          
          sessionDecisions.last = AgentDecision(
            type: AgentActionType.search_knowledge,
            content: keywords,
            reason: '${decision.reason} [RESULT: Found $totalMatches matches, showing batch ${knowledgeSearchBatchIndex + 1}]',
            continueAfter: true,
          );
          
          steps++;
          continue;
        }
        else if (decision.type == AgentActionType.take_note && decision.content != null) {
          // Action: Take Note (Agent's temporary memory)
          setState(() {
            _loadingStatus = 'æ­£åœ¨è®°å½•ç¬”è®°...';
            _currentReasoning = 'è®°å½•ç¬”è®°...';
          });
          final noteContent = decision.content!;
          
          // Count existing notes
          final noteCount = sessionRefs.where((r) => r.sourceName == 'AgentNotes').length + 1;
          
          // Also add as reference so Agent sees it in context
          sessionRefs.add(ReferenceItem(
            title: 'ğŸ“ Agent ç¬”è®° #$noteCount',
            url: 'internal://notes/session/$noteCount',
            snippet: noteContent,
            sourceName: 'AgentNotes',
            sourceType: 'system_note',
          ));
          
          // æ›´æ–°æ¨ç†é“¾
          if (mounted) {
            setState(() {
              _reasoningSteps.add('ğŸ“ è®°å½•ç¬”è®° #$noteCount');
            });
          }
          
          sessionDecisions.last = AgentDecision(
            type: AgentActionType.take_note,
            content: noteContent,
            reason: '${decision.reason} [NOTE #$noteCount SAVED]',
            continueAfter: true,
          );
          
          steps++;
          continue;
        }
        else if (decision.type == AgentActionType.save_file && decision.filename != null && decision.content != null) {
          // Action: Save File
          setState(() {
            _loadingStatus = 'æ­£åœ¨ä¿å­˜æ–‡ä»¶: ${decision.filename}...';
            _currentReasoning = 'ä¿å­˜æ–‡ä»¶: ${decision.filename}';
          });
          debugPrint('Agent saving file: ${decision.filename}');
          
          final savedPath = await FileSaver.saveTextFile(decision.filename!, decision.content!);
          
          if (savedPath != null) {
             // Success
             sessionDecisions.last = AgentDecision(
                type: AgentActionType.save_file,
                filename: decision.filename,
                content: decision.content,
                reason: '${decision.reason} [RESULT: File saved successfully to $savedPath]',
                continueAfter: decision.continueAfter,
             );
             
             sessionRefs.add(ReferenceItem(
                title: 'ğŸ’¾ æ–‡ä»¶å·²ä¿å­˜',
                url: 'file://$savedPath',
                snippet: 'æ–‡ä»¶ ${decision.filename} å·²ä¿å­˜ã€‚\nè·¯å¾„: $savedPath',
                sourceName: 'FileSaver',
                sourceType: 'system',
             ));
          } else {
             // Failed or Cancelled
             stepSucceeded = false;
             stepResult = 'File save cancelled or failed';
             
             sessionDecisions.last = AgentDecision(
                type: AgentActionType.save_file,
                filename: decision.filename,
                content: decision.content,
                reason: '${decision.reason} [RESULT: FAILED - File save cancelled or failed]',
                continueAfter: decision.continueAfter,
             );
             
             // ğŸ”´ PLAN SELF-ADJUSTMENT
             if (isFromPlan && _currentPlan != null) {
               debugPrint('ğŸ”„ Plan step failed (save_file failed), triggering REPLAN...');
               sessionRefs.add(ReferenceItem(
                 title: 'ğŸ”„ è®¡åˆ’è°ƒæ•´é€šçŸ¥',
                 url: 'internal://plan/replan/${DateTime.now().millisecondsSinceEpoch}',
                 snippet: 'åŸè®¡åˆ’æ­¥éª¤ ${planStepIndex + 1} æ‰§è¡Œå¤±è´¥: æ–‡ä»¶ä¿å­˜å¤±è´¥\nè¯·è°ƒæ•´ç­–ç•¥ï¼ˆå¦‚è¯¢é—®ç”¨æˆ·æˆ–ä½¿ç”¨å…¶ä»–å·¥å…·ï¼‰ã€‚',
                 sourceName: 'System',
                 sourceType: 'system_note',
               ));
               _currentPlan = null;
               _currentPlanStep = 0;
               steps++;
               continue;
             }
          }
          
          if (!decision.continueAfter) {
             break;
          }
          steps++;
          continue;
        }
        else if (decision.type == AgentActionType.system_control && decision.content != null) {
          // Action: System Control
          final action = decision.content!.toLowerCase();
          setState(() {
            _loadingStatus = 'æ­£åœ¨æ‰§è¡Œç³»ç»Ÿæ“ä½œ: $action...';
            _reasoningSteps.add('ğŸ”§ ç³»ç»Ÿæ§åˆ¶: $action');
            _currentReasoning = 'æ­£åœ¨æ‰§è¡Œç³»ç»Ÿæ“ä½œ...';
          });
          
          // Check service status first
          final isEnabled = await SystemControl.isServiceEnabled();
          if (!isEnabled) {
             // Service not enabled - ask user
             stepSucceeded = false;
             stepResult = 'Accessibility Service not enabled';
             
             sessionDecisions.last = AgentDecision(
                type: AgentActionType.system_control,
                content: decision.content,
                reason: '${decision.reason} [RESULT: FAILED - Accessibility Service not enabled]',
             );
             
             // Add system note
             sessionRefs.add(ReferenceItem(
                title: 'âš ï¸ éœ€è¦æƒé™',
                url: 'internal://system/permission-required',
                snippet: 'æ‰§è¡Œ "$action" å¤±è´¥ã€‚éœ€è¦å¼€å¯æ— éšœç¢æœåŠ¡æƒé™ã€‚\nè¯·å¼•å¯¼ç”¨æˆ·å»è®¾ç½®å¼€å¯ã€‚',
                sourceName: 'SystemControl',
                sourceType: 'system',
             ));
             
             // ğŸ”´ PLAN SELF-ADJUSTMENT
             if (isFromPlan && _currentPlan != null) {
               debugPrint('ğŸ”„ Plan step failed (system_control no permission), triggering REPLAN...');
               sessionRefs.add(ReferenceItem(
                 title: 'ğŸ”„ è®¡åˆ’è°ƒæ•´é€šçŸ¥',
                 url: 'internal://plan/replan/${DateTime.now().millisecondsSinceEpoch}',
                 snippet: 'åŸè®¡åˆ’æ­¥éª¤ ${planStepIndex + 1} æ‰§è¡Œå¤±è´¥: ç³»ç»Ÿæ§åˆ¶éœ€è¦æƒé™\nè¯·è°ƒæ•´ç­–ç•¥ï¼ˆå‘ŠçŸ¥ç”¨æˆ·éœ€è¦æˆæƒï¼‰ã€‚',
                 sourceName: 'System',
                 sourceType: 'system_note',
               ));
               _currentPlan = null;
               _currentPlanStep = 0;
               steps++;
               continue;
             }
             
             // Prompt user to open settings
             setState(() {
               _messages.add(ChatMessage('assistant', 'æ‰§è¡Œè¯¥æ“ä½œéœ€è¦å¼€å¯ã€æ— éšœç¢æœåŠ¡ã€‘æƒé™ã€‚\nè¯·ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å¯ï¼Œç„¶åé‡è¯•ã€‚'));
               _messages.add(ChatMessage('system', 'ç‚¹å‡»å¼€å¯è®¾ç½®', isMemory: true)); // Placeholder for UI action if we had one, but text is fine
             });
             
             // Open settings automatically
             await SystemControl.openAccessibilitySettings();
             break;
          }
          
          bool success = false;
          String actionResult = '';
          switch (action) {
            case 'home': success = await SystemControl.goHome(); actionResult = 'home'; break;
            case 'back': success = await SystemControl.goBack(); actionResult = 'back'; break;
            case 'recents': success = await SystemControl.showRecents(); actionResult = 'recents'; break;
            case 'notifications': success = await SystemControl.showNotifications(); actionResult = 'notifications'; break;
            case 'lock': success = await SystemControl.lockScreen(); actionResult = 'lock'; break;
            case 'screenshot': success = await SystemControl.takeScreenshot(); actionResult = 'screenshot'; break;
            default: 
              success = false;
              actionResult = 'UNKNOWN';
              debugPrint('Unknown system action: $action');
              // Record available actions for agent context
              sessionRefs.add(ReferenceItem(
                title: 'â“ æœªçŸ¥çš„ç³»ç»Ÿæ“ä½œ',
                url: 'internal://system/unknown-action',
                snippet: 'æ“ä½œ "$action" ä¸æ”¯æŒã€‚\næ”¯æŒçš„æ“ä½œæœ‰: home, back, recents, notifications, lock, screenshot\nè¯·ä½¿ç”¨æ”¯æŒçš„æ“ä½œæˆ–æ”¹ç”¨å…¶ä»–å·¥å…·ã€‚',
                sourceName: 'SystemControl',
                sourceType: 'system_note',
              ));
          }
          
          sessionDecisions.last = AgentDecision(
            type: AgentActionType.system_control,
            content: decision.content,
            reason: '${decision.reason} [RESULT: ${success ? "SUCCESS" : "FAILED"}]',
            continueAfter: decision.continueAfter,
          );
          
          if (success) {
             sessionRefs.add(ReferenceItem(
                title: 'ğŸ“± ç³»ç»Ÿæ“ä½œæ‰§è¡Œ',
                url: 'internal://system/action-performed',
                snippet: 'å·²æ‰§è¡Œæ“ä½œ: $action',
                sourceName: 'SystemControl',
                sourceType: 'system',
             ));
          } else {
             // ğŸ”´ PLAN SELF-ADJUSTMENT for failed system control
             if (isFromPlan && _currentPlan != null) {
               debugPrint('ğŸ”„ Plan step failed (system_control failed), triggering REPLAN...');
               sessionRefs.add(ReferenceItem(
                 title: 'ğŸ”„ è®¡åˆ’è°ƒæ•´é€šçŸ¥',
                 url: 'internal://plan/replan/${DateTime.now().millisecondsSinceEpoch}',
                 snippet: 'åŸè®¡åˆ’æ­¥éª¤ ${planStepIndex + 1} æ‰§è¡Œå¤±è´¥: ç³»ç»Ÿæ“ä½œ $action å¤±è´¥\nè¯·è°ƒæ•´ç­–ç•¥ã€‚',
                 sourceName: 'System',
                 sourceType: 'system_note',
               ));
               _currentPlan = null;
               _currentPlanStep = 0;
               steps++;
               continue;
             }
          }
          
          if (!decision.continueAfter) break;
          steps++;
          continue;
        }
        else if (decision.type == AgentActionType.vision && currentSessionImagePath != null) {
          // Action: Additional Vision Analysis (with custom prompt)
          
          // ğŸ”’ Pre-check: Is Vision API configured? (with fallback to Chat API)
          final visionApiConfigured = !_visionBase.contains('your-oneapi-host') && _visionKey.isNotEmpty;
          final chatApiConfigured = !_chatBase.contains('your-oneapi-host') && _chatKey.isNotEmpty;
          if (!visionApiConfigured && !chatApiConfigured) {
            debugPrint('âš ï¸ vision requested but neither Vision nor Chat API configured');
            sessionRefs.add(ReferenceItem(
              title: 'âš ï¸ å›¾ç‰‡åˆ†æå¤±è´¥',
              url: 'internal://error/vision-no-api/${DateTime.now().millisecondsSinceEpoch}',
              snippet: 'æ— æ³•åˆ†æå›¾ç‰‡ï¼šæœªé…ç½®è¯†å›¾APIæˆ–èŠå¤©APIã€‚\nè¯·åœ¨è®¾ç½®ä¸­è‡³å°‘é…ç½®ä¸€ä¸ªæ”¯æŒè§†è§‰çš„æ¨¡å‹ã€‚',
              sourceName: 'System',
              sourceType: 'feedback',
            ));
            sessionDecisions.last = AgentDecision(
              type: AgentActionType.vision,
              content: decision.content,
              reason: '${decision.reason} [RESULT: FAILED - No Vision/Chat API configured. Cannot analyze images.]',
            );
            steps++;
            continue;
          }
          
          // Count existing vision analyses for context
          final existingVisionCount = sessionRefs.where((r) => r.sourceType == 'vision').length;
          setState(() => _loadingStatus = 'æ­£åœ¨æ·±åº¦åˆ†æå›¾ç‰‡ (ç¬¬${existingVisionCount + 1}æ¬¡åˆ†æ)...');
          try {
            final customPrompt = decision.content ?? 'è¯·è¯¦ç»†åˆ†æè¿™å¼ å›¾ç‰‡çš„å†…å®¹ã€‚';
            final visionRefs = await analyzeImage(
              imagePath: currentSessionImagePath,
              baseUrl: _visionBase,
              apiKey: _visionKey,
              model: _visionModel,
              userPrompt: customPrompt,
              // Fallback to Chat API if Vision fails
              fallbackBaseUrl: _chatBase,
              fallbackApiKey: _chatKey,
              fallbackModel: _chatModel,
            );
            if (visionRefs.isNotEmpty) {
              // Remove pending_image marker since we've analyzed it
              sessionRefs.removeWhere((r) => r.sourceType == 'pending_image' && r.imageId == currentSessionImagePath);
              
              // Mark as additional analysis with context
              for (var ref in visionRefs) {
                // Enhance snippet with analysis context
                final enhancedSnippet = 'ã€åˆ†æè§†è§’ã€‘$customPrompt\nã€åˆ†æç»“æœã€‘${ref.snippet}';
                sessionRefs.add(ReferenceItem(
                  title: 'ğŸ“· æ·±åº¦åˆ†æ #${existingVisionCount + 1}: ${ref.title}',
                  url: ref.url,
                  snippet: enhancedSnippet,
                  sourceName: ref.sourceName,
                  imageId: ref.imageId,
                  sourceType: 'vision',
                ));
              }
              debugPrint('Added ${visionRefs.length} vision refs (analysis #${existingVisionCount + 1})');
              
              // Extract key insights for action history
              final firstResult = visionRefs.first.snippet;
              final summaryPreview = firstResult.length > 100 ? '${firstResult.substring(0, 100)}...' : firstResult;
              
              // Record success in action history with rich feedback
              sessionDecisions.last = AgentDecision(
                type: AgentActionType.vision,
                content: customPrompt,
                reason: '${decision.reason} [RESULT: Vision #${existingVisionCount + 1} complete. Key insight: $summaryPreview]',
              );
            } else {
              // Vision returned empty - record for planner
              sessionDecisions.last = AgentDecision(
                type: AgentActionType.vision,
                content: customPrompt,
                reason: '${decision.reason} [RESULT: Vision returned no insights - try different analysis angle]',
              );
            }
            // Continue loop to process the new vision info
          } catch (visionError) {
            debugPrint('Vision analysis failed: $visionError');
            stepSucceeded = false;
            stepResult = 'Vision exception: $visionError';
            
            sessionDecisions.last = AgentDecision(
              type: AgentActionType.vision,
              content: decision.content,
              reason: '${decision.reason} [RESULT: FAILED - Vision failed - $visionError. Consider: 1) Different prompt 2) Fallback to describe without analysis]',
            );
            
            // ğŸ”´ PLAN SELF-ADJUSTMENT
            if (isFromPlan && _currentPlan != null) {
              debugPrint('ğŸ”„ Plan step failed (vision error), triggering REPLAN...');
              sessionRefs.add(ReferenceItem(
                title: 'ğŸ”„ è®¡åˆ’è°ƒæ•´é€šçŸ¥',
                url: 'internal://plan/replan/${DateTime.now().millisecondsSinceEpoch}',
                snippet: 'åŸè®¡åˆ’æ­¥éª¤ ${planStepIndex + 1} æ‰§è¡Œå¤±è´¥: å›¾ç‰‡åˆ†æå¼‚å¸¸ - $visionError\nè¯·è°ƒæ•´ç­–ç•¥ã€‚',
                sourceName: 'System',
                sourceType: 'system_note',
              ));
              _currentPlan = null;
              _currentPlanStep = 0;
            }
            // Continue loop - Agent will decide next action based on failure
          }
          steps++;
          continue; // Always continue after vision to let Agent decide next action
        }
        else if (decision.type == AgentActionType.ocr) {
          // Action: OCR - Extract text from image
          _addReasoningStep('ğŸ“ æ‰§è¡Œ OCR æ–‡å­—æå–...');
          
          if (currentSessionImagePath == null || currentSessionImagePath.isEmpty) {
            _addReasoningStep('âŒ OCR å¤±è´¥: æ²¡æœ‰å¾…å¤„ç†çš„å›¾ç‰‡');
            sessionRefs.add(ReferenceItem(
              title: 'âš ï¸ OCR å¤±è´¥',
              url: 'internal://error/ocr-no-image/${DateTime.now().millisecondsSinceEpoch}',
              snippet: 'æ²¡æœ‰å¾…å¤„ç†çš„å›¾ç‰‡ã€‚è¯·å…ˆä¸Šä¼ å›¾ç‰‡å†ä½¿ç”¨ OCRã€‚',
              sourceName: 'System',
              sourceType: 'feedback',
            ));
            sessionDecisions.last = AgentDecision(
              type: AgentActionType.ocr,
              content: decision.content,
              reason: '${decision.reason} [RESULT: FAILED - No image to OCR]',
            );
            steps++;
            continue;
          }
          
          if (_ocrBase.contains('your-oneapi-host') || _ocrKey.isEmpty) {
            _addReasoningStep('âŒ OCR å¤±è´¥: æœªé…ç½® OCR API');
            sessionRefs.add(ReferenceItem(
              title: 'âš ï¸ OCR æœªé…ç½®',
              url: 'internal://error/ocr-no-api/${DateTime.now().millisecondsSinceEpoch}',
              snippet: 'æ— æ³•æ‰§è¡Œ OCRï¼šæœªé…ç½® OCR APIã€‚\nè¯·åœ¨è®¾ç½®ä¸­é…ç½® OCR æœåŠ¡ã€‚',
              sourceName: 'System',
              sourceType: 'feedback',
            ));
            sessionDecisions.last = AgentDecision(
              type: AgentActionType.ocr,
              content: decision.content,
              reason: '${decision.reason} [RESULT: FAILED - No OCR API configured]',
            );
            steps++;
            continue;
          }
          
          setState(() => _loadingStatus = 'æ­£åœ¨ OCR æå–æ–‡å­—...');
          try {
            final customPrompt = decision.content ?? '<|grounding|>OCR this image. Extract all text.';
            final filePath = currentSessionImagePath;
            final ext = filePath.toLowerCase().split('.').last;
            
            String? ocrText;
            if (ext == 'pdf') {
              // PDF: Use PDF OCR with page splitting
              _addReasoningStep('ğŸ“„ æ£€æµ‹åˆ° PDFï¼Œæ­£åœ¨é€é¡µ OCR...');
              ocrText = await _runPdfOcr(File(filePath), prompt: customPrompt);
            } else {
              // Image: Use direct image OCR
              final imageFile = File(filePath);
              ocrText = await _runImageOcr(imageFile, prompt: customPrompt);
            }
            
            if (ocrText != null && ocrText.trim().isNotEmpty) {
              _addReasoningStep('âœ… OCR æˆåŠŸ: æå–åˆ° ${ocrText.length} å­—ç¬¦');
              
              // Remove pending_image marker
              sessionRefs.removeWhere((r) => r.sourceType == 'pending_image' && r.imageId == currentSessionImagePath);
              
              // Add OCR result as reference
              sessionRefs.add(ReferenceItem(
                title: 'ğŸ“ OCR æ–‡å­—æå–ç»“æœ',
                url: currentSessionImagePath,
                snippet: ocrText,
                sourceName: 'OCR',
                imageId: currentSessionImagePath,
                sourceType: 'ocr',
              ));
              await _refManager.addExternalReferences([sessionRefs.last]);
              
              final previewText = ocrText.length > 150 ? '${ocrText.substring(0, 150)}...' : ocrText;
              sessionDecisions.last = AgentDecision(
                type: AgentActionType.ocr,
                content: customPrompt,
                reason: '${decision.reason} [RESULT: OCR success. Extracted text preview: $previewText]',
              );
            } else {
              _addReasoningStep('âš ï¸ OCR æœªæå–åˆ°æ–‡å­—');
              sessionRefs.add(ReferenceItem(
                title: 'âš ï¸ OCR æ— ç»“æœ',
                url: 'internal://ocr-empty/${DateTime.now().millisecondsSinceEpoch}',
                snippet: 'OCR æœªèƒ½ä»å›¾ç‰‡ä¸­æå–åˆ°æ–‡å­—ã€‚å¯èƒ½åŸå› :\n1. å›¾ç‰‡ä¸­æ²¡æœ‰æ–‡å­—\n2. å›¾ç‰‡è´¨é‡å¤ªä½\n3. æ–‡å­—ä¸æ¸…æ™°\n\nå»ºè®®: å°è¯•ä½¿ç”¨ vision å·¥å…·æ¥ç†è§£å›¾ç‰‡å†…å®¹ã€‚',
                sourceName: 'System',
                sourceType: 'feedback',
              ));
              sessionDecisions.last = AgentDecision(
                type: AgentActionType.ocr,
                content: customPrompt,
                reason: '${decision.reason} [RESULT: OCR returned empty - image may not contain readable text. Try vision instead.]',
              );
            }
          } catch (ocrError) {
            _addReasoningStep('âŒ OCR å¤±è´¥: $ocrError');
            debugPrint('OCR failed: $ocrError');
            
            sessionRefs.add(ReferenceItem(
              title: 'âš ï¸ OCR å¼‚å¸¸',
              url: 'internal://error/ocr/${DateTime.now().millisecondsSinceEpoch}',
              snippet: 'OCR å¤„ç†å¤±è´¥: $ocrError\n\nå»ºè®®: æ£€æŸ¥å›¾ç‰‡æ ¼å¼æ˜¯å¦æ”¯æŒï¼Œæˆ–å°è¯•ä½¿ç”¨ vision å·¥å…·ã€‚',
              sourceName: 'System',
              sourceType: 'feedback',
            ));
            sessionDecisions.last = AgentDecision(
              type: AgentActionType.ocr,
              content: decision.content,
              reason: '${decision.reason} [RESULT: FAILED - OCR error: $ocrError. Consider using vision instead.]',
            );
          }
          steps++;
          continue; // Always continue after OCR to let Agent process the result
        }
        else if (decision.type == AgentActionType.reflect) {
          // Action: Self-Reflection (Deep Think)
          final reflectionSummary = decision.content ?? 'è‡ªæˆ‘å®¡è§†å½“å‰æ–¹æ³•';
          // Show the actual thought process in UI
          setState(() => _loadingStatus = 'ğŸ¤” åæ€: ${reflectionSummary.length > 15 ? reflectionSummary.substring(0, 15) + "..." : reflectionSummary}');
          debugPrint('Agent reflecting: ${decision.content}');
          
          // Artificial delay to let user see the thinking state
          await Future.delayed(const Duration(milliseconds: 1200));
          
          // Record reflection in action history with insights
          sessionDecisions.last = AgentDecision(
            type: AgentActionType.reflect,
            content: reflectionSummary,
            reason: '${decision.reason} [REFLECTION: $reflectionSummary]',
            confidence: decision.confidence,
            uncertainties: decision.uncertainties,
          );
          
          // Add reflection as a special observation for next iteration
          sessionRefs.add(ReferenceItem(
            title: 'ğŸ§  æ·±åº¦åæ€',
            url: 'internal://reflection/${DateTime.now().millisecondsSinceEpoch}',
            snippet: 'ã€åæ€ç»“è®ºã€‘$reflectionSummary\nã€ç½®ä¿¡åº¦ã€‘${((decision.confidence ?? 0.5) * 100).toInt()}%\nã€å¾…è§£å†³ä¸ç¡®å®šæ€§ã€‘${decision.uncertainties?.join(", ") ?? "æ— "}',
            sourceName: 'DeepThink',
            sourceType: 'reflection',
          ));
          
          // æ›´æ–°æ¨ç†é“¾
          if (mounted) {
            setState(() {
              _reasoningSteps.add('ğŸ¤” æ·±åº¦åæ€');
            });
          }
          
          // Reflect always continues to next action
          // (Agent will decide what to do based on reflection)
          steps++;
          continue; // Continue loop to let Agent decide next action
        }
        else if (decision.type == AgentActionType.hypothesize) {
          // Action: Multi-Hypothesis Generation (Deep Think)
          final hypothesesList = decision.hypotheses ?? ['é»˜è®¤æ–¹æ¡ˆ'];
          final selected = decision.selectedHypothesis ?? hypothesesList.first;
          
          setState(() {
            _loadingStatus = 'ğŸ’¡ å‡è®¾: ${selected.length > 15 ? selected.substring(0, 15) + "..." : selected}';
            _currentReasoning = 'ç”Ÿæˆå‡è®¾æ–¹æ¡ˆ...';
          });
          debugPrint('Agent hypothesizing: ${decision.hypotheses}');
          
          // Artificial delay
          await Future.delayed(const Duration(milliseconds: 1200));
          
          // æ›´æ–°æ¨ç†é“¾
          if (mounted) {
            setState(() {
              _reasoningSteps.add('ğŸ’¡ å‡è®¾åˆ†æ: ç”Ÿæˆ ${hypothesesList.length} ä¸ªæ–¹æ¡ˆ');
            });
          }
          
          // Record hypotheses in action history
          sessionDecisions.last = AgentDecision(
            type: AgentActionType.hypothesize,
            content: selected,
            reason: '${decision.reason} [HYPOTHESES: ${hypothesesList.length} generated, selected: $selected]',
            confidence: decision.confidence,
            hypotheses: hypothesesList,
            selectedHypothesis: selected,
          );
          
          // Add hypothesis analysis as observation
          final hypothesesBuffer = StringBuffer();
          hypothesesBuffer.writeln('ã€å€™é€‰æ–¹æ¡ˆã€‘');
          for (var i = 0; i < hypothesesList.length; i++) {
            final isSelected = hypothesesList[i] == selected || selected.contains(hypothesesList[i]);
            hypothesesBuffer.writeln('  ${i + 1}. ${isSelected ? "âœ…" : "â—‹"} ${hypothesesList[i]}');
          }
          hypothesesBuffer.writeln('ã€é€‰å®šæ–¹æ¡ˆã€‘$selected');
          
          sessionRefs.add(ReferenceItem(
            title: 'ğŸ’¡ å‡è®¾åˆ†æ',
            url: 'internal://hypothesis/${DateTime.now().millisecondsSinceEpoch}',
            snippet: hypothesesBuffer.toString(),
            sourceName: 'DeepThink',
            sourceType: 'hypothesis',
          ));
          
          // Hypothesize always continues to execute the selected hypothesis
          steps++;
          continue; // Continue loop to let Agent execute the selected hypothesis
        }
        else if (decision.type == AgentActionType.clarify) {
          // Action: Request Clarification from User
          setState(() {
            _loadingStatus = 'â“ éœ€è¦æ‚¨æä¾›æ›´å¤šä¿¡æ¯...';
            _reasoningSteps.add('â“ è¯·æ±‚æ¾„æ¸…: éœ€è¦æ›´å¤šä¿¡æ¯');
            _currentReasoning = 'ç­‰å¾…ç”¨æˆ·å›å¤...';
          });
          debugPrint('Agent requesting clarification: ${decision.content}');
          
          final clarificationRequest = decision.content ?? 'è¯·æä¾›æ›´å¤šä¿¡æ¯';
          final missingInfoList = decision.infoSufficiency?.missingInfo ?? [];
          
          // Record clarification request in action history
          sessionDecisions.last = AgentDecision(
            type: AgentActionType.clarify,
            content: clarificationRequest,
            reason: '${decision.reason} [CLARIFY: Awaiting user input]',
            confidence: decision.confidence,
            infoSufficiency: decision.infoSufficiency,
          );
          
          // Build a user-friendly clarification message
          final clarifyBuffer = StringBuffer();
          clarifyBuffer.writeln('ğŸ¤” **éœ€è¦æ›´å¤šä¿¡æ¯**\n');
          clarifyBuffer.writeln(clarificationRequest);
          
          if (missingInfoList.isNotEmpty) {
            clarifyBuffer.writeln('\n\nğŸ“‹ **å…·ä½“éœ€è¦äº†è§£ï¼š**');
            for (var i = 0; i < missingInfoList.length; i++) {
              clarifyBuffer.writeln('${i + 1}. ${missingInfoList[i]}');
            }
          }
          
          if (decision.infoSufficiency != null && !decision.infoSufficiency!.isSufficient) {
            clarifyBuffer.writeln('\nğŸ“Š å½“å‰ä¿¡æ¯å……åˆ†åº¦: ä¸è¶³');
          }
          
          clarifyBuffer.writeln('\n\n*è¯·å›å¤è¡¥å……ä¿¡æ¯åï¼Œæˆ‘å°†ç»§ç»­ä¸ºæ‚¨åˆ†æã€‚*');
          
          // Add clarification to session refs for context
          sessionRefs.add(ReferenceItem(
            title: 'â“ ä¿¡æ¯è¯·æ±‚',
            url: 'internal://clarify/${DateTime.now().millisecondsSinceEpoch}',
            snippet: 'ã€ç¼ºå¤±ä¿¡æ¯ã€‘${missingInfoList.join("; ")}\nã€çŠ¶æ€ã€‘ç­‰å¾…ç”¨æˆ·å›å¤',
            sourceName: 'DeepThink',
            sourceType: 'system',
          ));
          
          // Create clarification message and end the Agent loop
          final clarifyMessage = ChatMessage(
            'assistant',
            clarifyBuffer.toString(),
          );
          
          setState(() {
            _messages.add(clarifyMessage);
            _sending = false;
            _loadingStatus = '';
          });
          
          // Save the clarification state so next user message continues the flow
          _pendingClarification = {
            'sessionRefs': sessionRefs.map((r) => r.toJson()).toList(),
            'sessionDecisions': sessionDecisions.map((d) => d.toJson()).toList(),
            'originalQuery': content,
          };
          
          await _saveChatHistory();
          return; // Exit Agent loop, wait for user input
        }
        else if (decision.type == AgentActionType.vision && currentSessionImagePath == null) {
          // âš ï¸ Vision requested but NO IMAGE available - this is an error!
          debugPrint('âš ï¸ Vision requested but no image available');
          stepSucceeded = false;
          stepResult = 'Vision failed: No image in current session';
          
          sessionDecisions.last = AgentDecision(
            type: AgentActionType.vision,
            content: decision.content,
            reason: '${decision.reason} [RESULT: FAILED - No image available. User must send an image first.]',
          );
          
          sessionRefs.add(ReferenceItem(
            title: 'âš ï¸ å›¾ç‰‡åˆ†æå¤±è´¥',
            url: 'internal://error/vision-no-image/${DateTime.now().millisecondsSinceEpoch}',
            snippet: 'æ— æ³•æ‰§è¡Œå›¾ç‰‡åˆ†æï¼šå½“å‰ä¼šè¯æ²¡æœ‰å›¾ç‰‡ã€‚\nè¯·æç¤ºç”¨æˆ·å‘é€å›¾ç‰‡ï¼Œæˆ–ä½¿ç”¨å…¶ä»–å·¥å…·ï¼ˆå¦‚searchï¼‰è·å–ä¿¡æ¯ã€‚',
            sourceName: 'System',
            sourceType: 'system_note',
          ));
          
          // ğŸ”´ PLAN SELF-ADJUSTMENT
          if (isFromPlan && _currentPlan != null) {
            debugPrint('ğŸ”„ Plan step failed (vision no image), triggering REPLAN...');
            _currentPlan = null;
            _currentPlanStep = 0;
          }
          
          steps++;
          continue; // Let Agent try alternative approach
        }
        else if (decision.type == AgentActionType.answer) {
          // Action: Answer
          
          // æ›´æ–°æ¨ç†é“¾
          if (mounted) {
            setState(() {
              _currentReasoning = 'å‡†å¤‡ç”Ÿæˆæœ€ç»ˆå›ç­”...';
            });
          }
          
          // ğŸ§  SMART FEEDBACK: Instead of forcing, provide feedback and let Agent decide
          final isSimpleGreeting = content.length < 10 && 
            (content.contains('ä½ å¥½') || content.contains('hi') || content.contains('hello') ||
             content.contains('è°¢è°¢') || content.contains('å†è§') || content.contains('å¥½çš„'));
          
          // Check if any REAL tools were used (not just reflect/hypothesize which are thinking tools)
          final hasRealToolsUsed = sessionDecisions.any((d) => 
            d.type == AgentActionType.search ||
            d.type == AgentActionType.draw ||
            d.type == AgentActionType.vision ||
            d.type == AgentActionType.ocr ||
            d.type == AgentActionType.read_url ||
            d.type == AgentActionType.search_knowledge ||
            d.type == AgentActionType.read_knowledge ||
            d.type == AgentActionType.save_file ||
            d.type == AgentActionType.system_control);
          
          // Check if we have real data from tools (not just system notes)
          final hasRealData = sessionRefs.any((r) => 
            r.sourceType != 'system_note' && 
            r.sourceType != 'system_command' &&
            r.sourceType != 'system' &&
            r.sourceType != 'feedback');
          
          // Count feedback attempts (not "blocks", just feedback)
          final feedbackAttempts = sessionDecisions.where((d) => 
            d.reason?.contains('[FEEDBACK]') == true
          ).length;
          
          // Determine if we should provide feedback or allow the answer
          final shouldProvideToolFeedback = !isSimpleGreeting && 
            !hasRealToolsUsed && 
            !hasRealData && 
            feedbackAttempts < 2 &&  // Only give feedback twice max
            steps < maxSteps - 2;
          
          if (shouldProvideToolFeedback) {
            // ğŸ§  FEEDBACK MODE: Tell Agent what we observed, let it decide
            debugPrint('ğŸ’¡ FEEDBACK: Agent chose answer without tools. Providing observation for reconsideration.');
            setState(() => _loadingStatus = 'ğŸ§  Agent æ­£åœ¨é‡æ–°è¯„ä¼°...');
            
            // Provide observation feedback - NOT a command, just information
            sessionRefs.add(ReferenceItem(
              title: 'ğŸ’¡ ç³»ç»Ÿè§‚å¯Ÿåé¦ˆ (éå¼ºåˆ¶)',
              url: 'internal://feedback/observation/${DateTime.now().millisecondsSinceEpoch}',
              snippet: '''[OBSERVATION - Agent è¯·è‡ªè¡Œåˆ¤æ–­]

ä½ é€‰æ‹©äº†ç›´æ¥å›ç­”ï¼Œä½†ç³»ç»Ÿè§‚å¯Ÿåˆ°ï¼š
â€¢ å½“å‰ <current_observations> ä¸­æ²¡æœ‰æ¥è‡ªå·¥å…·çš„çœŸå®æ•°æ®
â€¢ ç”¨æˆ·é—®é¢˜: "$content"

å¯èƒ½çš„æƒ…å†µåˆ†æï¼š
1. å¦‚æœè¿™æ˜¯ä¸€ä¸ªéœ€è¦å®æ—¶ä¿¡æ¯çš„é—®é¢˜ï¼ˆæ–°é—»ã€ä»·æ ¼ã€å¤©æ°”ç­‰ï¼‰â†’ search å¯èƒ½æ›´å¥½
2. å¦‚æœè¿™æ˜¯ä¸€ä¸ªåˆ›ä½œè¯·æ±‚ï¼ˆç”»å›¾ç­‰ï¼‰â†’ draw æ˜¯æ­£ç¡®é€‰æ‹©
3. å¦‚æœè¿™ç¡®å®æ˜¯ä¸€ä¸ªå¯ä»¥ç›´æ¥å›ç­”çš„é—®é¢˜ï¼ˆå¸¸è¯†ã€ç®€å•è®¡ç®—ç­‰ï¼‰â†’ ç»§ç»­ answer æ˜¯åˆç†çš„
4. å¦‚æœé—®é¢˜å¤æ‚éœ€è¦æ€è€ƒ â†’ reflect å¯ä»¥å¸®åŠ©ç†æ¸…æ€è·¯

è¯·æ ¹æ®ä½ å¯¹ç”¨æˆ·é—®é¢˜çš„ç†è§£ï¼Œè‡ªè¡Œå†³å®šï¼š
- åšæŒä½¿ç”¨ "answer"ï¼ˆå¦‚æœä½ ç¡®ä¿¡ä¸éœ€è¦å·¥å…·ï¼‰
- æˆ–æ”¹ç”¨å…¶ä»–å·¥å…·ï¼ˆå¦‚æœä½ è®¤ä¸ºå·¥å…·èƒ½æä¾›æ›´å¥½çš„å›ç­”ï¼‰

è¿™ä¸æ˜¯å¼ºåˆ¶å‘½ä»¤ï¼Œæ˜¯å¸®åŠ©ä½ åšå‡ºæ›´å¥½å†³ç­–çš„åé¦ˆã€‚''',
              sourceName: 'SystemFeedback',
              sourceType: 'feedback',
            ));
            
            // Record this as a feedback (not a block/override)
            sessionDecisions.add(AgentDecision(
              type: AgentActionType.reflect,
              content: 'ç³»ç»Ÿæä¾›äº†è§‚å¯Ÿåé¦ˆï¼ŒAgent æ­£åœ¨é‡æ–°è¯„ä¼°å†³ç­–',
              reason: '[FEEDBACK] Observation provided. Agent will reconsider. User: "$content"',
            ));
            
            steps++;
            continue;
          }
          
          // Deep Think: Check confidence before answering
          if (decision.needsMoreWork && steps < maxSteps - 2) {
            // Confidence too low - provide feedback instead of forcing
            debugPrint('ğŸ’¡ FEEDBACK: Confidence ${decision.confidence} is low.');
            setState(() => _loadingStatus = 'ğŸ§  Agent ç½®ä¿¡åº¦è¾ƒä½ï¼Œæ­£åœ¨é‡æ–°è¯„ä¼°...');
            
            // Provide confidence feedback
            sessionRefs.add(ReferenceItem(
              title: 'ğŸ’¡ ç½®ä¿¡åº¦åé¦ˆ',
              url: 'internal://feedback/confidence/${DateTime.now().millisecondsSinceEpoch}',
              snippet: '''[CONFIDENCE OBSERVATION]

ä½ çš„å›ç­”ç½®ä¿¡åº¦ä¸º ${((decision.confidence ?? 0.5) * 100).toInt()}%ï¼Œç³»ç»Ÿè§‚å¯Ÿåˆ°è¿™å¯èƒ½ä¸å¤Ÿç¡®å®šã€‚

ä¸ç¡®å®šæ€§: ${decision.uncertainties?.join(", ") ?? "æœªæ˜ç¡®æŒ‡å‡º"}

å»ºè®®ï¼ˆéå¼ºåˆ¶ï¼‰ï¼š
â€¢ å¦‚æœä¸ç¡®å®šäº‹å® â†’ search å¯ä»¥è·å–æ›´å¯é çš„ä¿¡æ¯
â€¢ å¦‚æœé€»è¾‘å¤æ‚ â†’ reflect å¯ä»¥å¸®åŠ©ç†æ¸…æ€è·¯
â€¢ å¦‚æœä½ è®¤ä¸ºå½“å‰ç½®ä¿¡åº¦å·²è¶³å¤Ÿ â†’ ç»§ç»­ answer ä¹Ÿå¯ä»¥

è¯·è‡ªè¡Œåˆ¤æ–­æ˜¯å¦éœ€è¦é¢å¤–çš„å·¥å…·æ¥æé«˜å›ç­”è´¨é‡ã€‚''',
              sourceName: 'SystemFeedback',
              sourceType: 'feedback',
            ));
            
            // Continue loop to let Agent reconsider
            steps++;
            continue;
          }
          
          // Agent decided to answer - execute it
          setState(() {
            _loadingStatus = 'æ­£åœ¨æ’°å†™å›å¤...';
            _reasoningSteps.add('âœ… ç”Ÿæˆæœ€ç»ˆå›ç­”');
            _currentReasoning = 'æ­£åœ¨æ’°å†™å›å¤...';
          });
          await _performChatRequest(content, localImage: currentSessionImagePath, references: sessionRefs, manageSendingState: false);
          
          // Clean up plan state after answer
          _currentPlan = null;
          _currentPlanStep = 0;
          
          break; // Answer is a terminal action
        }
        else {
          // âš ï¸ CRITICAL: Handle missing parameters for tool calls
          // If we reach here, it means a tool was called but with missing parameters
          // Instead of silently falling back to answer, we should:
          // 1. Log the issue
          // 2. Add a system note so Agent can see what went wrong
          // 3. Continue the loop so Agent can retry
          
          final toolName = decision.type.name;
          String missingParams = '';
          
          // Check what's missing for each tool type
          switch (decision.type) {
            case AgentActionType.search:
              if (decision.query == null) missingParams = 'query';
              break;
            case AgentActionType.read_url:
            case AgentActionType.draw:
            case AgentActionType.vision:
            case AgentActionType.search_knowledge:
            case AgentActionType.read_knowledge:
            case AgentActionType.delete_knowledge:
            case AgentActionType.take_note:
            case AgentActionType.system_control:
              if (decision.content == null) missingParams = 'content';
              break;
            case AgentActionType.save_file:
              final missing = <String>[];
              if (decision.filename == null) missing.add('filename');
              if (decision.content == null) missing.add('content');
              missingParams = missing.join(', ');
              break;
            case AgentActionType.hypothesize:
              if (decision.hypotheses == null) missingParams = 'hypotheses';
              break;
            default:
              missingParams = 'unknown';
          }
          
          debugPrint('âš ï¸ Tool $toolName called with missing params: $missingParams');
          
          // Add error note to session so Agent can see and fix
          sessionRefs.add(ReferenceItem(
            title: 'âš ï¸ å·¥å…·è°ƒç”¨å¤±è´¥: $toolName',
            url: 'internal://error/missing-params/${DateTime.now().millisecondsSinceEpoch}',
            snippet: 'å·¥å…· "$toolName" ç¼ºå°‘å¿…è¦å‚æ•°: $missingParams\nè¯·é‡æ–°è°ƒç”¨è¯¥å·¥å…·å¹¶æä¾›å®Œæ•´å‚æ•°ã€‚\n\næ­£ç¡®æ ¼å¼ç¤ºä¾‹:\n${_getToolExample(decision.type)}',
            sourceName: 'System',
            sourceType: 'system_note',
          ));
          
          // Record in decision history
          sessionDecisions.last = AgentDecision(
            type: decision.type,
            content: decision.content,
            reason: '${decision.reason ?? ""} [ERROR: Missing params: $missingParams]',
          );
          
          // Continue loop to let Agent retry with correct parameters
          if (steps < maxSteps - 1) {
            steps++;
            continue;
          }
          
          // If too many retries, fallback to answer
          setState(() => _loadingStatus = 'å·¥å…·è°ƒç”¨å¤±è´¥ï¼Œæ­£åœ¨æ’°å†™å›å¤...');
          await _performChatRequest(content, localImage: currentSessionImagePath, references: sessionRefs, manageSendingState: false);
          break;
        }
        
        steps++;
      }
      
      if (steps >= maxSteps) {
        // Fallback if max steps reached
        setState(() => _loadingStatus = 'æ€è€ƒæ­¥éª¤è¿‡å¤šï¼Œæ­£åœ¨å¼ºåˆ¶å›å¤...');
        // æ¸…ç† Plan çŠ¶æ€
        _currentPlan = null;
        _currentPlanStep = 0;
        await _performChatRequest(content, localImage: currentSessionImagePath, references: sessionRefs, manageSendingState: false);
      }

    } catch (e) {
      _showError('Agent Error: $e');
      // å‡ºé”™æ—¶ä¹Ÿæ¸…ç† Plan çŠ¶æ€
      _currentPlan = null;
      _currentPlanStep = 0;
    } finally {
      if (mounted) {
        setState(() {
          _sending = false;
          _loadingStatus = '';
        });
        // å»¶è¿Ÿéšè—æ¨ç†é“¾é¢æ¿ (ç§»åˆ° setState å¤–éƒ¨)
        Future.delayed(const Duration(seconds: 2), () {
          if (mounted && !_sending) {
            setState(() {
              _showReasoningPanel = false;
              _reasoningSteps = [];
              _currentReasoning = '';
            });
          }
        });
      }
    }
  }

  /// Get example JSON for a tool type (used in error messages)
  String _getToolExample(AgentActionType type) {
    switch (type) {
      case AgentActionType.search:
        return '{"type":"search","query":"æœç´¢å…³é”®è¯","continue":true}';
      case AgentActionType.read_url:
        return '{"type":"read_url","content":"https://example.com","continue":true}';
      case AgentActionType.draw:
        return '{"type":"draw","content":"a beautiful sunset","continue":false}';
      case AgentActionType.vision:
        return '{"type":"vision","content":"è¯·åˆ†æè¿™å¼ å›¾ç‰‡","continue":true}';
      case AgentActionType.save_file:
        return '{"type":"save_file","filename":"report.md","content":"æ–‡ä»¶å†…å®¹...","continue":false}';
      case AgentActionType.system_control:
        return '{"type":"system_control","content":"home","continue":false}';
      case AgentActionType.search_knowledge:
        return '{"type":"search_knowledge","content":"å…³é”®è¯","continue":true}';
      case AgentActionType.read_knowledge:
        return '{"type":"read_knowledge","content":"chunk_id","continue":true}';
      case AgentActionType.delete_knowledge:
        return '{"type":"delete_knowledge","content":"file_id","continue":false}';
      case AgentActionType.take_note:
        return '{"type":"take_note","content":"é‡è¦ç¬”è®°å†…å®¹","continue":true}';
      case AgentActionType.reflect:
        return '{"type":"reflect","content":"æ€è€ƒå†…å®¹","continue":true}';
      case AgentActionType.hypothesize:
        return '{"type":"hypothesize","hypotheses":["æ–¹æ¡ˆ1","æ–¹æ¡ˆ2"],"selectedHypothesis":"æ–¹æ¡ˆ1","continue":true}';
      case AgentActionType.clarify:
        return '{"type":"clarify","content":"è¯·é—®æ‚¨å…·ä½“æŒ‡...?","continue":false}';
      case AgentActionType.answer:
        return '{"type":"answer","content":"å›ç­”å†…å®¹","continue":false}';
    }
  }

  void _scrollToBottom() {
    WidgetsBinding.instance.addPostFrameCallback((_) {
      if (_scrollCtrl.hasClients) {
        _scrollCtrl.animateTo(
          _scrollCtrl.position.maxScrollExtent,
          duration: const Duration(milliseconds: 300),
          curve: Curves.easeOut,
        );
      }
    });
  }

  void _showError(String msg) {
    if (!mounted) return;
    ScaffoldMessenger.of(context).showSnackBar(
      SnackBar(content: Text(msg), behavior: SnackBarBehavior.floating),
    );
  }

  void _showSuccessSnackBar(String msg) {
    if (!mounted) return;
    ScaffoldMessenger.of(context).showSnackBar(
      SnackBar(
        content: Row(
          children: [
            Container(
              padding: const EdgeInsets.all(8),
              decoration: BoxDecoration(
                color: Colors.white.withOpacity(0.2),
                shape: BoxShape.circle,
              ),
              child: const Icon(Icons.check_circle, color: Colors.white, size: 20),
            ),
            const SizedBox(width: 12),
            Expanded(child: Text(msg, style: const TextStyle(fontWeight: FontWeight.w500))),
          ],
        ),
        backgroundColor: Colors.green[600],
        behavior: SnackBarBehavior.floating,
        shape: RoundedRectangleBorder(borderRadius: BorderRadius.circular(12)),
        duration: const Duration(seconds: 3),
      ),
    );
  }

  void _openSettings() async {
    await Navigator.push(
      context,
      MaterialPageRoute(builder: (context) => SettingsPage(
        onDeepProfile: _performDeepProfiling,
      )),
    );
    _loadSettings();
    // Reload global memory in case it was edited in settings
    final prefs = await SharedPreferences.getInstance();
    setState(() {
      _globalMemoryCache = prefs.getString('global_memory') ?? '';
    });
  }

  void _openPersonaManager() async {
    await Navigator.push(
      context,
      MaterialPageRoute(builder: (context) => PersonaManagerPage(
        personas: _personas,
        onSave: (updatedList) {
          setState(() {
            _personas = updatedList;
            _savePersonas();
          });
        },
      )),
    );
  }

  int _calculateTotalChars() {
    int total = 0;
    for (var m in _messages) {
      total += m.content.length;
    }
    return total;
  }

  @override
  Widget build(BuildContext context) {
    // ç­‰å¾…åˆå§‹åŒ–å®Œæˆ
    if (!_isInitialized) {
      return Scaffold(
        body: Container(
          decoration: BoxDecoration(
            gradient: LinearGradient(
              begin: Alignment.topLeft,
              end: Alignment.bottomRight,
              colors: [
                AppColors.primaryStart.withOpacity(0.1),
                AppColors.primaryEnd.withOpacity(0.05),
              ],
            ),
          ),
          child: Center(
            child: Column(
              mainAxisSize: MainAxisSize.min,
              children: [
                Container(
                  padding: const EdgeInsets.all(20),
                  decoration: BoxDecoration(
                    gradient: AppColors.primaryGradient,
                    shape: BoxShape.circle,
                    boxShadow: [
                      BoxShadow(
                        color: AppColors.primaryStart.withOpacity(0.3),
                        blurRadius: 20,
                        spreadRadius: 5,
                      ),
                    ],
                  ),
                  child: const CircularProgressIndicator(
                    valueColor: AlwaysStoppedAnimation(Colors.white),
                    strokeWidth: 3,
                  ),
                ),
                const SizedBox(height: 24),
                Text(
                  'æ­£åœ¨åˆå§‹åŒ–...',
                  style: TextStyle(
                    fontSize: 16,
                    color: Colors.grey[600],
                    fontWeight: FontWeight.w500,
                  ),
                ),
              ],
            ),
          ),
        ),
      );
    }
    
    final totalChars = _calculateTotalChars();
    final isMemoryFull = totalChars > 50000; // ç”¨æˆ·APIæ”¯æŒ60K tokens

    return Scaffold(
      extendBodyBehindAppBar: true,
      backgroundColor: Colors.transparent,
      body: Stack(
        children: [
          // åŠ¨æ€èƒŒæ™¯
          _buildAnimatedBackground(),
          
          // ä¸»å†…å®¹
          Column(
            children: [
              // åä¸½æ¸å˜ AppBar
              _buildGlassAppBar(context, totalChars, isMemoryFull),
              
              // è®°å¿†çŠ¶æ€æ  - ç»ç’ƒæ•ˆæœ
              if (totalChars > 0)
                _buildMemoryStatusBar(totalChars, isMemoryFull),
              
              // æ¨ç†é“¾/Plan æ˜¾ç¤ºé¢æ¿
              if (_showReasoningPanel && _sending)
                _buildReasoningPanel(),
              
              // æ¶ˆæ¯åˆ—è¡¨ - å¸¦åŠ¨ç”»æ•ˆæœ
              Expanded(
                child: _messages.isEmpty
                    ? _buildEmptyState()
                    : ListView.builder(
                        controller: _scrollCtrl,
                        padding: const EdgeInsets.symmetric(horizontal: 16, vertical: 20),
                        itemCount: _messages.length,
                        itemBuilder: (context, index) {
                          // ä¸ºæœ€æ–°çš„æ¶ˆæ¯æ·»åŠ å¼¹å…¥åŠ¨ç”»
                          final isRecent = index >= _messages.length - 2;
                          if (isRecent) {
                            return TweenAnimationBuilder<double>(
                              duration: const Duration(milliseconds: 400),
                              curve: Curves.easeOutBack,
                              tween: Tween(begin: 0.0, end: 1.0),
                              builder: (context, value, child) {
                                return Transform.translate(
                                  offset: Offset(0, 20 * (1 - value)),
                                  child: Opacity(
                                    opacity: value.clamp(0.0, 1.0),
                                    child: Transform.scale(
                                      scale: 0.95 + 0.05 * value,
                                      child: child,
                                    ),
                                  ),
                                );
                              },
                              child: _buildMessageItem(_messages[index]),
                            );
                          }
                          return _buildMessageItem(_messages[index]);
                        },
                      ),
              ),
            
              // åä¸½è¾“å…¥åŒºåŸŸ
              _buildFancyInputArea(context),
            ],
          ),
        ],
      ),
    );
  }
  
  /// åŠ¨æ€æ¸å˜èƒŒæ™¯
  Widget _buildAnimatedBackground() {
    return AnimatedBuilder(
      animation: _backgroundAnimation,
      builder: (context, child) {
        final value = _backgroundAnimation.value;
        return Container(
          decoration: BoxDecoration(
            gradient: LinearGradient(
              begin: Alignment(
                math.cos(value) * 0.5,
                math.sin(value) * 0.5,
              ),
              end: Alignment(
                math.cos(value + math.pi) * 0.5,
                math.sin(value + math.pi) * 0.5,
              ),
              colors: [
                AppColors.bgStart,
                Color.lerp(AppColors.bgEnd, AppColors.primaryStart.withOpacity(0.05), 
                    (math.sin(value) + 1) / 2)!,
                AppColors.bgEnd,
              ],
              stops: const [0.0, 0.5, 1.0],
            ),
          ),
          child: CustomPaint(
            painter: _ParticlePainter(value),
            size: Size.infinite,
          ),
        );
      },
    );
  }
  
  /// æ¨ç†é“¾/Plan æ˜¾ç¤ºé¢æ¿
  Widget _buildReasoningPanel() {
    return AnimatedContainer(
      duration: const Duration(milliseconds: 300),
      margin: const EdgeInsets.symmetric(horizontal: 16, vertical: 8),
      padding: const EdgeInsets.all(12),
      decoration: BoxDecoration(
        color: Colors.white.withOpacity(0.95),
        borderRadius: BorderRadius.circular(16),
        border: Border.all(color: AppColors.primaryStart.withOpacity(0.2)),
        boxShadow: [
          BoxShadow(
            color: AppColors.primaryStart.withOpacity(0.1),
            blurRadius: 12,
            offset: const Offset(0, 4),
          ),
        ],
      ),
      child: Column(
        crossAxisAlignment: CrossAxisAlignment.start,
        mainAxisSize: MainAxisSize.min,
        children: [
          // æ ‡é¢˜æ 
          Row(
            children: [
              Container(
                padding: const EdgeInsets.all(6),
                decoration: BoxDecoration(
                  gradient: AppColors.primaryGradient,
                  borderRadius: BorderRadius.circular(8),
                ),
                child: const Icon(Icons.psychology_rounded, size: 16, color: Colors.white),
              ),
              const SizedBox(width: 10),
              const Text(
                'Agent æ¨ç†è¿‡ç¨‹',
                style: TextStyle(
                  fontSize: 14,
                  fontWeight: FontWeight.bold,
                  color: Color(0xFF333333),
                ),
              ),
              const Spacer(),
              if (_currentPlan != null)
                Container(
                  padding: const EdgeInsets.symmetric(horizontal: 8, vertical: 4),
                  decoration: BoxDecoration(
                    color: AppColors.primaryStart.withOpacity(0.1),
                    borderRadius: BorderRadius.circular(12),
                  ),
                  child: Text(
                    'Step ${_currentPlanStep + 1}/${_currentPlan!.steps.length}',
                    style: TextStyle(
                      fontSize: 11,
                      fontWeight: FontWeight.w600,
                      color: AppColors.primaryStart,
                    ),
                  ),
                ),
              const SizedBox(width: 8),
              GestureDetector(
                onTap: () => setState(() => _showReasoningPanel = false),
                child: Icon(Icons.close_rounded, size: 18, color: Colors.grey[400]),
              ),
            ],
          ),
          
          // Plan ä¿¡æ¯
          if (_currentPlan != null) ...[
            const SizedBox(height: 12),
            _buildPlanInfo(_currentPlan!),
          ],
          
          // æ¨ç†æ­¥éª¤
          if (_reasoningSteps.isNotEmpty) ...[
            const SizedBox(height: 12),
            ConstrainedBox(
              constraints: const BoxConstraints(maxHeight: 120),
              child: SingleChildScrollView(
                child: Column(
                  crossAxisAlignment: CrossAxisAlignment.start,
                  children: _reasoningSteps.asMap().entries.map((entry) {
                    final index = entry.key;
                    final step = entry.value;
                    final isActive = index == _reasoningSteps.length - 1;
                    return Padding(
                      padding: const EdgeInsets.only(bottom: 6),
                      child: Row(
                        crossAxisAlignment: CrossAxisAlignment.start,
                        children: [
                          Container(
                            width: 20,
                            height: 20,
                            decoration: BoxDecoration(
                              color: isActive 
                                  ? AppColors.primaryStart 
                                  : Colors.green.withOpacity(0.8),
                              shape: BoxShape.circle,
                            ),
                            child: Center(
                              child: isActive
                                  ? SizedBox(
                                      width: 10,
                                      height: 10,
                                      child: CircularProgressIndicator(
                                        strokeWidth: 2,
                                        valueColor: const AlwaysStoppedAnimation(Colors.white),
                                      ),
                                    )
                                  : const Icon(Icons.check, size: 12, color: Colors.white),
                            ),
                          ),
                          const SizedBox(width: 8),
                          Expanded(
                            child: Text(
                              step,
                              style: TextStyle(
                                fontSize: 12,
                                color: isActive ? AppColors.primaryStart : Colors.grey[600],
                                fontWeight: isActive ? FontWeight.w500 : FontWeight.normal,
                              ),
                            ),
                          ),
                        ],
                      ),
                    );
                  }).toList(),
                ),
              ),
            ),
          ],
          
          // å½“å‰æ¨ç†
          if (_currentReasoning.isNotEmpty) ...[
            const SizedBox(height: 8),
            Container(
              padding: const EdgeInsets.all(10),
              decoration: BoxDecoration(
                color: AppColors.primaryStart.withOpacity(0.05),
                borderRadius: BorderRadius.circular(10),
              ),
              child: Row(
                crossAxisAlignment: CrossAxisAlignment.start,
                children: [
                  _buildBouncingDots(),
                  const SizedBox(width: 10),
                  Expanded(
                    child: Text(
                      _currentReasoning,
                      style: TextStyle(
                        fontSize: 12,
                        color: Colors.grey[700],
                        fontStyle: FontStyle.italic,
                      ),
                      maxLines: 2,
                      overflow: TextOverflow.ellipsis,
                    ),
                  ),
                ],
              ),
            ),
          ],
        ],
      ),
    );
  }
  
  /// Plan ä¿¡æ¯å±•ç¤º
  Widget _buildPlanInfo(AgentPlan plan) {
    return Container(
      padding: const EdgeInsets.all(10),
      decoration: BoxDecoration(
        gradient: LinearGradient(
          colors: [
            AppColors.primaryStart.withOpacity(0.08),
            AppColors.primaryEnd.withOpacity(0.04),
          ],
        ),
        borderRadius: BorderRadius.circular(10),
        border: Border.all(color: AppColors.primaryStart.withOpacity(0.1)),
      ),
      child: Column(
        crossAxisAlignment: CrossAxisAlignment.start,
        children: [
          // ä¸‰è½®æ€è€ƒ
          _buildThinkingRow('ğŸ¯ æ„å›¾', plan.userIntent),
          const SizedBox(height: 6),
          _buildThinkingRow('ğŸ”§ èƒ½åŠ›', plan.capabilityReview),
          const SizedBox(height: 6),
          _buildThinkingRow('âœ¨ é¢„æœŸ', plan.expectedOutcome),
          const SizedBox(height: 10),
          
          // æ‰§è¡Œæ­¥éª¤
          Wrap(
            spacing: 6,
            runSpacing: 6,
            children: plan.steps.asMap().entries.map((entry) {
              final index = entry.key;
              final step = entry.value;
              final isCompleted = index < _currentPlanStep;
              final isActive = index == _currentPlanStep;
              
              return Container(
                padding: const EdgeInsets.symmetric(horizontal: 10, vertical: 5),
                decoration: BoxDecoration(
                  color: isCompleted 
                      ? Colors.green.withOpacity(0.15)
                      : isActive 
                          ? AppColors.primaryStart.withOpacity(0.2)
                          : Colors.grey.withOpacity(0.1),
                  borderRadius: BorderRadius.circular(20),
                  border: Border.all(
                    color: isCompleted 
                        ? Colors.green.withOpacity(0.3)
                        : isActive 
                            ? AppColors.primaryStart.withOpacity(0.4)
                            : Colors.grey.withOpacity(0.2),
                  ),
                ),
                child: Row(
                  mainAxisSize: MainAxisSize.min,
                  children: [
                    if (isCompleted)
                      const Icon(Icons.check_circle, size: 14, color: Colors.green)
                    else if (isActive)
                      SizedBox(
                        width: 14,
                        height: 14,
                        child: CircularProgressIndicator(
                          strokeWidth: 2,
                          valueColor: AlwaysStoppedAnimation(AppColors.primaryStart),
                        ),
                      )
                    else
                      Icon(Icons.circle_outlined, size: 14, color: Colors.grey[400]),
                    const SizedBox(width: 6),
                    Text(
                      '${index + 1}. ${step.action.name}',
                      style: TextStyle(
                        fontSize: 11,
                        fontWeight: isActive ? FontWeight.w600 : FontWeight.normal,
                        color: isCompleted 
                            ? Colors.green[700]
                            : isActive 
                                ? AppColors.primaryStart
                                : Colors.grey[600],
                      ),
                    ),
                  ],
                ),
              );
            }).toList(),
          ),
        ],
      ),
    );
  }
  
  Widget _buildThinkingRow(String label, String content) {
    return Row(
      crossAxisAlignment: CrossAxisAlignment.start,
      children: [
        Text(label, style: const TextStyle(fontSize: 11)),
        const SizedBox(width: 6),
        Expanded(
          child: Text(
            content,
            style: TextStyle(fontSize: 11, color: Colors.grey[700]),
            maxLines: 1,
            overflow: TextOverflow.ellipsis,
          ),
        ),
      ],
    );
  }

  // è®°å¿†çŠ¶æ€æ 
  Widget _buildMemoryStatusBar(int totalChars, bool isMemoryFull) {
    final progress = (totalChars / 50000).clamp(0.0, 1.0); // ç”¨æˆ·APIæ”¯æŒ60K tokens
    return Container(
      margin: const EdgeInsets.symmetric(horizontal: 16, vertical: 8),
      padding: const EdgeInsets.symmetric(horizontal: 16, vertical: 10),
      decoration: BoxDecoration(
        color: Colors.white.withOpacity(0.9),
        borderRadius: BorderRadius.circular(16),
        boxShadow: [
          BoxShadow(
            color: isMemoryFull 
                ? Colors.red.withOpacity(0.15)
                : AppColors.shadowLight,
            blurRadius: 10,
            offset: const Offset(0, 2),
          ),
        ],
        border: Border.all(
          color: isMemoryFull 
              ? Colors.red.withOpacity(0.3)
              : Colors.white.withOpacity(0.5),
        ),
      ),
      child: Row(
        children: [
          Container(
            padding: const EdgeInsets.all(6),
            decoration: BoxDecoration(
              gradient: isMemoryFull 
                  ? const LinearGradient(colors: [Color(0xFFFF6B6B), Color(0xFFEE5A5A)])
                  : AppColors.primaryGradient,
              borderRadius: BorderRadius.circular(8),
            ),
            child: Icon(
              isMemoryFull ? Icons.warning_amber_rounded : Icons.psychology_rounded, 
              size: 16, 
              color: Colors.white,
            ),
          ),
          const SizedBox(width: 12),
          Expanded(
            child: Column(
              crossAxisAlignment: CrossAxisAlignment.start,
              children: [
                Text(
                  isMemoryFull ? 'è®°å¿†å³å°†æ»¡è½½' : 'è®°å¿†å®¹é‡',
                  style: TextStyle(
                    fontSize: 11,
                    fontWeight: FontWeight.w600,
                    color: isMemoryFull ? Colors.red[700] : Colors.grey[700],
                  ),
                ),
                const SizedBox(height: 4),
                Stack(
                  children: [
                    Container(
                      height: 4,
                      decoration: BoxDecoration(
                        color: Colors.grey[200],
                        borderRadius: BorderRadius.circular(2),
                      ),
                    ),
                    FractionallySizedBox(
                      widthFactor: progress,
                      child: Container(
                        height: 4,
                        decoration: BoxDecoration(
                          gradient: isMemoryFull 
                              ? const LinearGradient(colors: [Color(0xFFFF6B6B), Color(0xFFEE5A5A)])
                              : AppColors.primaryGradient,
                          borderRadius: BorderRadius.circular(2),
                          boxShadow: [
                            BoxShadow(
                              color: (isMemoryFull ? Colors.red : AppColors.primaryStart).withOpacity(0.4),
                              blurRadius: 4,
                            ),
                          ],
                        ),
                      ),
                    ),
                  ],
                ),
              ],
            ),
          ),
          const SizedBox(width: 8),
          Text(
            '$totalChars',
            style: TextStyle(
              fontSize: 12,
              fontWeight: FontWeight.bold,
              color: isMemoryFull ? Colors.red : AppColors.primaryStart,
            ),
          ),
          if (totalChars > 500)
            Padding(
              padding: const EdgeInsets.only(left: 8),
              child: Material(
                color: Colors.transparent,
                child: InkWell(
                  onTap: _sending ? null : _performAdaptiveCompression,
                  borderRadius: BorderRadius.circular(8),
                  child: Container(
                    padding: const EdgeInsets.symmetric(horizontal: 10, vertical: 6),
                    decoration: BoxDecoration(
                      gradient: isMemoryFull 
                          ? const LinearGradient(colors: [Color(0xFFFF6B6B), Color(0xFFEE5A5A)])
                          : AppColors.primaryGradient,
                      borderRadius: BorderRadius.circular(8),
                      boxShadow: [
                        BoxShadow(
                          color: (isMemoryFull ? Colors.red : AppColors.primaryStart).withOpacity(0.3),
                          blurRadius: 6,
                          offset: const Offset(0, 2),
                        ),
                      ],
                    ),
                    child: const Text(
                      'å‹ç¼©',
                      style: TextStyle(
                        fontSize: 11,
                        fontWeight: FontWeight.w600,
                        color: Colors.white,
                      ),
                    ),
                  ),
                ),
              ),
            ),
        ],
      ),
    );
  }

  // ç©ºçŠ¶æ€ - å¸¦åŠ¨ç”»æ•ˆæœ
  Widget _buildEmptyState() {
    return Center(
      child: AnimatedBuilder(
        animation: _floatAnimation,
        builder: (context, child) {
          return Transform.translate(
            offset: Offset(0, _floatAnimation.value),
            child: child,
          );
        },
        child: Column(
          mainAxisAlignment: MainAxisAlignment.center,
          children: [
            ScaleTransition(
              scale: _pulseAnimation,
              child: Container(
                padding: const EdgeInsets.all(28),
                decoration: BoxDecoration(
                  gradient: AppColors.primaryGradient,
                  shape: BoxShape.circle,
                  boxShadow: [
                    BoxShadow(
                      color: AppColors.primaryStart.withOpacity(0.4),
                      blurRadius: 30,
                      offset: const Offset(0, 10),
                    ),
                  ],
                ),
                child: const Icon(
                  Icons.auto_awesome_rounded,
                  size: 48,
                  color: Colors.white,
                ),
              ),
            ),
            const SizedBox(height: 32),
            ShaderMask(
              shaderCallback: (bounds) => AppColors.primaryGradient.createShader(bounds),
              child: const Text(
                'å¼€å§‹æ–°çš„å¯¹è¯',
                style: TextStyle(
                  fontSize: 22,
                  fontWeight: FontWeight.bold,
                  color: Colors.white,
                ),
              ),
            ),
            const SizedBox(height: 12),
            Container(
              padding: const EdgeInsets.symmetric(horizontal: 16, vertical: 8),
              decoration: BoxDecoration(
                color: Colors.white.withOpacity(0.8),
                borderRadius: BorderRadius.circular(20),
                boxShadow: [
                  BoxShadow(
                    color: AppColors.shadowLight,
                    blurRadius: 10,
                  ),
                ],
              ),
              child: Row(
                mainAxisSize: MainAxisSize.min,
                children: [
                  Container(
                    width: 8,
                    height: 8,
                    decoration: BoxDecoration(
                      gradient: AppColors.primaryGradient,
                      shape: BoxShape.circle,
                    ),
                  ),
                  const SizedBox(width: 8),
                  Text(
                    _activePersona.name,
                    style: TextStyle(
                      fontSize: 14,
                      fontWeight: FontWeight.w500,
                      color: Colors.grey[700],
                    ),
                  ),
                ],
              ),
            ),
          ],
        ),
      ),
    );
  }

  // åä¸½è¾“å…¥åŒºåŸŸ - ç»ç’ƒè´¨æ„Ÿ
  Widget _buildFancyInputArea(BuildContext context) {
    return ClipRRect(
      borderRadius: const BorderRadius.vertical(top: Radius.circular(28)),
      child: BackdropFilter(
        filter: ImageFilter.blur(sigmaX: 20, sigmaY: 20),
        child: Container(
          decoration: BoxDecoration(
            gradient: LinearGradient(
              begin: Alignment.topCenter,
              end: Alignment.bottomCenter,
              colors: [
                Colors.white.withOpacity(0.85),
                Colors.white.withOpacity(0.95),
              ],
            ),
            borderRadius: const BorderRadius.vertical(top: Radius.circular(28)),
            border: Border(
              top: BorderSide(
                color: Colors.white.withOpacity(0.8),
                width: 1.5,
              ),
            ),
            boxShadow: [
              BoxShadow(
                color: AppColors.shadowMedium,
                blurRadius: 20,
                offset: const Offset(0, -8),
              ),
            ],
          ),
          child: SafeArea(
            child: Column(
              mainAxisSize: MainAxisSize.min,
              children: [
                // åŠ è½½çŠ¶æ€ - ä½¿ç”¨è·³åŠ¨åŠ¨ç”»
                if (_sending)
                  _loadingStatus.contains('æœç´¢çŸ¥è¯†åº“') || _loadingStatus.contains('è¯»å–çŸ¥è¯†åº“')
                      ? _buildScanningIndicator(_loadingStatus.isEmpty ? 'æ­£åœ¨æ€è€ƒ...' : _loadingStatus)
                      : Container(
                          padding: const EdgeInsets.symmetric(horizontal: 20, vertical: 12),
                          child: Row(
                            children: [
                              _buildBouncingDots(),
                              const SizedBox(width: 14),
                              Expanded(
                                child: Text(
                                  _loadingStatus.isEmpty ? 'æ­£åœ¨æ€è€ƒ...' : _loadingStatus,
                                  style: TextStyle(
                                    fontSize: 13,
                                    color: AppColors.primaryStart,
                                    fontWeight: FontWeight.w500,
                                  ),
                                  overflow: TextOverflow.ellipsis,
                                ),
                              ),
                            ],
                          ),
                        ),
                // å·²é€‰å›¾ç‰‡é¢„è§ˆ
                if (_selectedImage != null)
                  Container(
                    margin: const EdgeInsets.fromLTRB(16, 8, 16, 0),
                    padding: const EdgeInsets.all(10),
                    decoration: BoxDecoration(
                      gradient: LinearGradient(
                        colors: [
                          AppColors.primaryStart.withOpacity(0.1),
                          AppColors.primaryEnd.withOpacity(0.05),
                        ],
                      ),
                      borderRadius: BorderRadius.circular(16),
                      border: Border.all(color: AppColors.primaryStart.withOpacity(0.2)),
                    ),
                    child: Row(
                      children: [
                        ClipRRect(
                          borderRadius: BorderRadius.circular(10),
                          child: Image.file(File(_selectedImage!.path), width: 50, height: 50, fit: BoxFit.cover),
                        ),
                        const SizedBox(width: 12),
                        Expanded(
                          child: Column(
                            crossAxisAlignment: CrossAxisAlignment.start,
                            children: [
                              const Text('å·²é€‰æ‹©å›¾ç‰‡', style: TextStyle(fontSize: 13, fontWeight: FontWeight.w600)),
                              Text('ç‚¹å‡»å‘é€è¿›è¡Œè¯†å›¾', style: TextStyle(fontSize: 11, color: Colors.grey[500])),
                            ],
                          ),
                        ),
                        IconButton(
                          icon: Icon(Icons.close_rounded, size: 20, color: Colors.grey[400]),
                          onPressed: () => setState(() => _selectedImage = null),
                        ),
                      ],
                    ),
                  ),
                // è¾“å…¥è¡Œ
                Padding(
                  padding: const EdgeInsets.fromLTRB(8, 8, 8, 12),
                  child: Row(
                    crossAxisAlignment: CrossAxisAlignment.end,
                    children: [
                      // å›¾ç‰‡æŒ‰é’®
                      _buildInputActionButton(
                        icon: Icons.add_photo_alternate_rounded,
                        onPressed: _sending ? null : _pickImage,
                        tooltip: 'å‘é€å›¾ç‰‡',
                      ),
                      // æ–‡ä»¶æŒ‰é’®
                      _buildInputActionButton(
                        icon: Icons.attach_file_rounded,
                        onPressed: _sending ? null : _pickAndIngestFile,
                        tooltip: 'ä¸Šä¼ æ–‡ä»¶',
                      ),
                      // ç”Ÿå›¾æŒ‰é’®
                      _buildInputActionButton(
                        icon: Icons.auto_fix_high_rounded,
                        onPressed: _sending ? null : _manualGenerateImage,
                        tooltip: 'AI ç”Ÿå›¾',
                      ),
                      const SizedBox(width: 8),
                      // è¾“å…¥æ¡†
                      Expanded(
                        child: Container(
                          decoration: BoxDecoration(
                            color: Colors.grey[100],
                            borderRadius: BorderRadius.circular(24),
                            border: Border.all(color: Colors.grey[200]!),
                          ),
                          child: TextField(
                            controller: _inputCtrl,
                            maxLines: 5,
                            minLines: 1,
                            textInputAction: TextInputAction.send,
                            onSubmitted: (_) => _sending ? null : _send(),
                            style: const TextStyle(fontSize: 15),
                            decoration: InputDecoration(
                              hintText: 'è¾“å…¥æ¶ˆæ¯...',
                              hintStyle: TextStyle(color: Colors.grey[400]),
                              border: InputBorder.none,
                              contentPadding: const EdgeInsets.symmetric(horizontal: 18, vertical: 12),
                            ),
                          ),
                        ),
                      ),
                      const SizedBox(width: 8),
                      // å‘é€æŒ‰é’® - å¸¦è„‰å†²åŠ¨ç”»å’Œç‚¹å‡»æ³¢çº¹
                      GestureDetector(
                        onTapDown: (_) {
                          if (!_sending) {
                            _sendButtonController.forward();
                          }
                        },
                        onTapUp: (_) {
                          _sendButtonController.reverse();
                        },
                        onTapCancel: () {
                          _sendButtonController.reverse();
                        },
                        child: AnimatedBuilder(
                          animation: Listenable.merge([_pulseController, _sendButtonController]),
                          builder: (context, child) {
                            final canSend = !_sending && (_inputCtrl.text.trim().isNotEmpty || _selectedImage != null);
                            final pressScale = 1.0 - _sendButtonController.value * 0.1;
                            return Transform.scale(
                              scale: (canSend ? 1.0 + (_pulseAnimation.value - 1.0) * 0.3 : 1.0) * pressScale,
                              child: Stack(
                                alignment: Alignment.center,
                                children: [
                                  // å¤–åœˆå…‰ç¯åŠ¨æ•ˆ
                                  if (canSend)
                                    ...List.generate(2, (i) {
                                      final delay = i * 0.5;
                                      final ringValue = (_pulseController.value + delay) % 1.0;
                                      return Container(
                                        width: 48 + ringValue * 20,
                                        height: 48 + ringValue * 20,
                                        decoration: BoxDecoration(
                                          shape: BoxShape.circle,
                                          border: Border.all(
                                            color: AppColors.primaryStart.withOpacity((1 - ringValue) * 0.3),
                                            width: 2,
                                          ),
                                        ),
                                      );
                                    }),
                                  // ä¸»æŒ‰é’®
                                  Container(
                                    decoration: BoxDecoration(
                                      gradient: _sending ? null : AppColors.primaryGradient,
                                      color: _sending ? Colors.grey[300] : null,
                                      shape: BoxShape.circle,
                                      boxShadow: _sending ? null : [
                                        BoxShadow(
                                          color: AppColors.primaryStart.withOpacity(0.3 + _pulseAnimation.value * 0.2),
                                          blurRadius: 12 + _pulseAnimation.value * 8,
                                          offset: const Offset(0, 4),
                                          spreadRadius: _pulseAnimation.value * 2,
                                        ),
                                      ],
                                    ),
                                    child: Material(
                                      color: Colors.transparent,
                                      child: InkWell(
                                        onTap: _sending ? null : _send,
                                        borderRadius: BorderRadius.circular(24),
                                        splashColor: Colors.white.withOpacity(0.3),
                                        highlightColor: Colors.white.withOpacity(0.1),
                                        child: Container(
                                          width: 48,
                                          height: 48,
                                          alignment: Alignment.center,
                                          child: AnimatedSwitcher(
                                            duration: const Duration(milliseconds: 200),
                                            transitionBuilder: (child, animation) {
                                              return RotationTransition(
                                                turns: Tween(begin: 0.5, end: 1.0).animate(animation),
                                                child: ScaleTransition(scale: animation, child: child),
                                              );
                                            },
                                            child: _sending
                                                ? SizedBox(
                                                    width: 20,
                                                    height: 20,
                                                    child: CircularProgressIndicator(
                                                      strokeWidth: 2,
                                                      valueColor: AlwaysStoppedAnimation(Colors.grey[500]),
                                                    ),
                                                  )
                                                : Icon(
                                                    Icons.arrow_upward_rounded,
                                                    key: const ValueKey('send'),
                                                    color: Colors.white,
                                                    size: 24,
                                                  ),
                                          ),
                                        ),
                                      ),
                                    ),
                                  ),
                                ],
                              ),
                            );
                          },
                        ),
                      ),
                    ],
                  ),
                ),
              ],
            ),
          ),
        ),
      ),
    );
  }

  Widget _buildInputActionButton({
    required IconData icon,
    required VoidCallback? onPressed,
    required String tooltip,
  }) {
    return Material(
      color: Colors.transparent,
      child: InkWell(
        onTap: onPressed,
        borderRadius: BorderRadius.circular(12),
        child: Container(
          padding: const EdgeInsets.all(10),
          child: Icon(
            icon,
            color: onPressed != null ? Colors.grey[600] : Colors.grey[400],
            size: 24,
          ),
        ),
      ),
    );
  }

  // åä¸½ç»ç’ƒæ•ˆæœ AppBar
  Widget _buildGlassAppBar(BuildContext context, int totalChars, bool isMemoryFull) {
    return ClipRRect(
      child: BackdropFilter(
        filter: ImageFilter.blur(sigmaX: 10, sigmaY: 10),
        child: Container(
          padding: EdgeInsets.only(top: MediaQuery.of(context).padding.top),
          decoration: BoxDecoration(
            gradient: LinearGradient(
              colors: [
                AppColors.primaryStart.withOpacity(0.9),
                AppColors.primaryEnd.withOpacity(0.85),
              ],
              begin: Alignment.topLeft,
              end: Alignment.bottomRight,
            ),
            border: Border(
              bottom: BorderSide(
                color: Colors.white.withOpacity(0.2),
                width: 1,
              ),
            ),
            boxShadow: [
              BoxShadow(
                color: AppColors.primaryStart.withOpacity(0.3),
                blurRadius: 20,
                offset: const Offset(0, 4),
              ),
            ],
          ),
          child: Column(
            children: [
              // ä¸» AppBar åŒºåŸŸ
              Padding(
                padding: const EdgeInsets.symmetric(horizontal: 8, vertical: 8),
                child: Row(
                  children: [
                    const SizedBox(width: 8),
                    // æ ‡é¢˜åŒºåŸŸ
                    Expanded(
                      child: Column(
                        crossAxisAlignment: CrossAxisAlignment.start,
                        children: [
                          const Text(
                            'One-API åŠ©æ‰‹',
                            style: TextStyle(
                              fontSize: 18,
                              fontWeight: FontWeight.bold,
                              color: Colors.white,
                              letterSpacing: 0.5,
                            ),
                          ),
                          const SizedBox(height: 2),
                          Row(
                            children: [
                              Container(
                                width: 6,
                                height: 6,
                                decoration: BoxDecoration(
                                  color: Colors.greenAccent,
                                  shape: BoxShape.circle,
                                  boxShadow: [
                                    BoxShadow(
                                      color: Colors.greenAccent.withOpacity(0.5),
                                      blurRadius: 4,
                                    ),
                                  ],
                                ),
                              ),
                              const SizedBox(width: 6),
                              Text(
                                _chatModel,
                                style: TextStyle(
                              fontSize: 11,
                              color: Colors.white.withOpacity(0.8),
                            ),
                          ),
                        ],
                      ),
                    ],
                  ),
                ),
                // æ“ä½œæŒ‰é’®
                _buildAppBarButton(
                  icon: Icons.delete_outline_rounded,
                  onPressed: () {
                    setState(() {
                      _messages.clear();
                      _saveChatHistory();
                      _refManager.clearExternalReferences();
                    });
                  },
                  tooltip: 'æ¸…ç©ºå¯¹è¯',
                ),
                // æ¨ç†é“¾æ˜¾ç¤ºåˆ‡æ¢æŒ‰é’®
                _buildAppBarButton(
                  icon: _showReasoningPanel ? Icons.psychology : Icons.psychology_outlined,
                  onPressed: () {
                    setState(() => _showReasoningPanel = !_showReasoningPanel);
                  },
                  tooltip: 'æ˜¾ç¤º/éšè—æ¨ç†è¿‡ç¨‹',
                ),
                _buildPersonaSwitcher(context),
                _buildAppBarButton(
                  icon: Icons.settings_outlined,
                  onPressed: _openSettings,
                  tooltip: 'è®¾ç½®',
                ),
              ],
            ),
          ),
        ],
      ),
      ),
      ),
    );
  }

  Widget _buildAppBarButton({
    required IconData icon,
    required VoidCallback onPressed,
    required String tooltip,
  }) {
    return Material(
      color: Colors.transparent,
      child: InkWell(
        onTap: onPressed,
        borderRadius: BorderRadius.circular(12),
        child: Container(
          padding: const EdgeInsets.all(10),
          decoration: BoxDecoration(
            color: Colors.white.withOpacity(0.15),
            borderRadius: BorderRadius.circular(12),
          ),
          child: Icon(icon, color: Colors.white, size: 20),
        ),
      ),
    );
  }

  Widget _buildPersonaSwitcher(BuildContext context) {
    return PopupMenuButton<String>(
      tooltip: 'åˆ‡æ¢äººæ ¼',
      offset: const Offset(0, 48),
      shape: RoundedRectangleBorder(borderRadius: BorderRadius.circular(16)),
      onSelected: (value) {
        if (value == 'manage') {
          _openPersonaManager();
        } else {
          _switchPersona(value);
        }
      },
      itemBuilder: (context) {
        return [
          ..._personas.map((p) => PopupMenuItem(
            value: p.id,
            child: Row(
              children: [
                Container(
                  width: 28, height: 28,
                  decoration: BoxDecoration(
                    shape: BoxShape.circle,
                    gradient: p.id == _currentPersonaId 
                        ? AppColors.primaryGradient 
                        : null,
                    color: p.id != _currentPersonaId ? Colors.grey[200] : null,
                    image: p.avatarPath != null && File(p.avatarPath!).existsSync()
                        ? DecorationImage(image: FileImage(File(p.avatarPath!)), fit: BoxFit.cover)
                        : null,
                  ),
                  child: p.avatarPath == null 
                      ? Icon(Icons.person, size: 16, color: p.id == _currentPersonaId ? Colors.white : Colors.grey) 
                      : null,
                ),
                const SizedBox(width: 12),
                Expanded(
                  child: Text(p.name, style: TextStyle(
                    fontWeight: p.id == _currentPersonaId ? FontWeight.bold : FontWeight.normal,
                    color: p.id == _currentPersonaId ? AppColors.primaryStart : null,
                  )),
                ),
                if (p.id == _currentPersonaId)
                  Container(
                    padding: const EdgeInsets.all(2),
                    decoration: const BoxDecoration(
                      gradient: AppColors.primaryGradient,
                      shape: BoxShape.circle,
                    ),
                    child: const Icon(Icons.check, size: 12, color: Colors.white),
                  ),
              ],
            ),
          )),
          const PopupMenuDivider(),
          const PopupMenuItem(
            value: 'manage',
            child: Row(
              children: [
                Icon(Icons.settings_accessibility, size: 20, color: Colors.grey),
                SizedBox(width: 12),
                Text('ç®¡ç†äººæ ¼...'),
              ],
            ),
          ),
        ];
      },
      child: Container(
        padding: const EdgeInsets.all(10),
        margin: const EdgeInsets.symmetric(horizontal: 4),
        decoration: BoxDecoration(
          color: Colors.white.withOpacity(0.15),
          borderRadius: BorderRadius.circular(12),
        ),
        child: const Icon(Icons.people_outline, color: Colors.white, size: 20),
      ),
    );
  }

  Widget _buildMessageItem(ChatMessage m) {
    final isUser = m.role == 'user';
    final isSystem = m.role == 'system';

    if (isSystem) {
      return Center(
        child: Container(
          margin: const EdgeInsets.symmetric(vertical: 16),
          padding: const EdgeInsets.symmetric(horizontal: 16, vertical: 8),
          decoration: BoxDecoration(
            gradient: LinearGradient(
              colors: [
                Colors.grey[200]!.withOpacity(0.8),
                Colors.grey[100]!.withOpacity(0.8),
              ],
            ),
            borderRadius: BorderRadius.circular(20),
            border: Border.all(color: Colors.grey[300]!.withOpacity(0.5)),
          ),
          child: Text(
            m.content,
            style: TextStyle(fontSize: 11, color: Colors.grey[600], fontWeight: FontWeight.w500),
          ),
        ),
      );
    }

    // å‹ç¼©æ¶ˆæ¯ UI - æ›´åä¸½
    if (m.isCompressed) {
      return Padding(
        padding: const EdgeInsets.only(bottom: 12),
        child: Row(
          mainAxisAlignment: isUser ? MainAxisAlignment.end : MainAxisAlignment.start,
          children: [
            if (!isUser) ...[
              _buildAvatar(isUser: false),
              const SizedBox(width: 8),
            ],
            Container(
              width: 200,
              padding: const EdgeInsets.all(12),
              decoration: BoxDecoration(
                gradient: LinearGradient(
                  colors: [Colors.grey[100]!, Colors.grey[50]!],
                  begin: Alignment.topLeft,
                  end: Alignment.bottomRight,
                ),
                borderRadius: BorderRadius.circular(16),
                border: Border.all(color: Colors.grey[300]!),
                boxShadow: [
                  BoxShadow(
                    color: Colors.grey.withOpacity(0.1),
                    blurRadius: 8,
                    offset: const Offset(0, 2),
                  ),
                ],
              ),
              child: Column(
                crossAxisAlignment: CrossAxisAlignment.start,
                children: [
                  Row(
                    children: [
                      Container(
                        padding: const EdgeInsets.all(4),
                        decoration: BoxDecoration(
                          gradient: AppColors.primaryGradient,
                          borderRadius: BorderRadius.circular(6),
                        ),
                        child: const Icon(Icons.compress, size: 12, color: Colors.white),
                      ),
                      const SizedBox(width: 8),
                      Expanded(
                        child: Text(
                          'å·²å‹ç¼© (${(m.compressionRatio! * 100).toInt()}%)',
                          style: TextStyle(fontSize: 11, fontWeight: FontWeight.bold, color: Colors.grey[700]),
                        ),
                      ),
                      Text(
                        '${m.content.length}å­—',
                        style: TextStyle(fontSize: 10, color: Colors.grey[500]),
                      ),
                    ],
                  ),
                  const SizedBox(height: 8),
                  Stack(
                    children: [
                      Container(
                        height: 4,
                        decoration: BoxDecoration(
                          color: Colors.grey[200],
                          borderRadius: BorderRadius.circular(2),
                        ),
                      ),
                      FractionallySizedBox(
                        widthFactor: m.compressionRatio!,
                        child: Container(
                          height: 4,
                          decoration: BoxDecoration(
                            gradient: AppColors.primaryGradient,
                            borderRadius: BorderRadius.circular(2),
                          ),
                        ),
                      ),
                    ],
                  ),
                ],
              ),
            ),
            if (isUser) ...[
              const SizedBox(width: 8),
              _buildAvatar(isUser: true),
            ],
          ],
        ),
      );
    }

    // æ™®é€šæ¶ˆæ¯ - åä¸½æ°”æ³¡
    return Padding(
      padding: const EdgeInsets.only(bottom: 20),
      child: Row(
        mainAxisAlignment: isUser ? MainAxisAlignment.end : MainAxisAlignment.start,
        crossAxisAlignment: CrossAxisAlignment.start,
        children: [
          if (!isUser) ...[
            _buildAvatar(isUser: false),
            const SizedBox(width: 10),
          ],
          Flexible(
            child: Column(
              crossAxisAlignment: isUser ? CrossAxisAlignment.end : CrossAxisAlignment.start,
              children: [
                if (!isUser)
                  Padding(
                    padding: const EdgeInsets.only(left: 4, bottom: 6),
                    child: Row(
                      mainAxisSize: MainAxisSize.min,
                      children: [
                        Container(
                          width: 6,
                          height: 6,
                          decoration: BoxDecoration(
                            gradient: AppColors.primaryGradient,
                            shape: BoxShape.circle,
                          ),
                        ),
                        const SizedBox(width: 6),
                        Text(
                          _activePersona.name,
                          style: TextStyle(
                            fontSize: 12,
                            fontWeight: FontWeight.w600,
                            color: Colors.grey[600],
                          ),
                        ),
                      ],
                    ),
                  ),
                Container(
                  padding: const EdgeInsets.symmetric(horizontal: 16, vertical: 12),
                  decoration: BoxDecoration(
                    gradient: isUser 
                        ? AppColors.userMessageGradient 
                        : LinearGradient(
                            begin: Alignment.topLeft,
                            end: Alignment.bottomRight,
                            colors: [
                              Colors.white,
                              Colors.grey[50]!,
                            ],
                          ),
                    borderRadius: BorderRadius.only(
                      topLeft: const Radius.circular(20),
                      topRight: const Radius.circular(20),
                      bottomLeft: Radius.circular(isUser ? 20 : 4),
                      bottomRight: Radius.circular(isUser ? 4 : 20),
                    ),
                    border: isUser ? null : Border.all(
                      color: Colors.white.withOpacity(0.8),
                      width: 1.5,
                    ),
                    boxShadow: [
                      BoxShadow(
                        color: isUser 
                            ? AppColors.primaryStart.withOpacity(0.3)
                            : Colors.black.withOpacity(0.08),
                        blurRadius: isUser ? 12 : 10,
                        offset: const Offset(0, 4),
                      ),
                      if (!isUser) BoxShadow(
                        color: Colors.white.withOpacity(0.8),
                        blurRadius: 1,
                        offset: const Offset(0, -1),
                      ),
                    ],
                  ),
                  child: Column(
                    crossAxisAlignment: CrossAxisAlignment.start,
                    children: [
                      if (m.localImagePath != null)
                        Padding(
                          padding: const EdgeInsets.only(bottom: 8.0),
                          child: ClipRRect(
                            borderRadius: BorderRadius.circular(12),
                            child: Builder(
                              builder: (context) {
                                final file = File(m.localImagePath!);
                                if (file.existsSync()) {
                                  return Image.file(file, width: 200, fit: BoxFit.cover);
                                } else {
                                  return Container(
                                    width: 200, height: 100,
                                    color: Colors.grey[300],
                                    child: const Column(
                                      mainAxisAlignment: MainAxisAlignment.center,
                                      children: [
                                        Icon(Icons.broken_image, color: Colors.grey),
                                        SizedBox(height: 4),
                                        Text('å›¾ç‰‡å·²å¤±æ•ˆ', style: TextStyle(fontSize: 10, color: Colors.grey)),
                                      ],
                                    ),
                                  );
                                }
                              },
                            ),
                          ),
                        ),
                      if (m.imageUrl != null)
                        Padding(
                          padding: const EdgeInsets.only(bottom: 8.0),
                          child: ClipRRect(
                            borderRadius: BorderRadius.circular(12),
                            child: Image.network(m.imageUrl!, width: 200, fit: BoxFit.cover),
                          ),
                        ),
                      if (m.content.isNotEmpty)
                        MarkdownBody(
                          data: m.content,
                          selectable: true,
                          inlineSyntaxes: [
                            BlockMathSyntax(),
                            InlineMathSyntax(),
                          ],
                          builders: {
                            'inline_math': MathBuilder(isBlock: false),
                            'block_math': MathBuilder(isBlock: true),
                          },
                          styleSheet: MarkdownStyleSheet(
                            p: TextStyle(
                              color: isUser ? Colors.white : Colors.black87,
                              fontSize: 15,
                              height: 1.4,
                            ),
                            code: TextStyle(
                              color: isUser ? Colors.white.withOpacity(0.9) : Colors.black87,
                              backgroundColor: isUser ? Colors.white.withOpacity(0.15) : Colors.grey[100],
                              fontFamily: 'monospace',
                              fontSize: 13,
                            ),
                            codeblockDecoration: BoxDecoration(
                              color: isUser ? Colors.black.withOpacity(0.1) : Colors.grey[50],
                              borderRadius: BorderRadius.circular(8),
                              border: Border.all(color: isUser ? Colors.white10 : Colors.grey[200]!),
                            ),
                          ),
                        ),
                      if (m.references != null && m.references!.isNotEmpty)
                        Padding(
                          padding: const EdgeInsets.only(top: 8.0),
                          child: Theme(
                            data: Theme.of(context).copyWith(dividerColor: Colors.transparent),
                            child: ExpansionTile(
                              tilePadding: EdgeInsets.zero,
                              childrenPadding: EdgeInsets.zero,
                              iconColor: isUser ? Colors.white70 : Colors.grey[400],
                              collapsedIconColor: isUser ? Colors.white70 : Colors.grey[400],
                              title: Row(
                                children: [
                                  Icon(Icons.link, size: 14, color: isUser ? Colors.white70 : Colors.grey[500]),
                                  const SizedBox(width: 4),
                                  Text(
                                    'å‚è€ƒèµ„æ–™ (${m.references!.length})',
                                    style: TextStyle(
                                      fontSize: 11,
                                      fontWeight: FontWeight.w500,
                                      color: isUser ? Colors.white70 : Colors.grey[500],
                                    ),
                                  ),
                                ],
                              ),
                              children: m.references!.map((ref) => InkWell(
                                onTap: () {
                                  if (ref.url.isNotEmpty) {
                                    Clipboard.setData(ClipboardData(text: ref.url));
                                    ScaffoldMessenger.of(context).showSnackBar(
                                      SnackBar(
                                        content: Text('é“¾æ¥å·²å¤åˆ¶: ${ref.url}'),
                                        duration: const Duration(seconds: 1),
                                        behavior: SnackBarBehavior.floating,
                                      ),
                                    );
                                  }
                                },
                                child: Container(
                                  margin: const EdgeInsets.only(bottom: 6),
                                  padding: const EdgeInsets.all(8),
                                  decoration: BoxDecoration(
                                    color: isUser ? Colors.white.withOpacity(0.1) : Colors.grey[50],
                                    borderRadius: BorderRadius.circular(8),
                                  ),
                                  child: Column(
                                    crossAxisAlignment: CrossAxisAlignment.start,
                                    children: [
                                      Text(
                                        ref.title,
                                        style: TextStyle(
                                          fontSize: 11,
                                          color: isUser ? Colors.white : Colors.black87,
                                          fontWeight: FontWeight.bold,
                                        ),
                                        maxLines: 1,
                                        overflow: TextOverflow.ellipsis,
                                      ),
                                      const SizedBox(height: 2),
                                      Text(
                                        ref.snippet,
                                        maxLines: 2,
                                        overflow: TextOverflow.ellipsis,
                                        style: TextStyle(
                                          fontSize: 10,
                                          color: isUser ? Colors.white70 : Colors.grey[600],
                                        ),
                                      ),
                                    ],
                                  ),
                                ),
                              )).toList(),
                            ),
                          ),
                        ),
                    ],
                  ),
                ),
              ],
            ),
          ),
          if (isUser) ...[
            const SizedBox(width: 8),
            _buildAvatar(isUser: true),
          ],
        ],
      ),
    );
  }

  Widget _buildAvatar({required bool isUser}) {
    if (isUser) {
      return Container(
        width: 40, height: 40,
        decoration: BoxDecoration(
          gradient: AppColors.primaryGradient,
          shape: BoxShape.circle,
          boxShadow: [
            BoxShadow(
              color: AppColors.primaryStart.withOpacity(0.3),
              blurRadius: 8,
              offset: const Offset(0, 2),
            ),
          ],
        ),
        child: const Icon(Icons.person_rounded, size: 22, color: Colors.white),
      );
    } else {
      final avatarPath = _activePersona.avatarPath;
      final hasAvatar = avatarPath != null && File(avatarPath).existsSync();
      
      return Container(
        width: 40, height: 40,
        decoration: BoxDecoration(
          gradient: hasAvatar ? null : AppColors.primaryGradient,
          color: hasAvatar ? Colors.white : null,
          shape: BoxShape.circle,
          image: hasAvatar 
              ? DecorationImage(image: FileImage(File(avatarPath)), fit: BoxFit.cover)
              : null,
          boxShadow: [
            BoxShadow(
              color: AppColors.primaryStart.withOpacity(0.25),
              blurRadius: 10,
              offset: const Offset(0, 3),
            ),
          ],
        ),
        child: !hasAvatar 
            ? Center(
                child: Text(
                  _activePersona.name.isNotEmpty ? _activePersona.name[0] : '?',
                  style: const TextStyle(
                    fontWeight: FontWeight.bold,
                    fontSize: 16,
                    color: Colors.white,
                  ),
                ),
              )
            : null,
      );
    }
  }
  
  /// è·³åŠ¨çš„åŠ è½½ç‚¹ç‚¹æŒ‡ç¤ºå™¨
  Widget _buildBouncingDots() {
    return AnimatedBuilder(
      animation: _loadingDotsController,
      builder: (context, child) {
        return Row(
          mainAxisSize: MainAxisSize.min,
          children: List.generate(3, (index) {
            // æ¯ä¸ªç‚¹çš„åŠ¨ç”»å»¶è¿Ÿ
            final delay = index * 0.2;
            final value = (_loadingDotsController.value + delay) % 1.0;
            // ä½¿ç”¨æ­£å¼¦æ›²çº¿åˆ›å»ºå¼¹è·³æ•ˆæœ
            final bounce = math.sin(value * math.pi);
            
            return Transform.translate(
              offset: Offset(0, -bounce * 6),
              child: Container(
                margin: const EdgeInsets.symmetric(horizontal: 3),
                width: 8,
                height: 8,
                decoration: BoxDecoration(
                  gradient: LinearGradient(
                    colors: [
                      AppColors.primaryStart.withOpacity(0.6 + bounce * 0.4),
                      AppColors.primaryEnd.withOpacity(0.6 + bounce * 0.4),
                    ],
                  ),
                  shape: BoxShape.circle,
                  boxShadow: [
                    BoxShadow(
                      color: AppColors.primaryStart.withOpacity(bounce * 0.5),
                      blurRadius: 4 + bounce * 4,
                      spreadRadius: bounce * 2,
                    ),
                  ],
                ),
              ),
            );
          }),
        );
      },
    );
  }
  
  /// çŸ¥è¯†åº“æœç´¢æ—¶çš„æ‰«æåŠ¨ç”»ç»„ä»¶
  Widget _buildScanningIndicator(String text) {
    return AnimatedBuilder(
      animation: _loadingDotsController,
      builder: (context, child) {
        return Container(
          padding: const EdgeInsets.symmetric(horizontal: 16, vertical: 10),
          child: Row(
            children: [
              // æ‰«æåŠ¨ç”»å›¾æ ‡
              Stack(
                alignment: Alignment.center,
                children: [
                  // å¤–åœˆæ—‹è½¬
                  Transform.rotate(
                    angle: _loadingDotsController.value * 2 * math.pi,
                    child: Container(
                      width: 24,
                      height: 24,
                      decoration: BoxDecoration(
                        shape: BoxShape.circle,
                        border: Border.all(
                          color: AppColors.primaryStart.withOpacity(0.3),
                          width: 2,
                        ),
                      ),
                      child: Align(
                        alignment: Alignment.topCenter,
                        child: Container(
                          width: 6,
                          height: 6,
                          decoration: BoxDecoration(
                            color: AppColors.primaryStart,
                            shape: BoxShape.circle,
                          ),
                        ),
                      ),
                    ),
                  ),
                  // ä¸­å¿ƒç‚¹
                  Container(
                    width: 6,
                    height: 6,
                    decoration: BoxDecoration(
                      gradient: AppColors.primaryGradient,
                      shape: BoxShape.circle,
                    ),
                  ),
                ],
              ),
              const SizedBox(width: 12),
              Expanded(
                child: ShaderMask(
                  shaderCallback: (bounds) {
                    final progress = _loadingDotsController.value;
                    return LinearGradient(
                      colors: [
                        AppColors.primaryStart,
                        AppColors.primaryEnd,
                        AppColors.primaryStart,
                      ],
                      stops: [
                        (progress - 0.3).clamp(0.0, 1.0),
                        progress,
                        (progress + 0.3).clamp(0.0, 1.0),
                      ],
                    ).createShader(bounds);
                  },
                  child: Text(
                    text,
                    style: const TextStyle(
                      fontSize: 13,
                      fontWeight: FontWeight.w600,
                      color: Colors.white,
                    ),
                    overflow: TextOverflow.ellipsis,
                  ),
                ),
              ),
            ],
          ),
        );
      },
    );
  }
  /// Enforce tool-first policy: when the model tries toç›´æ¥å›ç­”, force a tool action if patterns are detected.
  AgentDecision _enforceToolPolicy(String userText, AgentDecision decision, {required bool hasKnowledge}) {
    if (decision.type != AgentActionType.answer) return decision;

    final dataRegex = RegExp(r'(æ•°æ®|ç»Ÿè®¡|è¶‹åŠ¿|æ¥æº|æƒå¨|æœ€æ–°|å¸‚åœº|æŒ‡æ ‡|åˆ†æ)');
    final planRegex = RegExp(r'(è®¡åˆ’|æ­¥éª¤|è·¯çº¿å›¾|æ—¶é—´è¡¨|é‡Œç¨‹ç¢‘|æ–¹æ¡ˆ|ä»»åŠ¡|è¿›åº¦|é£é™©|é¢„ç®—|æˆæœ¬|èµ„æº)');
    final visionRegex = RegExp(r'(pdf|æ‰«æ|å›¾ç‰‡|æˆªå›¾|ocr)', caseSensitive: false);

    final needsData = dataRegex.hasMatch(userText);
    final needsPlan = planRegex.hasMatch(userText);
    final needsVision = visionRegex.hasMatch(userText);

    // Vision/OCR trigger
    if (needsVision) {
      return AgentDecision(
        type: AgentActionType.vision,
        content: decision.content ?? 'è¯·åˆ†æä¸Šä¼ çš„æ–‡ä»¶/å›¾ç‰‡ï¼ˆè‹¥ä¸ºPDFè¯·å…ˆOCRï¼‰å¹¶æå–å…³é”®ä¿¡æ¯ã€‚',
        reason: '${decision.reason ?? ''} [AUTO-TOOL] æ£€æµ‹åˆ°PDF/å›¾ç‰‡/æ‰«æï¼Œå…ˆç”¨ vision/OCR è·å–å†…å®¹ã€‚',
        confidence: decision.confidence ?? 0.6,
        continueAfter: true,
      );
    }

    // Data/plan trigger â†’ search first (prefer knowledge search forè§„åˆ’ç±»)
    if (needsData || needsPlan) {
      final query = _buildQueryFromUser(userText);
      final preferKnowledge = hasKnowledge && needsPlan && !needsData;
      final actionType = preferKnowledge ? AgentActionType.search_knowledge : AgentActionType.search;
      return AgentDecision(
        type: actionType,
        query: query,
        reason: '${decision.reason ?? ''} [AUTO-TOOL] è§¦å‘${needsData ? 'æ•°æ®/è¶‹åŠ¿' : 'è§„åˆ’'}åœºæ™¯ï¼Œå…ˆ${preferKnowledge ? 'search_knowledge' : 'search'}è·å–ä¾æ®ã€‚',
        confidence: decision.confidence ?? 0.7,
        continueAfter: true,
      );
    }

    return decision;
  }

  /// Build a concise query from user text (limit length, strip newlines)
  String _buildQueryFromUser(String userText) {
    final normalized = userText.replaceAll('\n', ' ').trim();
    if (normalized.isEmpty) return 'æŸ¥è¯¢';
    if (normalized.length <= 80) return normalized;
    return normalized.substring(0, 80);
  }

  /// Start periodic polling for async tasks
  void _startTaskPolling() {
    _taskPollTimer?.cancel();
    _taskPollTimer = Timer.periodic(const Duration(seconds: 20), (_) {
      _pollAsyncTasks();
    });
  }

  Future<void> _pollAsyncTasks() async {
    if (_taskPollInProgress) return;
    _taskPollInProgress = true;
    try {
      await _taskQueue.pollTasks();
      final ready = _taskQueue.getUndeliveredReady();
      if (ready.isEmpty) return;

      final refs = <ReferenceItem>[];
      final deliveredIds = <String>[];
      final newSystemMessages = <ChatMessage>[];

      for (final task in ready) {
        deliveredIds.add(task.id);
        final isSuccess = task.status == TaskStatus.success;
        final sourceType = _mapTaskTypeToSource(task.type);
        final statusLabel = isSuccess ? 'âœ… å·²å®Œæˆ' : (task.status == TaskStatus.failed ? 'âŒ å¤±è´¥' : 'âš ï¸ å¼‚å¸¸');
        final snippet = (task.result?.isNotEmpty == true ? task.result! : task.error ?? 'æœªè¿”å›ç»“æœ').trim();
        refs.add(ReferenceItem(
          title: '$statusLabel Â· ä»»åŠ¡ ${task.type}',
          url: task.statusUrl ?? 'task://${task.id}',
          snippet: snippet,
          sourceName: 'AsyncTask',
          sourceType: sourceType,
          reliability: isSuccess ? 0.7 : 0.3,
          authorityLevel: 'unknown',
          caveats: task.error != null ? [task.error!] : null,
        ));

        // Add a system message to inform user/agent
        newSystemMessages.add(ChatMessage(
          'system',
          '$statusLabel: ä»»åŠ¡ ${task.id} (${task.type})\n${snippet.isNotEmpty ? snippet : "æ— å†…å®¹"}',
          isMemory: true,
        ));
      }

      if (refs.isNotEmpty) {
        await _refManager.addExternalReferences(refs);
        if (mounted) {
          setState(() {
            _messages.addAll(newSystemMessages);
            _saveChatHistory();
          });
        } else {
          _messages.addAll(newSystemMessages);
          _saveChatHistory();
        }
      }

      await _taskQueue.markDelivered(deliveredIds);
    } catch (e) {
      debugPrint('Async task polling error: $e');
    } finally {
      _taskPollInProgress = false;
    }
  }

  String _mapTaskTypeToSource(String type) {
    final lower = type.toLowerCase();
    if (lower.contains('vision') || lower.contains('ocr') || lower.contains('image')) return 'vision';
    if (lower.contains('read') || lower.contains('url')) return 'url_content';
    if (lower.contains('knowledge')) return 'knowledge';
    if (lower.contains('search')) return 'web';
    if (lower.contains('analysis') || lower.contains('summary')) return 'feedback';
    return 'feedback';
  }

  /// Finalize a decision: enforce tool policy, fill missing fields with safe defaults
  AgentDecision _finalizeDecision(String userText, AgentDecision decision, {required bool hasKnowledge}) {
    final enforced = _enforceToolPolicy(userText, decision, hasKnowledge: hasKnowledge);
    
    // Fill required fields per tool
    switch (enforced.type) {
      case AgentActionType.search:
      case AgentActionType.search_knowledge:
        final safeQuery = (enforced.query ?? _buildQueryFromUser(userText)).trim();
        final safeReason = enforced.reason?.isNotEmpty == true ? enforced.reason! : '[AUTO-FIX] å¡«å……é»˜è®¤åŸå› ';
        return enforced.copyWith(
          query: safeQuery.isEmpty ? _buildQueryFromUser(userText) : safeQuery,
          reason: safeReason,
          confidence: enforced.confidence ?? 0.7,
          continueAfter: true,
        );
      case AgentActionType.vision:
        final safeContent = enforced.content?.isNotEmpty == true
            ? enforced.content!
            : 'è¯·åˆ†æä¸Šä¼ çš„æ–‡ä»¶/å›¾ç‰‡ï¼ˆè‹¥ä¸ºPDFè¯·å…ˆOCRï¼‰å¹¶æå–å…³é”®ä¿¡æ¯ã€‚';
        return enforced.copyWith(
          content: safeContent,
          reason: enforced.reason ?? '[AUTO-FIX] å¡«å……é»˜è®¤åŸå› ',
          confidence: enforced.confidence ?? 0.6,
          continueAfter: true,
        );
      case AgentActionType.draw:
        final safePrompt = enforced.content?.isNotEmpty == true ? enforced.content! : 'user requested image';
        return enforced.copyWith(
          content: safePrompt,
          reason: enforced.reason ?? '[AUTO-FIX] å¡«å……é»˜è®¤åŸå› ',
          confidence: enforced.confidence ?? 0.8,
          continueAfter: false,
        );
      case AgentActionType.read_url:
        final safeQuery = enforced.query?.isNotEmpty == true ? enforced.query! : _buildQueryFromUser(userText);
        return enforced.copyWith(
          query: safeQuery,
          reason: enforced.reason ?? '[AUTO-FIX] å¡«å……é»˜è®¤åŸå› ',
          confidence: enforced.confidence ?? 0.7,
          continueAfter: true,
        );
      case AgentActionType.save_file:
        final safeName = enforced.filename?.isNotEmpty == true ? enforced.filename! : 'output_${DateTime.now().millisecondsSinceEpoch}.md';
        final safeContent = enforced.content?.isNotEmpty == true ? enforced.content! : '# è¾“å‡ºå†…å®¹\n';
        return enforced.copyWith(
          filename: safeName,
          content: safeContent,
          reason: enforced.reason ?? '[AUTO-FIX] å¡«å……é»˜è®¤åŸå› ',
          confidence: enforced.confidence ?? 0.8,
          continueAfter: false,
        );
      case AgentActionType.take_note:
        final safeNote = enforced.content?.isNotEmpty == true ? enforced.content! : 'å¾…è®°å½•è¦ç‚¹';
        return enforced.copyWith(
          content: safeNote,
          reason: enforced.reason ?? '[AUTO-FIX] å¡«å……é»˜è®¤åŸå› ',
          confidence: enforced.confidence ?? 0.8,
          continueAfter: true,
        );
      default:
        return enforced.copyWith(
          reason: enforced.reason ?? '[AUTO-FIX] å¡«å……é»˜è®¤åŸå› ',
          confidence: enforced.confidence ?? 0.7,
        );
    }
  }
}

/// ç²’å­èƒŒæ™¯ç”»ç¬” - ä¼˜é›…çš„æµåŠ¨ç²’å­æ•ˆæœ
class _ParticlePainter extends CustomPainter {
  final double animationValue;
  
  _ParticlePainter(this.animationValue);
  
  @override
  void paint(Canvas canvas, Size size) {
    final paint = Paint()
      ..style = PaintingStyle.fill;
    
    // ç»˜åˆ¶å¤šä¸ªæµåŠ¨çš„ç²’å­/å…‰ç‚¹
    for (int i = 0; i < 15; i++) {
      final seed = i * 137.5; // é»„é‡‘è§’åº¦é—´éš”
      final x = (math.sin(animationValue + seed) * 0.4 + 0.5) * size.width;
      final y = (math.cos(animationValue * 0.7 + seed) * 0.4 + 0.5) * size.height;
      final radius = 2 + math.sin(animationValue * 2 + seed) * 1.5;
      final opacity = 0.1 + math.sin(animationValue + seed) * 0.05;
      
      paint.color = AppColors.primaryStart.withOpacity(opacity.clamp(0.02, 0.15));
      canvas.drawCircle(Offset(x, y), radius, paint);
      
      // å…‰æ™•æ•ˆæœ
      paint.color = AppColors.primaryStart.withOpacity(opacity * 0.3);
      canvas.drawCircle(Offset(x, y), radius * 2.5, paint);
    }
    
    // ç»˜åˆ¶å‡ æ¡ä¼˜é›…çš„æµåŠ¨æ›²çº¿
    for (int i = 0; i < 3; i++) {
      final path = Path();
      final startY = size.height * (0.3 + i * 0.2);
      
      path.moveTo(0, startY);
      for (double x = 0; x <= size.width; x += 10) {
        final wave = math.sin(x * 0.01 + animationValue + i) * 30;
        path.lineTo(x, startY + wave);
      }
      
      paint
        ..color = AppColors.primaryStart.withOpacity(0.03)
        ..style = PaintingStyle.stroke
        ..strokeWidth = 1.5;
      
      canvas.drawPath(path, paint);
    }
  }
  
  @override
  bool shouldRepaint(covariant _ParticlePainter oldDelegate) {
    return oldDelegate.animationValue != animationValue;
  }
}
